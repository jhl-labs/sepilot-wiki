{
  "title": "Qwen 3.5",
  "slug": "ai/qwen3-5",
  "content": "\n## 1. ê°œìš”\n**Qwen 3.5**ëŠ” **Alibaba**ì—ì„œ ë°œí‘œí•œ ìµœì‹  ëŒ€ê·œëª¨ ì–¸ì–´ ëª¨ë¸(LLM)ì…ë‹ˆë‹¤. **Gated DeltaNet + Mixtureâ€‘ofâ€‘Experts(MoE)** ì•„í‚¤í…ì²˜ë¥¼ ì±„íƒí•˜ì—¬, ì „ì²´ 397B íŒŒë¼ë¯¸í„° ì¤‘ 17Bë§Œ í™œì„±í™”í•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ë†’ì€ ì„±ëŠ¥ê³¼ íš¨ìœ¨ì„±ì„ ë™ì‹œì— ë‹¬ì„±í•©ë‹ˆë‹¤.\n\n- **ì£¼ìš” ëª©í‘œ** â€“ í…ìŠ¤íŠ¸Â·ì´ë¯¸ì§€Â·ë¹„ë””ì˜¤ë¥¼ í•˜ë‚˜ì˜ ëª¨ë¸ë¡œ ì²˜ë¦¬í•˜ë©´ì„œ, ì½”ë”© ì—ì´ì „íŠ¸Â·ê²€ìƒ‰ ì—ì´ì „íŠ¸ ë“± ë„êµ¬ í™œìš© ëŠ¥ë ¥ê¹Œì§€ ê°–ì¶˜ ë²”ìš© AI ëª¨ë¸.\n- **ì£¼ìš” ì ìš© ë¶„ì•¼** â€“ ì±—ë´‡, ì½”ë”© ì—ì´ì „íŠ¸, ë¬¸ì„œÂ·ì´ë¯¸ì§€ ë¶„ì„, ë‹¤êµ­ì–´ ë²ˆì—­, ì˜ë£Œ ì˜ìƒ ë¶„ì„ ë“±.\n\n### ëª¨ë¸ ì‚¬ì–‘\n| í•­ëª© | ë‚´ìš© |\n|------|------|\n| **ì „ì²´ íŒŒë¼ë¯¸í„°** | 397B (3,970ì–µ) |\n| **í™œì„± íŒŒë¼ë¯¸í„°** | 17B (A17B) |\n| **ì•„í‚¤í…ì²˜** | Gated DeltaNet + MoE (512 experts, 10 routed + 1 shared) |\n| **ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´** | ê¸°ë³¸ 262,144 í† í°, ìµœëŒ€ 1,010,000 í† í°ê¹Œì§€ í™•ì¥ |\n| **ì§€ì› ì–¸ì–´** | 201ê°œ ì–¸ì–´ ë° ë°©ì–¸ |\n\n> **ì‰½ê²Œ ë§í•´**: MoE(Mixtureâ€‘ofâ€‘Experts)ëŠ” ì „ë¬¸ê°€ ì—¬ëŸ¬ ëª… ì¤‘ í•„ìš”í•œ ì „ë¬¸ê°€ë§Œ ê³¨ë¼ ì“°ëŠ” ë°©ì‹ì…ë‹ˆë‹¤. 512ëª…ì˜ ì „ë¬¸ê°€ ì¤‘ ë§¤ë²ˆ 10ëª…ë§Œ í™œì„±í™”í•˜ê¸° ë•Œë¬¸ì—, ê±°ëŒ€í•œ ëª¨ë¸ì´ì§€ë§Œ ì‹¤ì œ ì—°ì‚°ëŸ‰ì€ 17B ëª¨ë¸ ìˆ˜ì¤€ìœ¼ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.\n\n---\n\n## 2. ëª¨ë¸ ì•„í‚¤í…ì²˜\n1. **Gated DeltaNet** â€“ ê¸°ì¡´ Transformerì˜ attention ë©”ì»¤ë‹ˆì¦˜ì„ ê°œì„ í•œ êµ¬ì¡°ë¡œ, ê¸´ ë¬¸ë§¥ì—ì„œë„ ë©”ëª¨ë¦¬ íš¨ìœ¨ì´ ì¢‹ìŠµë‹ˆë‹¤.\n2. **Mixtureâ€‘ofâ€‘Experts (MoE)** â€“ 512ê°œì˜ ì „ë¬¸ê°€(expert) ë„¤íŠ¸ì›Œí¬ ì¤‘ 10ê°œë¥¼ ë¼ìš°íŒ…í•˜ê³ , 1ê°œì˜ ê³µìœ  ì „ë¬¸ê°€ë¥¼ í•­ìƒ í™œì„±í™”í•©ë‹ˆë‹¤. ì´ ë•ë¶„ì— ì „ì²´ 397B íŒŒë¼ë¯¸í„°ì˜ ì§€ì‹ì„ í™œìš©í•˜ë©´ì„œë„ ì‹¤ì œ ì—°ì‚°ì€ 17B ìˆ˜ì¤€ìœ¼ë¡œ ìœ ì§€ë©ë‹ˆë‹¤.\n3. **ë©€í‹°ëª¨ë‹¬ ì…ë ¥ ì²˜ë¦¬** â€“ í…ìŠ¤íŠ¸Â·ì´ë¯¸ì§€Â·ë¹„ë””ì˜¤ë¥¼ ë™ì¼í•œ í† í° ê³µê°„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í•˜ë‚˜ì˜ ëª¨ë¸ì—ì„œ ì²˜ë¦¬í•©ë‹ˆë‹¤.\n4. **ì´ˆì¥ë¬¸ ì»¨í…ìŠ¤íŠ¸** â€“ ê¸°ë³¸ 262K í† í°, ìµœëŒ€ ì•½ 100ë§Œ í† í°ê¹Œì§€ ì²˜ë¦¬ ê°€ëŠ¥í•˜ì—¬ ëŒ€ê·œëª¨ ì½”ë“œë² ì´ìŠ¤ë‚˜ ê¸´ ë¬¸ì„œ ë¶„ì„ì— ìœ ë¦¬í•©ë‹ˆë‹¤.\n\n---\n\n## 3. í•™ìŠµ ë°ì´í„° ë° ë°©ë²•\n| êµ¬ë¶„ | ë‚´ìš© |\n|------|------|\n| **ì‚¬ì „í•™ìŠµ** | ë‹¤êµ­ì–´ í…ìŠ¤íŠ¸, ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ìŒ, ì½”ë“œ ë°ì´í„°ë¡œ ë©€í‹°ëª¨ë‹¬ ì‚¬ì „í•™ìŠµ |\n| **í›„ì²˜ë¦¬** | RLHF(ì¸ê°„ í”¼ë“œë°± ê¸°ë°˜ ê°•í™”í•™ìŠµ)ë¥¼ í†µí•œ ë¯¸ì„¸ì¡°ì • |\n| **ì§€ì› ì–¸ì–´** | 201ê°œ ì–¸ì–´ ë° ë°©ì–¸ (ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ì—ì„œ ìµœìƒìœ„ê¶Œ ì„±ëŠ¥) |\n| **íš¨ìœ¨ì„± ìµœì í™”** | MoE ë¼ìš°íŒ…, Mixedâ€‘Precision(BF16) |\n\n---\n\n## 4. ì£¼ìš” ê¸°ëŠ¥ ë° íŠ¹ì§•\n| ê¸°ëŠ¥ | ì„¤ëª… |\n|------|------|\n| **ìì—°ì–´ ì´í•´Â·ìƒì„±** | MMLUâ€‘Pro 87.8%, SuperGPQA 70.4% ë“± ì§€ì‹ ë²¤ì¹˜ë§ˆí¬ì—ì„œ GPTâ€‘5.2ì— ê·¼ì ‘í•˜ëŠ” ì„±ëŠ¥ |\n| **ì½”ë”© ì—ì´ì „íŠ¸** | SWEâ€‘bench Verified 76.4%, LiveCodeBench v6 83.6% ë“± ì‹¤ì œ ì½”ë“œ ìˆ˜ì •Â·ìƒì„± ëŠ¥ë ¥ ê²€ì¦ |\n| **ë©€í‹°ëª¨ë‹¬ ì²˜ë¦¬** | ì´ë¯¸ì§€Â·ë¹„ë””ì˜¤ ì´í•´, ë¬¸ì„œ OCR, ê³µê°„ ì¸ì‹ ë“± ë‹¤ì–‘í•œ ë¹„ì „ íƒœìŠ¤í¬ ì§€ì› |\n| **ë„êµ¬Â·ì—ì´ì „íŠ¸ í™œìš©** | BFCLâ€‘V4 72.9%, MCPâ€‘Mark 46.1% ë“± ë„êµ¬ í˜¸ì¶œ ë° ì—ì´ì „íŠ¸ ì‘ì—…ì—ì„œ ê°•ì  |\n| **ì´ˆì¥ë¬¸ ì²˜ë¦¬** | ìµœëŒ€ 100ë§Œ í† í° ì»¨í…ìŠ¤íŠ¸ë¡œ ëŒ€ê·œëª¨ ì½”ë“œë² ì´ìŠ¤Â·ë¬¸ì„œ ë¶„ì„ ê°€ëŠ¥ |\n| **ë‹¤êµ­ì–´ ì§€ì›** | 201ê°œ ì–¸ì–´ ì§€ì›, MMMLU 88.5%, NOVAâ€‘63 59.1%ë¡œ ë‹¤êµ­ì–´ ë²¤ì¹˜ë§ˆí¬ ìµœìƒìœ„ê¶Œ |\n\n---\n\n## 5. ë²¤ì¹˜ë§ˆí¬ ì„±ëŠ¥\n\n> **ì¶œì²˜** â€“ [Hugging Face Model Card](https://huggingface.co/Qwen/Qwen3.5-397B-A17B). ë¹„êµ ëª¨ë¸: GPTâ€‘5.2, Claude 4.5 Opus, Geminiâ€‘3 Pro, Qwen3â€‘Maxâ€‘Thinking, K2.5â€‘1Tâ€‘A32B.\n\n### 5â€‘1. ì–¸ì–´ ë²¤ì¹˜ë§ˆí¬\n\n#### ì§€ì‹ (Knowledge)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| MMLUâ€‘Pro | **87.8** | 87.4 | 89.5 | 89.8 |\n| MMLUâ€‘Redux | **94.9** | 95.0 | 95.6 | 95.9 |\n| SuperGPQA | **70.4** | 67.9 | 70.6 | 74.0 |\n| Câ€‘Eval | **93.0** | 90.5 | 92.2 | 93.4 |\n\n#### ì§€ì‹œ ìˆ˜í–‰ (Instruction Following)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| IFEval | **92.6** | 94.8 | 90.9 | 93.5 |\n| IFBench | **76.5** | 75.4 | 58.0 | 70.4 |\n| MultiChallenge | **67.6** | 57.9 | 54.2 | 64.2 |\n\n#### STEM (ê³¼í•™Â·ê¸°ìˆ Â·ê³µí•™Â·ìˆ˜í•™)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| GPQA | **88.4** | 92.4 | 87.0 | 91.9 |\n| HLE | **28.7** | 35.5 | 30.8 | 37.5 |\n| HLEâ€‘Verified | **37.6** | 43.3 | 38.8 | 48.0 |\n\n#### ì¶”ë¡  (Reasoning)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| LiveCodeBench v6 | **83.6** | 87.7 | 84.8 | 90.7 |\n| HMMT Feb 25 | **94.8** | 99.4 | 92.9 | 97.3 |\n| HMMT Nov 25 | **92.7** | 100 | 93.3 | 93.3 |\n| IMOAnswerBench | **80.9** | 86.3 | 84.0 | 83.3 |\n| AIME26 | **91.3** | 96.7 | 93.3 | 90.6 |\n\n#### ê¸´ ë¬¸ë§¥ (Long Context)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| AAâ€‘LCR | **68.7** | 72.7 | 74.0 | 70.7 |\n| LongBench v2 | **63.2** | 54.5 | 64.4 | 68.2 |\n\n#### ì¼ë°˜ ì—ì´ì „íŠ¸ (General Agent)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| BFCLâ€‘V4 | **72.9** | 63.1 | 77.5 | 72.5 |\n| TAU2â€‘Bench | **86.7** | 87.1 | 91.6 | 85.4 |\n| VITAâ€‘Bench | **49.7** | 38.2 | 56.3 | 51.6 |\n| DeepPlanning | **34.3** | 44.6 | 33.9 | 23.3 |\n| Tool Decathlon | **38.3** | 43.8 | 43.5 | 36.4 |\n| MCPâ€‘Mark | **46.1** | 57.5 | 42.3 | 53.9 |\n\n#### ê²€ìƒ‰ ì—ì´ì „íŠ¸ (Search Agent)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| HLE w/ tool | **48.3** | 45.5 | 43.4 | 45.8 |\n| BrowseComp | **69.0** | 65.8 | 67.8 | 59.2 |\n| BrowseCompâ€‘zh | **70.3** | 76.1 | 62.4 | 66.8 |\n| WideSearch | **74.0** | 76.8 | 76.4 | 68.0 |\n\n#### ì½”ë”© ì—ì´ì „íŠ¸ (Coding Agent)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| SWEâ€‘bench Verified | **76.4** | 80.0 | 80.9 | 76.2 |\n| SWEâ€‘bench Multilingual | **69.3** | 72.0 | 77.5 | 65.0 |\n| SecCodeBench | **68.3** | 68.7 | 68.6 | 62.4 |\n| Terminal Bench 2 | **52.5** | 54.0 | 59.3 | 54.2 |\n\n#### ë‹¤êµ­ì–´ (Multilingualism)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| MMMLU | **88.5** | 89.5 | 90.1 | 90.6 |\n| MMLUâ€‘ProX | **84.7** | 83.7 | 85.7 | 87.7 |\n| NOVAâ€‘63 | **59.1** | 54.6 | 56.7 | 56.7 |\n| INCLUDE | **85.6** | 87.5 | 86.2 | 90.5 |\n| Global PIQA | **89.8** | 90.9 | 91.6 | 93.2 |\n| PolyMATH | **73.3** | 62.5 | 79.0 | 81.6 |\n| WMT24++ | **78.9** | 78.8 | 79.7 | 80.7 |\n| MAXIFE | **88.2** | 88.4 | 79.2 | 87.5 |\n\n### 5â€‘2. ë¹„ì „â€‘ì–¸ì–´ ë²¤ì¹˜ë§ˆí¬\n\n#### STEM ë° í¼ì¦\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| MMMU | **85.0** | 86.7 | 80.7 | 87.2 |\n| MMMUâ€‘Pro | **79.0** | 79.5 | 70.6 | 81.0 |\n| MathVision | **88.6** | 83.0 | 74.3 | 86.6 |\n| MathVista (mini) | **90.3** | 83.1 | 80.0 | 87.9 |\n| Weâ€‘Math | **87.9** | 79.0 | 70.0 | 86.9 |\n| DynaMath | **86.3** | 86.8 | 79.7 | 85.1 |\n| ZEROBench | **12** | 9 | 3 | 10 |\n| BabyVision | **52.3** | 34.4 | 14.2 | 49.7 |\n\n#### ì¼ë°˜ ì‹œê° ì´í•´ (General VQA)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| RealWorldQA | **83.9** | 83.3 | 77.0 | 83.3 |\n| MMStar | **83.8** | 77.1 | 73.2 | 83.1 |\n| HallusionBench | **71.4** | 65.2 | 64.1 | 68.6 |\n| MMBench EN | **93.7** | 88.2 | 89.2 | 93.7 |\n| SimpleVQA | **67.1** | 55.8 | 65.7 | 73.2 |\n\n#### ë¬¸ì„œ ì´í•´Â·OCR\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| OmniDocBench1.5 | **90.8** | 85.7 | 87.7 | 88.5 |\n| CharXiv (RQ) | **80.8** | 82.1 | 68.5 | 81.4 |\n| MMLongBenchâ€‘Doc | **61.5** | â€” | 61.9 | 60.5 |\n| CCâ€‘OCR | **82.0** | 70.3 | 76.9 | 79.0 |\n| AI2D TEST | **93.9** | 92.2 | 87.7 | 94.1 |\n| OCRBench | **93.1** | 80.7 | 85.8 | 90.4 |\n\n#### ê³µê°„ ì¸ì‹ (Spatial Intelligence)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| ERQA | **67.5** | 59.8 | 46.8 | 70.5 |\n| CountBench | **97.2** | 91.9 | 90.6 | 97.3 |\n| EmbSpatialBench | **84.5** | 81.3 | 75.7 | 61.2 |\n| LingoQA | **81.6** | 68.8 | 78.8 | 72.8 |\n| V* | **95.8** | 75.9 | 67.0 | 88.0 |\n\n#### ë¹„ë””ì˜¤ ì´í•´\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| VideoMME (w/ sub) | **87.5** | 86.0 | 77.6 | 88.4 |\n| VideoMME (w/o sub) | **83.7** | 85.8 | 81.4 | 87.7 |\n| VideoMMMU | **84.7** | 85.9 | 84.4 | 87.6 |\n| MLVU (Mâ€‘Avg) | **86.7** | 85.6 | 81.7 | 83.0 |\n| MVBench | **77.6** | 78.1 | 67.2 | 74.1 |\n| LVBench | **75.5** | 73.7 | 57.3 | 76.2 |\n\n#### ë¹„ì£¼ì–¼ ì—ì´ì „íŠ¸\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| ScreenSpot Pro | **65.6** | â€” | 45.7 | 72.7 |\n| OSWorldâ€‘Verified | **62.2** | 38.2 | 66.3 | â€” |\n| AndroidWorld | **66.8** | â€” | â€” | â€” |\n\n#### ì˜ë£Œ (Medical VQA)\n| ë²¤ì¹˜ë§ˆí¬ | Qwen 3.5 | GPTâ€‘5.2 | Claude 4.5 Opus | Geminiâ€‘3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| SLAKE | **79.9** | 76.9 | 76.4 | 81.3 |\n| PMCâ€‘VQA | **64.2** | 58.9 | 59.9 | 62.3 |\n| MedXpertQAâ€‘MM | **70.0** | 73.3 | 63.6 | 76.0 |\n\n### 5â€‘3. ì„±ëŠ¥ ìš”ì•½\n- **ë¹„ì „â€‘ìˆ˜í•™ ë¶„ì•¼ ìµœê°•**: MathVision(88.6%), MathVista(90.3%), Weâ€‘Math(87.9%)ì—ì„œ GPTâ€‘5.2ì™€ Geminiâ€‘3 Proë¥¼ ì•ì„¬.\n- **ë¬¸ì„œÂ·OCR íŠ¹í™”**: OmniDocBench(90.8%), OCRBench(93.1%), CCâ€‘OCR(82.0%)ì—ì„œ ì „ ëª¨ë¸ ëŒ€ë¹„ ìµœê³  ì„±ëŠ¥.\n- **ê³µê°„ ì¸ì‹ ìš°ìˆ˜**: V*(95.8%), CountBench(97.2%), EmbSpatialBench(84.5%)ì—ì„œ ì••ë„ì  ì°¨ì´.\n- **ë‹¤êµ­ì–´ ê°•ì **: NOVAâ€‘63(59.1%), MAXIFE(88.2%)ì—ì„œ ì „ ëª¨ë¸ 1ìœ„.\n- **ì—ì´ì „íŠ¸ ëŠ¥ë ¥**: IFBench(76.5%), MultiChallenge(67.6%)ì—ì„œ ì§€ì‹œ ìˆ˜í–‰ ëŠ¥ë ¥ì´ ë‹ë³´ì„.\n- **ì¶”ë¡ Â·ì½”ë”©ì€ GPTâ€‘5.2ì— ë¹„í•´ ì†Œí­ ë’¤ì²˜ì§**: AIME26(91.3 vs 96.7), SWEâ€‘bench Verified(76.4 vs 80.0).\n\n---\n\n## 6. ë¼ì´ì„ ìŠ¤ ë° ë°ì´í„° ì‚¬ìš©ê¶Œ\n| í•­ëª© | ë‚´ìš© | ë¹„ê³  |\n|------|------|------|\n| **ëª¨ë¸ ì½”ë“œÂ·ê°€ì¤‘ì¹˜** | Apache 2.0 | ìƒì—…ì Â·ë¹„ìƒì—…ì  ëª¨ë‘ ì‚¬ìš© ê°€ëŠ¥ |\n| **í…ìŠ¤íŠ¸ ë°ì´í„°** | CCâ€‘BY 4.0, CCâ€‘0, ìì²´ ìˆ˜ì§‘ | ìƒì„¸ ë¼ì´ì„ ìŠ¤ëŠ” ëª¨ë¸ ì¹´ë“œ ì°¸ê³  |\n| **ì½”ë“œ ë°ì´í„°** | MIT, Apache 2.0, GPL ë“± | ê°œë³„ ë ˆí¬ì§€í„°ë¦¬ ë¼ì´ì„ ìŠ¤ í™•ì¸ í•„ìš” |\n\n---\n\n## 7. ì œí•œì  ë° ì£¼ì˜ì‚¬í•­\n- **ì¶”ë¡  ë¹„ìš©** â€“ 397B ëª¨ë¸ì€ ëŒ€ê·œëª¨ GPU í´ëŸ¬ìŠ¤í„°ê°€ í•„ìš”í•˜ë¯€ë¡œ, ê°œì¸ í™˜ê²½ì—ì„œëŠ” ê²½ëŸ‰ íŒŒìƒ ëª¨ë¸ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n- **í¸í–¥Â·ì•ˆì „ì„±** â€“ ëŒ€ê·œëª¨ ì›¹ ë°ì´í„° í•™ìŠµ íŠ¹ì„±ìƒ ì„±ë³„Â·ì¸ì¢…Â·ë¬¸í™” í¸í–¥ì´ ì¡´ì¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n- **HLE ì„±ëŠ¥** â€“ Humanity's Last Exam ë²¤ì¹˜ë§ˆí¬ì—ì„œ 28.7%ë¡œ, GPTâ€‘5.2(35.5%)Â·Geminiâ€‘3 Pro(37.5%)ì— ë¹„í•´ ì´ˆê³ ë‚œì´ë„ ë¬¸ì œì—ì„œ ì•½ì„¸ë¥¼ ë³´ì…ë‹ˆë‹¤.\n\n---\n\n## 8. ì°¸ê³  ìë£Œ\n- **Hugging Face Model Card** â€“ https://huggingface.co/Qwen/Qwen3.5-397B-A17B\n- **Qwen ê³µì‹ ë¸”ë¡œê·¸** â€“ https://qwenlm.github.io/blog/qwen3.5/\n\n*ë³¸ ë¬¸ì„œëŠ” 2026â€‘02â€‘19 í˜„ì¬ Hugging Face Model Cardì— ê³µê°œëœ ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*\n",
  "lastModified": "2026-02-20T01:32:22Z",
  "author": "SEPilot AI",
  "status": "draft",
  "isDraft": true,
  "isInvalid": false,
  "tags": [
    "Qwen",
    "LLM",
    "ë©€í‹°ëª¨ë‹¬",
    "MoE",
    "ë²¤ì¹˜ë§ˆí¬"
  ],
  "order": 2,
  "history": [
    {
      "sha": "f08fbbd",
      "message": "ğŸŒ³ Wiki Tree Maintenance: WikiëŠ” 4ê°œì˜ ì£¼ìš” ì¹´í…Œê³ ë¦¬(ai, projects, kubernetes, bun)ì™€ ë³´ì¡° ì¹´í…Œê³ ë¦¬(reports)ë¡œ êµ¬ì„±ë¼ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì€ ëŒ€ë¶€ë¶„ ê·œì¹™ì— ë§ì§€ë§Œ,  ì¹´í…Œê³ ë¦¬ì— ë™ì¼ ë‚´ìš©ì˜ Opencode ë¬¸ì„œê°€ ë‘ ê°œ ì¡´ì¬í•©ë‹ˆë‹¤(í•˜ë‚˜ëŠ” published, ë‹¤ë¥¸ í•˜ë‚˜ëŠ” deleted). ì „ì²´ì ìœ¼ë¡œ ë¬¸ì„œê°€ í©ì–´ì ¸ ìˆì–´ ì¹´í…Œê³ ë¦¬ ë‚´ ì •ë ¬(order)ê³¼ ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤.",
      "author": "GitHub Action",
      "authorEmail": "action@github.com",
      "date": "2026-02-20T01:32:22Z",
      "additions": 0,
      "deletions": 0
    },
    {
      "sha": "6444b78",
      "message": "fix: findDocument()ê°€ ì‚­ì œ ë¬¸ì„œë¥¼ ê±´ë„ˆë›°ë„ë¡ ìˆ˜ì • ë° Issue #183 í”¼ë“œë°± ë°˜ì˜",
      "author": "JHL",
      "authorEmail": "bkperio@gmail.com",
      "date": "2026-02-19T11:18:18+09:00",
      "additions": 0,
      "deletions": 0
    },
    {
      "sha": "9459c99",
      "message": "ğŸŒ³ Wiki Tree Maintenance: ì „ì²´ 22ê°œì˜ ë¬¸ì„œê°€ 5ê°œì˜ ì£¼ìš” ì¹´í…Œê³ ë¦¬( reports, ai, kubernetes, projects, bun )ì— ë¶„ì‚°ë˜ì–´ ìˆë‹¤. ë£¨íŠ¸ ë ˆë²¨ì— ì¡´ì¬í•˜ëŠ” Qwen3.5 ë¬¸ì„œê°€ ì¤‘ë³µë˜ì–´ ìˆìœ¼ë©°, ë£¨íŠ¸ì— íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²ƒì€ ê¸ˆì§€ ê·œì¹™ì„ ìœ„ë°˜í•œë‹¤. ë˜í•œ ë™ì¼í•œ Opencode ë¬¸ì„œê°€ ë‘ ê°œ ì¡´ì¬í•˜ì§€ë§Œ í•˜ë‚˜ëŠ” ì´ë¯¸ deleted ìƒíƒœì´ë¯€ë¡œ ì‚­ì œë§Œìœ¼ë¡œ ì¶©ë¶„í•˜ë‹¤. íŒŒì¼ëª…ì€ ëŒ€ë¶€ë¶„ slug ê·œì¹™ì„ ë”°ë¥´ê³  ìˆì–´ ë³„ë„ renameì´ í•„ìš”í•˜ì§€ ì•Šë‹¤. ê° ì¹´í…Œê³ ë¦¬ë³„ ë¬¸ì„œ ìˆœì„œë¥¼ ì •ë¦¬í•˜ê³ , ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ íƒìƒ‰ì„±ì´ í–¥ìƒëœë‹¤.",
      "author": "github-actions[bot]",
      "authorEmail": "github-actions[bot]@users.noreply.github.com",
      "date": "2026-02-19T02:01:59Z",
      "additions": 0,
      "deletions": 0
    },
    {
      "sha": "e9ead79",
      "message": "ğŸŒ³ Wiki Tree Maintenance: ì „ì²´ 23ê°œì˜ ë¬¸ì„œê°€ 5ê°œì˜ ì£¼ìš” ì¹´í…Œê³ ë¦¬(projects, ai, kubernetes, bun, reports)ë¡œ ë‚˜ë‰˜ì–´ ìˆìŠµë‹ˆë‹¤. ë£¨íŠ¸ì— ìœ„ì¹˜í•œ Qwen3.5 ë¬¸ì„œê°€ ai ì¹´í…Œê³ ë“œì™€ ì¤‘ë³µë˜ì–´ ìˆìœ¼ë©°, Opencode ê´€ë ¨ ì¤‘ë³µ ë¬¸ì„œê°€ ì¡´ì¬í•©ë‹ˆë‹¤. íŒŒì¼ëª…ì€ ëŒ€ë¶€ë¶„ slug í˜•íƒœì´ì§€ë§Œ, ë£¨íŠ¸ì— ë‚¨ì•„ ìˆëŠ” ë¬¸ì„œëŠ” ì´ë™ì´ í•„ìš”í•©ë‹ˆë‹¤. ê° ì¹´í…Œê³ ë¦¬ ë‚´ ë¬¸ì„œ ìˆœì„œë¥¼ ì •ì˜í•˜ê³ , ì¹´í…Œê³ ë¦¬ ë©”íƒ€ë°ì´í„°ë¥¼ ì¶”ê°€í•˜ë©´ íƒìƒ‰ì„±ì´ í–¥ìƒë©ë‹ˆë‹¤.",
      "author": "github-actions[bot]",
      "authorEmail": "github-actions[bot]@users.noreply.github.com",
      "date": "2026-02-19T01:41:58Z",
      "additions": 0,
      "deletions": 0
    },
    {
      "sha": "0b99235",
      "message": "ğŸŒ³ Wiki Tree Maintenance: ì „ì²´ ìœ„í‚¤ëŠ” 5ê°œì˜ ì£¼ìš” ì¹´í…Œê³ ë¦¬( reports, ai, kubernetes, bun, projects ) ë¡œ êµ¬ì„±ë˜ì–´ ìˆìœ¼ë‚˜, ë£¨íŠ¸ì— ì¼ë°˜ ë¬¸ì„œê°€ ì¡´ì¬í•˜ê³  ì¤‘ë³µëœ Opencode ë¬¸ì„œê°€ ë‚¨ì•„ ìˆìŠµë‹ˆë‹¤. íŒŒì¼ëª…ì€ ëŒ€ë¶€ë¶„ slug ê·œì¹™ì„ ë”°ë¥´ê³  ìˆìœ¼ë‚˜, ë£¨íŠ¸ íŒŒì¼ì€ ì´ë™ì´ í•„ìš”í•©ë‹ˆë‹¤.",
      "author": "github-actions[bot]",
      "authorEmail": "github-actions[bot]@users.noreply.github.com",
      "date": "2026-02-19T01:25:27Z",
      "additions": 0,
      "deletions": 0
    }
  ]
}