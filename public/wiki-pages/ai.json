{
  "title": "AI 에이전트 보안 베스트 프랙티스",
  "slug": "ai",
  "content": "\n## 개요\n- **문서 목적**: AI 에이전트를 운영·관리하는 팀에게 최신 보안 위협에 대비하고, 설계·구현·운영 단계에서 적용할 수 있는 구체적인 보안 권고안을 제공한다.  \n- **대상 독자**: AI 플랫폼 엔지니어, DevSecOps 담당자, 보안 아키텍트, 클라우드 운영팀 등 AI 에이전트를 서비스 형태로 제공하거나 내부에 배포하는 모든 이해관계자.  \n- **AI 에이전트 보안 정의**: 모델·프롬프트·실행 환경을 포함한 전체 에이전트 파이프라인을 대상으로 무단 접근, 모델 탈취, 프롬프트 인젝션, 데이터 포이즈닝 등 위협을 방지·탐지·복구하는 일련의 활동을 의미한다.  \n- **적용 범위**: 퍼블릭 클라우드(AWS, Azure 등), 온프레미스 데이터센터, 엣지 디바이스 등 배포 형태와 관계없이 동일한 보안 원칙을 적용한다.\n\n## 최신 위협 현황\n| 위협 유형 | 설명 | 참고 |\n|----------|------|------|\n| 모델 탈취·역공학 | 공격자가 모델 파일이나 파라미터를 탈취해 재학습·재배포하거나, 모델 구조를 역추적해 취약점을 찾는다. | 추가 조사가 필요합니다 |\n| 프롬프트 인젝션·데이터 포이즈닝 | 악의적인 입력이 프롬프트 엔진에 삽입돼 의도치 않은 동작을 유발하거나, 학습 데이터에 오염된 샘플이 모델 품질을 저하시킨다. | 추가 조사가 필요합니다 |\n| 권한 상승·악성 행동 주입 | 에이전트 실행 환경에 대한 권한이 과도하게 부여돼, 공격자가 시스템 명령을 실행하거나 악성 코드를 주입한다. | 추가 조사가 필요합니다 |\n| 공급망 공격·서드파티 라이브러리 위험 | 의존성 라이브러리나 컨테이너 이미지에 포함된 취약점이 악용돼 에이전트 전체가 위험에 노출된다. | AWS Well‑Architected 프레임워크는 의존성 관리와 CVE 트래킹을 강조한다[[AWS Well‑Architected 프레임워크](https://docs.aws.amazon.com/ko_kr/wellarchitected/latest/framework/wellarchitected-framework.pdf)] |\n\n## 보안 설계 원칙\n1. **최소 권한 원칙 (Least Privilege)** – 필요 최소한의 권한만 부여한다. AWS Well‑Architected 운영 우수성 원칙 중 “OPS05‑BP01 버전 관리 사용” 등은 최소 권한 적용을 권고한다[[AWS 운영 우수성 요소](https://docs.aws.amazon.com/ko_kr/wellarchitected/latest/operational-excellence-pillar/wellarchitected-operational-excellence-pillar.pdf)].\n2. **방어 깊이 (Defense‑in‑Depth)** – 네트워크, 호스트, 애플리케이션 레이어 각각에 방어 체계를 구축한다.\n3. **제로 트러스트 아키텍처** – 모든 요청을 인증·인가하고, 내부 트래픽도 검증한다.\n4. **보안‑우선 개발 라이프사이클 (SecDevOps)** – 설계·코딩·배포·운영 전 단계에 보안 검증을 자동화한다. AWS Well‑Architected는 “피드백 루프 구현”을 통해 지속적인 보안 개선을 강조한다[[AWS 운영 우수성 요소](https://docs.aws.amazon.com/ko_kr/wellarchitected/latest/operational-excellence-pillar/wellarchitected-operational-excellence-pillar.pdf)].\n\n## AI 에이전트 아키텍처 보안\n- **컴포넌트 구분**  \n  - *모델*: 학습된 파라미터와 가중치 파일.  \n  - *프롬프트 엔진*: 사용자 입력을 모델에 전달하고 결과를 가공하는 로직.  \n  - *실행 환경*: 컨테이너·VM·샌드박스 등 실제 코드가 실행되는 인프라.  \n- **격리 전략**  \n  - 컨테이너 기반 격리: Docker, Kubernetes 등에서 네임스페이스와 cgroup을 활용한다.  \n  - 가상 머신 격리: 고위험 작업은 별도 VM에서 실행한다.  \n  - 샌드박스: 제한된 시스템 콜만 허용하도록 Seccomp, AppArmor 등을 적용한다.  \n- **네트워크 세분화 및 트래픽 암호화**  \n  - VPC 서브넷, 보안 그룹, 서비스 메쉬(예: Istio)로 내부 트래픽을 분리한다.  \n  - TLS 1.2 이상을 사용해 모델·프롬프트 간 통신을 암호화한다.\n\n### 위험한 명령 실행 방지\nAI 코딩 에이전트(Claude Code, Cursor, Copilot 등)는 **셸 명령 실행**, **파일 편집**, **API 호출** 등 강력한 시스템 접근 권한을 가질 수 있다. 최근 EUNO.NEWS 기사[[링크](https://euno.news/posts/ko/your-ai-agent-just-ran-rm-rf-heres-how-to-stop-it-06b436)]에서는 에이전트가 `rm -rf /`와 같은 파괴적인 명령을 실행할 위험성을 강조하고, 이를 차단하기 위한 **BodAIGuard**라는 가드레일 솔루션을 소개한다.\n\n#### 핵심 방어 메커니즘\n| 요소 | 설명 |\n|------|------|\n| **프롬프트‑인젝션 스캐너** | 입력 텍스트를 정규식·Base64 디코딩 등으로 분석해 숨겨진 악성 페이로드를 탐지한다. |\n| **45개의 Block Rules** | 예: `rm\\s+(-[a-zA-Z]*)?\\s*/` → “Filesystem root destruction” 차단. |\n| **45개의 Confirm Rules** | 위험도가 낮은 명령(예: `rm -r`)은 사용자 확인 절차를 요구한다. |\n| **12개의 카테고리** | 파괴 명령, 파일 시스템 접근, 권한 탈취 등으로 분류해 정책 적용을 단순화한다. |\n| **Shell Guard** | Bash와 연동해 실시간으로 명령을 평가하고, 차단된 경우 JSON‑RPC 오류를 반환한다. |\n| **MCP/HTTP Proxy** | 모든 도구 호출을 프록시를 통해 라우팅해 중앙에서 정책을 적용한다. |\n\n#### 적용 방법 (요약)\n1. **바이너리 설치**  \n   ```bash\n   # 플랫폼에 맞는 바이너리 다운로드\n   chmod +x bodaiguard-linux-x64\n   sudo mv bodaiguard-linux-x64 /usr/local/bin/bodaiguard\n   ```\n2. **훅 설치** (Claude Code 등)  \n   ```bash\n   bodaiguard install hooks\n   ```\n3. **테스트**  \n   ```bash\n   bodaiguard test 'rm -rf /'   # → BLOCK: Filesystem root destruction\n   bodaiguard test 'ls -la'     # → ALLOW\n   ```\n4. **규칙 커스터마이징** (`default.yaml`)  \n   ```yaml\n   actions:\n     destructive:\n       block:\n         - pattern: 'rm\\\\s+(-[a-zA-Z]*)?\\\\s*/'\n           reason: Filesystem root destruction\n         - pattern: 'mkfs\\\\.'\n           reason: Filesystem format\n       confirm:\n         - pattern: 'rm\\\\s+-r'\n           reason: Recursive delete\n     paths:\n       block:\n         - ~/.ssh/**\n         - /etc/shadow\n       readonly:\n         - /etc/passwd\n   ```\n5. **CI/CD 연동**: CI 파이프라인에 `bodaiguard test`를 삽입해 PR 단계에서 위험 명령을 자동 차단한다.\n\n#### 베스트 프랙티스 요약\n- **샌드박스·컨테이너 격리**: 모든 코딩 에이전트는 최소 권한 컨테이너에서 실행하고, 파일 시스템은 읽기 전용 루트와 제한된 볼륨만 마운트한다.  \n- **명령 허용 리스트**: 허용된 명령 집합을 사전 정의하고, 허용되지 않은 명령은 `BodAIGuard`가 차단하도록 설정한다.  \n- **실시간 모니터링**: Falco·OPA와 연계해 `bodaiguard` 차단 이벤트를 SIEM에 전송하고, 알림 기반 자동 격리 워크플로우를 구축한다.  \n- **정기적인 규칙 리뷰**: 새로운 공격 기법이 등장하면 `default.yaml`에 규칙을 추가하고, CI 테스트를 통해 회귀를 방지한다.  \n\n> **참고**: BodAIGuard는 오픈소스 프로젝트이며, GitHub Releases 페이지에서 최신 바이너리를 제공한다. 자세한 구현 내용은 프로젝트 README와 공식 문서를 확인한다.\n\n## 모델 및 파라미터 보호\n- **모델 암호화 및 키 관리 (KMS)** – 모델 파일을 저장소에 업로드하기 전 암호화하고, 키는 클라우드 KMS(AWS KMS, Azure Key Vault 등)로 관리한다.  \n- **모델 서명 및 무결성 검증** – SHA‑256 해시와 디지털 서명을 이용해 배포 시 무결성을 확인한다.  \n- **버전 관리와 롤백 정책** – 모델 레지스트리(예: MLflow, SageMaker Model Registry)에서 버전을 명시하고, 취약점 발견 시 이전 안전 버전으로 롤백한다.\n\n## 프롬프트 및 입력 데이터 보안\n- **입력 검증 및 정규화** – 사용자 입력을 화이트리스트 기반으로 정규화하고, 특수 문자·스크립트 삽입을 차단한다.  \n- **프롬프트 템플릿 보안 (시크릿 관리)** – 템플릿에 포함되는 API 키·비밀번호 등은 비밀 관리 서비스(Secrets Manager)에서 동적으로 주입한다.  \n- **데이터 포이즈닝 탐지 메커니즘** – 입력 데이터의 통계적 이상치를 모니터링하고, 의심스러운 샘플을 자동 차단한다. GPAI 위험 관리 프레임워크는 데이터 품질 검증을 핵심 요소로 제시한다[[GPAI 위험 관리 프레임워크 (PDF)](https://astlyi.s3.ap-northeast-2.amazonaws.com/2025/TTA_%E1%84%87%E1%85%A5%E1%86%B7%E1%84%8B%E1%85%AD%E1%86%BC+%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A9%E1%86%BC%E1%84%8C%E1%85%B5%E1%84%82%E1%85%B3+(GPAI)+%E1%84%8B%E1%85%B1%E1%84%92%E1%85%A5%E1%86%B7+%E1%84%80%E1%85%AA%E1%86%AB%E1%84%85%E1%85%B5+%E1%84%91%E1%85%B3%E1%84%85%E1%85%A6%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3.pdf)].\n\n## 인증·인가·감사 (IAM)\n- **강력 인증** – MFA, OIDC, SSO 등 다중 인증을 기본 적용한다.  \n- **역할 기반 접근 제어 (RBAC)** – 서비스 계정·사용자에게 최소 권한 역할을 할당하고, 정책은 IaC(Terraform, CloudFormation)로 관리한다.  \n- **감사 로그 수집 및 보관 정책** – CloudTrail, Azure Monitor 등에서 모든 IAM 이벤트를 수집하고, 최소 90일 이상 보관한다.\n\n## 런타임 모니터링 및 위협 탐지\n- **행동 기반 이상 탐지** – 모델 호출 빈도·응답 시간 등을 실시간으로 분석해 비정상 패턴을 감지한다.  \n- **실시간 로그 분석 및 SIEM 연동** – Falco, OPA 등 오픈소스 도구와 AWS GuardDuty, Azure Sentinel 등 클라우드 SIEM을 연동한다.  \n- **자동 대응 워크플로우** – 이상 징후 발생 시 컨테이너 자동 격리·재시작을 트리거하는 GitHub Actions 또는 Argo Workflows를 활용한다.\n\n## Preventing Dangerous Command Execution in AI Coding Agents\n> **출처**: [EUNO.NEWS – “당신의 AI 에이전트가 방금 rm -rf / 를 실행했습니다 — 이를 멈추는 방법”](https://euno.news/posts/ko/your-ai-agent-just-ran-rm-rf-heres-how-to-stop-it-06b436)\n\n### 1. 위험 개요\nAI 코딩 에이전트(Claude Code, Cursor, GitHub Copilot 등)는 **셸 명령 실행**, **파일 편집**, **API 호출** 기능을 제공한다. 이러한 기능이 악용되면 `rm -rf /` 와 같은 파괴적인 명령이 실행되어 시스템 전체가 손상될 수 있다.\n\n### 2. 가드레일 필요성\n- **프롬프트 인젝션**을 통해 악성 텍스트가 도구 결과에 삽입되면 에이전트가 의도치 않은 명령을 수행한다.  \n- 보호가 없을 경우 에이전트가 실제 시스템에 직접적인 피해를 줄 수 있다.\n\n### 3. BodAIGuard 개요\nBodAIGuard는 **AI 에이전트와 시스템 사이에 위치**해 모든 도구 호출을 사전 평가한다.\n\n| 구성 요소 | 역할 |\n|-----------|------|\n| **Block Rules** (45개) | 위험한 명령·경로를 즉시 차단 |\n| **Confirm Rules** (45개) | 위험도가 낮지만 확인이 필요한 명령을 사용자에게 확인 요청 |\n| **Categories** (12개) | 명령, 파일 경로, 역할 탈취 등으로 분류 |\n| **Prompt‑Injection Scanner** | 입력에 숨겨진 베이스64, 제로‑폭 문자, HTML 인젝션 등을 탐지 |\n| **강제 모드** | 모든 차단/확인 규칙을 강제 적용 |\n\n### 4. 주요 차단·확인 규칙 예시\n```yaml\nactions:\n  destructive:\n    block:\n      - pattern: 'rm\\\\s+(-[a-zA-Z]*)?\\\\s*/'\n        reason: Filesystem root destruction\n      - pattern: 'mkfs\\\\.'\n        reason: Filesystem format\n    confirm:\n      - pattern: 'rm\\\\s+-r'\n        reason: Recursive delete\n  paths:\n    block:\n      - ~/.ssh/**\n      - /etc/shadow\n    readonly:\n      - /etc/passwd\n```\n- 위 규칙은 `default.yaml`에 기본 포함되어 있어 별도 코드 수정 없이 적용 가능하다.\n\n### 5. 설치 및 사용 흐름\n1. **바이너 다운로드** – GitHub Releases 페이지에서 플랫폼에 맞는 바이너를 다운로드한다.  \n   ```bash\n   chmod +x bodaiguard-linux-x64\n   sudo mv bodaiguard-linux-x64 /usr/local/bin/bodaiguard\n   ```\n2. **Claude 코드 훅 설치** (예시)  \n   ```bash\n   bodaiguard install hooks\n   ```\n3. **빠른 테스트**  \n   ```bash\n   bodaiguard test 'rm -rf /'   # → BLOCK: Filesystem root destruction\n   bodaiguard test 'ls -la'     # → ALLOW\n   ```\n4. **MCP 서버 래핑** – 모든 도구 호출을 `bodaiguard`를 통해 프록시한다.  \n   ```json\n   {\n     \"mcpServers\": {\n       \"my-tool\": {\n         \"command\": \"bodaiguard\",\n         \"args\": [\"mcp-proxy\", \"node\", \"/path/to/mcp-server.js\"]\n       }\n     }\n   }\n   ```\n5. **프롬프트‑인젝션 스캔**  \n   ```bash\n   bodaiguard scan 'Check encoded payloads'\n   # → Detects base64‑encoded attacks, hidden HTML, zero‑width obfuscation\n   ```\n\n### 6. 운영 시 권고\n- **샌드박스·최소 권한**: AI 코딩 에이전트는 제한된 컨테이너/VM에서 실행하고, 파일 시스템은 읽기 전용 루트와 제한된 쓰기 경로만 허용한다.  \n- **명령 허용 리스트**: `allowlist.yaml`에 안전한 명령만 명시하고, 모든 기타 명령은 차단하거나 확인 절차를 거치게 한다.  \n- **CI/CD 연동**: `bodaiguard test`를 테스트 파이프라인에 포함시켜 PR 단계에서 위험 명령 사용 여부를 자동 검증한다.  \n- **로그·감사**: 차단·확인 이벤트를 중앙 로그(예: CloudWatch, Elastic)로 전송하고, SIEM에서 알림을 설정한다.  \n- **정기 규칙 리뷰**: 새로운 공격 기법이 등장하면 `default.yaml`·`allowlist.yaml`을 업데이트하고, 버전 관리(Git)로 변경 이력을 관리한다.\n\n## Agent Testing Failures and Debugging Strategies\n> **출처**: [왜 Agent Testing이 깨졌는가 (EUNO.NEWS)](https://euno.news/posts/ko/why-agent-testing-is-broken-a07ad0)\n\n### 1. 문제의 본질\n- **계약 위반**: 전통적인 함수 테스트는 *같은 입력 → 같은 출력*을 보장한다. LLM 기반 에이전트는 모델 업데이트, 프롬프트 미세조정, 컨텍스트 변화 등에 따라 미묘하지만 의미론적으로 다른 출력을 생성한다.\n- **재현 불가**: 모델 자체가 바뀐 것이 아니라 프롬프트·컨텍스트·API 업데이트 등 외부 요인에 의해 동작이 변한다. `git bisect`와 같은 전통적 디버깅이 적용되지 않는다.\n- **테스트 공백**: 기존 단위·통합 테스트는 API 호출 성공 여부만 확인하고, 실제 출력 내용이 다운스트림 요구사항을 만족하는지는 검증하지 않는다.\n\n### 2. 행동 계약 기반 테스트 프레임워크\n| 단계 | 내용 |\n|------|------|\n| **베이스라인 캡처** | 정상 동작 중인 에이전트의 출력(구조·의미적 특성)을 기록한다. |\n| **포함 검사** | “반드시 포함돼야 할 키워드·섹션·구조”를 정의한다. 정확한 문자열이 아니라 의미적 앵커를 사용한다. |\n| **드리프트 감지** | 새 출력과 베이스라인을 유사도(예: cosine similarity)로 비교하고, 임계값 이하이면 빌드 실패 처리한다. |\n| **CI 통합** | 코드 푸시, 모델 버전 변경, 프롬프트 수정 시마다 자동 실행한다. 기존 유닛 테스트와 동일한 파이프라인에 포함한다. |\n\n### 3. 최소 실행 가능한 인터페이스 예시\n```yaml\n# scenarios/summarize_contract.yaml\nname: summarize_contract\ninput: |\n  Summarize this contract clause in 5 bullet points:\n  \"...The Contractor shall indemnify...termination upon 30 days notice...\"\nexpected_contains:\n  - liability\n  - termination\nmax_tokens: 512\n```\n\n```bash\nagentprobe run scenarios/ \\\n  --backend anthropic \\\n  --baseline baseline.json \\\n  --tolerance 0.8\n# 결과 예시\n✓ PASS  summarize_contract\n✗ FAIL  extract_parties\nDrift detected: similarity 0.61\n```\n*`agentprobe`는 경량 pytest‑like 도구이며, 드리프트가 감지되면 프로세스 종료 코드 1을 반환한다.*\n\n### 4. 도구·프레임워크 격차\n- 기존 RAG 평가 도구(RAGAS, LangSmith 등)는 **특정 프레임워크 종속**이거나 **RAG 품질에 초점**을 맞추고 있어, 행동 회귀 테스트에 바로 활용하기 어렵다.\n- 시장에서 요구되는 것은 **경량, 조합 가능, 로컬 실행 가능**한 에이전트 전용 테스트 프레임워크이다. 위 예시와 같은 YAML 기반 시나리오와 `agentprobe` 같은 CLI 도구가 그 역할을 수행한다.\n\n### 5. 실무 적용 권고\n1. **베이스라인 저장소**를 별도 버전 관리(Git) 하여, 모델·프롬프트 변경 시마다 스냅샷을 기록한다.  \n2. **포함 검사**를 비즈니스 규칙(예: “termination” 반드시 포함)과 연결해, 정책 파일에 선언한다.  \n3. **드리프트 임계값**은 서비스 위험도에 따라 조정하고, 임계값 초과 시 자동 롤백 또는 수동 검토 워크플로우를 트리거한다.  \n4. **CI 파이프라인**에 `agentprobe` 실행 단계를 추가하고, 실패 시 PR 머지를 차단한다.  \n5. **모니터링**: 배포 후에도 실시간 유사도 모니터링을 수행해, 운영 중 드리프트를 감지한다(예: Prometheus + Alertmanager).\n\n> 이러한 접근법은 **에이전트 테스트 파이프라인을 결정론적 함수 테스트와 동일한 수준의 신뢰성**으로 끌어올리며, 배포 실패 위험을 크게 감소시킨다.\n\n## 취약점 관리 및 패치 프로세스\n- **정기적인 코드·컨테이너 스캔** – Trivy, Snyk 등으로 이미지와 종속성을 주기적으로 스캔한다.  \n- **의존성 관리와 서드파티 라이브러리 업데이트** – Dependabot, Renovate Bot 등을 CI에 통합해 최신 버전을 자동 적용한다.  \n- **CVE 트래킹 및 긴급 패치 절차** – NVD, GitHub Advisory DB를 모니터링하고, 심각도 높은 CVE는 24시간 이내 패치한다.\n\n## 사고 대응 및 복구 계획\n- **AI 에이전트 전용 사고 대응 플레인** – 탐지 → 격리 → 원인 분석 → 복구 → 사후 검토 단계로 구성한다.  \n- **포렌식 수집 및 증거 보존 방법** – 로그, 메모리 덤프, 컨테이너 이미지 등을 안전하게 보관하고, 체인 오브 커스터디를 유지한다.  \n- **복구 시나리오와 복원 테스트** – 백업된 모델·컨테이너를 사용해 복구 연습을 정기적으로 수행한다.\n\n## 규정·표준·컴플라이언스 연계\n- **GDPR, HIPAA, ISO/IEC 27001** 등 개인정보·보건 데이터와 관련된 규제는 모델·데이터 암호화·접근 통제 요구사항을 충족해야 한다.  \n- **AI 윤리·투명성 가이드** – 모델 설명 가능성, 데이터 출처 투명성 등을 보안 정책에 포함한다.  \n- **감사 체크리스트와 문서화 요구사항** – 설계 문서, 위험 평가, 보안 테스트 결과 등을 문서화하고, 정기 리뷰를 수행한다.\n\n## 도구·플랫폼 베스트 프랙티스\n| 카테고리 | 도구/서비스 | 적용 포인트 |\n|----------|-------------|--------------|\n| 클라우드 보안 | AWS GuardDuty, Azure Sentinel | 실시간 위협 탐지·알림 |\n| 오픈소스 보안 | Trivy (이미지 스캔), OPA (정책 엔진), Falco (런타임 탐지) | CI/CD 파이프라인에 자동화 삽입 |\n| CI/CD 보안 자동화 | GitHub Actions, GitLab CI, Argo CD | 코드·컨테이너 스캔, 정책 검증 단계 추가 |\n| 비밀 관리 | AWS Secrets Manager, HashiCorp Vault | 모델·프롬프트 시크릿 안전하게 주입 |\n\n## 체크리스트·요약 가이드\n### 설계 단계\n- [ ] 최소 권한 원칙 적용 설계  \n- [ ] 모델 암호화·키 관리 설계  \n- [ ] 네트워크 세분화 및 TLS 적용 계획  \n\n### 구현 단계\n- [ ] 입력 검증 로직 구현  \n- [ ] OPA/Falco 정책 적용  \n- [ ] CI에 Trivy·Dependabot 연동  \n\n### 운영 단계\n- [ ] IAM 로그 실시간 수집·SIEM 연동  \n- [ ] 이상 탐지 알림 및 자동 격리 워크플로우 활성화  \n- [ ] 정기적인 취약점 스캔·패치 적용  \n\n## 참고 자료·링크\n- **ServiceNow AI 에이전트 소개** – AI 기반 워크플로우와 자율 행동 에이전트 개념[[ServiceNow 문서](https://www.servicenow.com/docs/ko-KR/bundle/zurich-platform-administration/page/administer/contextual-search/task/specify-field-copy-kb-article.html)]  \n- **AI 앱 개발 가이드 (위키독스)** – AI 애플리케이션 개발 전 단계와 테스트 흐름[[AI 앱 개발: 개념에서 생산까지](https://wikidocs.net/323763)]  \n- **AWS Well‑Architected 프레임워크** – 운영 우수성, 보안, 비용 최적화 원칙[[AWS Well‑Architected 프레임워크 PDF](https://docs.aws.amazon.com/ko_kr/wellarchitected/latest/framework/wellarchitected-framework.pdf)]  \n- **GPAI 위험 관리 프레임워크** – AI 시스템 위험 관리와 데이터 품질 검증[[GPAI 위험 관리 프레임워크 PDF](https://astlyi.s3.ap-northeast-2.amazonaws.com/2025/TTA_%E1%84%87%E1%85%A5%E1%86%B7%E1%84%8B%E1%85%AD%E1%86%BC+%E1%84%8B%E1%85%B5%E1%86%AB%E1%84%80%E1%85%A9%E1%86%BC%E1%84%8C%E1%85%B5%E1%84%82%E1%85%B3+(GPAI)+%E1%84%8B%E1%85%B1%E1%84%92%E1%85%A5%E1%86%B7+%E1%84%80%E1%85%AA%E1%86%AB%E1%84%85%E1%85%B5+%E1%84%91%E1%85%B3%E1%84%85%E1%85%A6%E1%84%8B%E1%85%B5%E1%86%B7%E1%84%8B%E1%85%AF%E1%84%8F%E1%85%B3.pdf)]  \n- **AI 코딩 에이전트 위험 방지** – BodAIGuard 프로젝트 및 적용 가이드[[EUNO.NEWS 기사](https://euno.news/posts/ko/your-ai-agent-just-ran-rm-rf-heres-how-to-stop-it-06b436)]  \n\n*본 문서는 현재 제공된 리서치 자료를 기반으로 작성되었습니다. 구체적인 구현 가이드나 최신 위협 상세 내용은 추가 조사가 필요합니다.*",
  "lastModified": "2026-02-28T18:06:35Z",
  "author": "SEPilot AI",
  "status": "published",
  "isDraft": false,
  "isInvalid": false,
  "tags": [
    "AI",
    "보안",
    "에이전트",
    "베스트프랙티스",
    "운영"
  ],
  "history": [
    {
      "sha": "c054f50",
      "message": "chore: 뉴스 인텔리전스 보고서 업데이트",
      "author": "GitHub Action",
      "authorEmail": "action@github.com",
      "date": "2026-02-28T18:06:35Z",
      "isAutoCommit": false,
      "additions": 0,
      "deletions": 0
    }
  ]
}