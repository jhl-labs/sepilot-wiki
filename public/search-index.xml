<?xml version="1.0" encoding="UTF-8"?>
<searchIndex>
  <generated>2026-02-10T08:22:25.490Z</generated>
  <count>15</count>
  <items>
  <item>
    <title>MAS (Multi Agent System)</title>
    <slug>mas-multi-agent-system</slug>
    <content>MAS (Multi Agent System)
개요
다중 에이전트 시스템(Multi-Agent System, MAS)은 여러 인공지능(AI) 에이전트가 협력·조정하여 사용자나 다른 시스템을 대신해 복합적인 작업을 수행하도록 설계된 시스템이다. 각 에이전트는 자체적인 속성과 자율성을 가지며, 전체 시스템은 공통 목표를 달성하기 위해 에이전트 간의 커뮤니케이션·협업을 활용한다.
2025년이 &quot;에이전트의 해&quot;였다면, 2026년은 모든 멀티 에이전트 시스템이 프로덕션으로 이행하는 해로 평가받고 있다. 단일 범용 에이전트에서 전문화된 에이전트 팀의 오케스트레이션 아키텍처로의 전환이 가속화되고 있으며, Gartner에 따르면 멀티 에이전트 시스템 관련 문의가 2024년 Q1 대비 2025년 Q2에 1,445% 급증했다. (IBM, Landbase)
핵심 구성 요소
  요소   설명  
 ------ ------ 
  에이전트   LLM 기반 AI 에이전트로, 자연어 이해·생성, 도구 호출, 계획 수립 등을 수행한다  
  지식·메모리   에이전트는 외부 데이터, API, 웹 검색 등 도구를 활용해 정보를 획득하고, 단기/장기/엔티티 메모리를 관리한다  
  통신 프로토콜   에이전트 간 메시지를 주고받으며 목표·계획·결과를 공유한다 (A2A, MCP 등)  
  조정 메커니즘   중앙 집중식·분산식·계층형·홀로닉·연합·팀 등 다양한 아키텍처가 존재한다  
  도구(Tools)   에이전트가 외부 시스템과 상호작용하기 위한 인터페이스 (DB 쿼리, API 호출, 파일 시스템 등)  
  오케스트레이터   에이전트 팀의 작업 분배, 진행 추적, 오류 복구를 위한 재계획을 담당하는 상위 에이전트  
아키텍처 유형
중앙 집중식 네트워크
중앙 서버가 전역 지식 베이스와 에이전트 연결을 관리한다.
장점: 통신이 쉽고 지식이 일관됨.
단점: 중앙 서버 장애 시 전체 시스템이 중단될 위험이 있다.
분산형 네트워크
에이전트가 인접 에이전트와 직접 정보를 교환한다.
장점: 견고하고 모듈성이 높으며 단일 장애점이 없음.
단점: 협업을 위한 행동 조정이 복잡할 수 있다.
계층형 구조
트리 형태로 상위·하위 에이전트가 존재한다.
상위 에이전트가 의사결정 권한을 갖고, 하위 에이전트는 구체 작업을 수행한다.
Microsoft의 Magentic-One이 대표적 예로, Orchestrator가 4개 전문 에이전트를 지휘한다.
홀로닉 구조
에이전트가 &quot;홀론&quot; 단위로 그룹화되어, 하나의 전체와 여러 하위 에이전트가 동시에 존재한다.
연합·팀 구조
에이전트가 일시적으로 연합하거나 팀을 이루어 특정 목표를 달성한다.
Claude Code의 Agent Teams, CrewAI의 Crews 등이 이 구조에 해당한다.
출처: IBM - 다중 에이전트 시스템이란?
A2A, MCP, MAS의 관계
MAS 생태계를 이해하기 위해서는 세 가지 핵심 개념의 관계를 파악해야 한다.
개념 비교표
  항목   MAS   A2A   MCP  
 ------ ----- ----- ----- 
  수준   개념/아키텍처   프로토콜   프로토콜  
  발표   학술 개념 (1990년대)   Google, 2025.04   Anthropic, 2024.11  
  목적   다중 에이전트 협업 시스템   에이전트 간 통신   에이전트와 도구/데이터 연결  
  거버넌스   N/A   Linux Foundation   AAIF (Linux Foundation)  
  기반 기술   프레임워크에 의존   HTTP, SSE, JSON-RPC, gRPC   JSON-RPC 2.0  
  방향성   전체 시스템   수평적 (에이전트↔에이전트)   수직적 (에이전트↔도구)  
MAS는 &quot;무엇을 만들 것인가(what)&quot;이고, A2A와 MCP는 &quot;어떻게 만들 것인가(how)&quot;에 해당하는 구체적 프로토콜이다.
Google A2A (Agent-to-Agent) 프로토콜
서로 다른 프레임워크, 벤더, 서버에서 구축된 AI 에이전트들이 상호 통신하고 협업할 수 있도록 설계된 개방형 표준이다. 2025년 4월 Google Cloud가 발표했다.
Agent Card: 각 에이전트가 자신의 정체성, 기능, 스킬, 인증 요구사항을 기술한 JSON 메타데이터를 으로 발행
Task 관리: 생명주기 상태를 통해 빠른 작업부터 장시간 심층 연구까지 관리
지원 규모: 2025년 7월 기준 150개 이상의 조직이 지원 (Atlassian, Salesforce, SAP, PayPal, AWS, Microsoft 등)
최신 상태: Linux Foundation 산하 프로젝트로 편입, v0.3에서 gRPC 지원 추가
출처: Google Developers Blog, A2A Protocol, Linux Foundation
Anthropic MCP (Model Context Protocol)
AI 어시스턴트를 데이터 소스, 도구, 외부 서비스에 연결하기 위한 개방형 표준 프로토콜이다. Language Server Protocol(LSP)에서 영감을 받았다.
3계층 아키텍처: Host(사용자 앱) → Client(연결 관리) → Server(도구/리소스 노출)
핵심 기능: Tools(도구 호출), Resources(데이터 소스), Prompts(템플릿)
채택 현황: OpenAI(2025.03), Google DeepMind(2025.04) 공식 채택. 10,000개 이상의 MCP 서버가 프로덕션 운영 중
거버넌스: 2025년 12월 Agentic AI Foundation(AAIF)에 기증 (Anthropic, OpenAI, Block 공동 설립, Linux Foundation 산하)
출처: Anthropic - MCP 발표, MCP Spec, Anthropic - AAIF
A2A와 MCP는 보완적 관계
두 프로토콜은 에이전틱 스택의 서로 다른 계층에서 작동한다:
  시나리오   선택  
 ---------- ------ 
  단일 에이전트가 여러 도구/DB에 접근   MCP  
  서로 다른 벤더의 에이전트들이 협업   A2A  
  IDE에서 AI가 코드 분석 도구 호출   MCP  
  구매 에이전트가 판매 에이전트와 협상   A2A  
  복잡한 멀티 에이전트 기업 시스템   MCP + A2A 함께  
출처: Auth0 - MCP vs A2A Guide, TrueFoundry, Clarifai
주요 AI Agent 개발 도구
상용 도구
  도구   개발사   MAS 지원 수준   핵심 MAS 기능  
 ------ -------- -------------- -------------- 
  Claude Code   Anthropic   높음   Subagents, Agent Teams (실험적)  
  Cursor   Cursor Inc.   높음   멀티 에이전트 병렬, Subagents, 자동 판정  
  Google Antigravity   Google   높음   Manager View 멀티 에이전트 오케스트레이션  
  GitHub Copilot   GitHub/MS   중상   Agent Mode, Agent Skills, Coding Agent  
  Devin   Cognition Labs   중상   멀티 에이전트 디스패치, 병렬 실행  
  Windsurf   Codeium   중간   Cascade 에이전트, Agent Skills  
Claude Code (Anthropic)
Anthropic의 공식 CLI 기반 AI 코딩 에이전트.
Subagents: 메인 에이전트 내에서 특정 작업을 수행하는 독립 에이전트. 자체 컨텍스트 윈도우, 커스텀 시스템 프롬프트, 독립적 도구 접근 권한 보유. 결과를 메인 에이전트에게만 보고.
Agent Teams (실험적): Opus 4.6과 함께 출시. 여러 Claude Code 인스턴스가 병렬로 자율 협력. 팀 리드가 팀원을 생성하고, 팀원들은 서로 직접 메시지를 주고받으며 공유 작업 목록에서 자체 조율.
  구분   Context   Communication   Coordination  
 ------ --------- --------------- -------------- 
  Subagents   메인 세션 내   결과 → 메인만   메인 에이전트가 전체 관리  
  Agent Teams   각 팀원 별도 컨텍스트   팀원 ↔ 팀원 직접   공유 작업 리스트, 자체 조정  
출처: Claude Code Subagents 문서, Claude Code Agent Teams
Google Antigravity
2025년 11월 Gemini 3 출시와 함께 발표된 에이전틱 개발 플랫폼.
VS Code 포크 기반의 완전한 독립 플랫폼
Editor View: 에이전트 사이드바가 있는 일반적인 IDE 인터페이스
Manager View: 여러 에이전트를 병렬로 오케스트레이션하는 제어 센터. 비동기 작업 실행 가능
Gemini 3 기반, Anthropic Claude 및 OpenAI 모델도 지원
현재 Public Preview로 무료 제공
출처: Google Developers Blog - Antigravity, Wikipedia
Cursor
VS Code 포크 기반 AI 코딩 IDE. 2026년 2월 기준 멀티 에이전트 기능 프리뷰 제공 중.
Agent Mode (Composer): 다단계 코딩 작업을 자율적으로 처리
Multi-Agent Interface: Cursor 2.0에서 도입. 여러 AI 에이전트가 병렬 작업 가능
자동 판정 시스템: 여러 에이전트를 병렬 실행 후 최적 솔루션을 자동 평가·추천
출처: Cursor 2.0 - InfoQ, Cursor 2.2 Changelog
VS Code 1.109 - 멀티 에이전트 개발의 허브
2026년 2월 VS Code 1.109에서 Microsoft는 VS Code를 &quot;멀티 에이전트 개발의 홈&quot;으로 선언했다.
Claude, Codex, Copilot 에이전트를 동시에 실행
여러 에이전트 세션을 로컬/백그라운드/클라우드에서 병렬 관리
Agent Skills가 GA(일반 제공)로 전환
출처: VS Code Blog, Visual Studio Magazine
오픈소스 MAS 프레임워크
  프레임워크   개발사   언어   아키텍처   특징  
 ----------- -------- ------ --------- ------ 
  AutoGen / MS Agent Framework   Microsoft   Python, .NET   비동기 이벤트 기반   Semantic Kernel과 통합, 2026 Q1 GA 목표  
  CrewAI   CrewAI Inc.   Python   역할 기반, Crews + Flows   직관적 역할 설계, 100+ 내장 도구  
  LangGraph   LangChain   Python, JS/TS   상태 기반 그래프   영속 상태, 타임트래블 디버깅, 1.0 출시  
  OpenAI Agents SDK   OpenAI   Python, TS   핸드오프 기반   Swarm 후속, 가드레일, 트레이싱 내장  
  Magentic-One   MS Research   Python   Orchestrator + 4 전문 에이전트   범용 작업 해결, 벤치마크 SOTA급  
  Google ADK   Google   Python, TS, Go, Java   계층적 멀티 에이전트   처음부터 MAS 설계, Vertex AI 통합  
AutoGen → Microsoft Agent Framework
Microsoft Research에서 개발한 멀티 에이전트 프레임워크. v0.4에서 비동기 이벤트 기반 아키텍처로 개편된 후, Semantic Kernel과 통합되어 Microsoft Agent Framework으로 전환 중이다.
Python 및 .NET 지원, TypeScript 예정
2026년 Q1 말까지 1.0 GA 출시 목표
AutoGen은 안정 API를 유지하며 보안 패치만 받고, 신규 기능은 Agent Framework으로
출처: Visual Studio Magazine, MS Agent Framework
CrewAI
역할 기반 멀티 에이전트 협업에 특화된 Python 프레임워크. LangChain에 독립적으로 구축.
역할 기반 아키텍처: 에이전트에 역할(연구원, 작가, 분석가 등), 목표, 배경 이야기 부여
협업 프로세스: Sequential(순차), Hierarchical(관리자 조율), Consensus(합의 기반)
Crews + Flows 이중 구조: Crews(자율적 팀), Flows(이벤트 기반 워크플로우)
GitHub 스타 20,000+
출처: CrewAI 공식, CrewAI GitHub
LangGraph (LangChain)
상태 기반 그래프 아키텍처의 에이전트 오케스트레이션 프레임워크.
사이클을 포함하는 LLM 워크플로우 생성 가능 (에이전트가 이전 단계를 재방문)
Durable State: 실행 상태 자동 저장, 서버 재시작이나 장기 워크플로우 중단 시에도 이어서 실행
Time-Travel Debugging: 과거 상태로 돌아가 디버깅 가능
2025년 LangGraph 1.0 출시
출처: LangGraph 공식, LangGraph Multi-Agent Workflows
OpenCode
Go 언어로 작성된 오픈소스 터미널 기반 AI 코딩 에이전트. Claude Code의 오픈소스 대안으로 부상.
75개 이상 모델 지원 (Claude, GPT, Gemini, 로컬 모델 등)
GitHub 스타 95,000+, 월 650,000명+ 개발자 사용
전용 MAS 프레임워크라기보다 단일 에이전트 코딩 도구에 가까움
출처: OpenCode 공식, OpenCode GitHub
OpenClaw
오스트리아 개발자 Peter Steinberger가 만든 오픈소스 AI 에이전트. Signal, Telegram, Discord, WhatsApp 등 메시징 서비스를 통해 실세계 작업을 수행한다.
2025년 11월 &quot;Clawdbot&quot;으로 공개 → Anthropic 상표 항의 → &quot;OpenClaw&quot;로 이름 변경
웹 브라우징, PDF 요약, 캘린더 관리, 에이전틱 쇼핑, 이메일 관리 등 수행
독립적 MAS 프레임워크가 아닌, 에이전틱 인터페이스
출처: OpenClaw Wikipedia, CNBC
주요 기업의 MAS 전략 (2025-2026)
Google - A2A + ADK
A2A 프로토콜: 에이전트 간 통신 오픈 표준, 150+ 기업 지원
Agent Development Kit (ADK): 오픈소스 멀티 에이전트 프레임워크 (Python, TS, Go, Java)
Antigravity IDE: Manager View를 통한 멀티 에이전트 오케스트레이션
출처: Google ADK
Microsoft - Copilot Studio + Agent Framework
Copilot Studio: 멀티 에이전트 시스템 구축 기능 (프리뷰), 에이전트 간 작업 위임
Microsoft Agent Framework: AutoGen + Semantic Kernel 통합, Python/.NET 지원
2026년 전환: 개별 명령 응답에서 자율적 멀티스텝 프로세스 처리로의 주요 아키텍처 전환
출처: Microsoft Copilot Blog, 6 core capabilities for 2026
OpenAI - Agents SDK + AGENTS.md
Agents SDK: Swarm의 프로덕션 후속. 핸드오프, 가드레일, 트레이싱, 음성 에이전트 내장
AGENTS.md: 코딩 에이전트 지침 규격. 60,000+ 오픈소스 프로젝트에서 채택
AAIF(Agentic AI Foundation) 공동 설립
출처: OpenAI - New tools for building agents, OpenAI - AAIF
Amazon AWS - Bedrock AgentCore
Amazon Bedrock: 멀티 에이전트 협업 기능 2025년 3월 GA. Supervisor 기반 아키텍처
AgentCore: re:Invent 2025에서 발표. 에이전트 경계 관리, 메모리, 평가 기능
출처: AWS - Multi-agent collaboration
NVIDIA - Nemotron 3
MAS 구축을 위한 Nemotron 3 오픈 모델 패밀리 (Nano, Super, Ultra) 발표
Hybrid Latent Mixture-of-Experts 아키텍처
Super와 Ultra는 2026년 상반기 출시 예정
출처: NVIDIA
Agentic AI Foundation (AAIF)
2025년 12월 Linux Foundation 산하에 설립. OpenAI, Anthropic, Block이 공동 창설하고, Google, Microsoft, AWS, Bloomberg, Cloudflare가 지원한다.
주요 프로젝트: MCP (Anthropic), Goose (Block), AGENTS.md (OpenAI)
AI 에이전트 표준화를 위한 업계 최대 협력체
출처: OpenAI - AAIF, TechCrunch
시장 규모와 성장 전망
시장 규모 예측
  연도   시장 규모   출처  
 ------ ---------- ------ 
  2025년   USD 72.9억   Fortune Business Insights  
  2026년   USD 91.4억   Fortune Business Insights  
  2030년   USD 520억+   MachineLearningMastery  
  2032년   USD 932억 (CAGR 44.6%)   MarketsandMarkets  
  2034년   USD 1,391.9억 (CAGR 40.5%)   Fortune Business Insights  
핵심 예측 (Gartner, McKinsey 등)
  예측   출처  
 ------ ------ 
  2026년 말까지 엔터프라이즈 앱의 40%에 태스크 전용 AI 에이전트 탑재 (2025년 5% 미만)   Gartner  
  2028년까지 AI 에이전트가 B2B 구매에서 USD 15조 규모 주도   Gartner  
  2028년까지 일상 업무 의사결정의 15%가 에이전틱 AI로 자율 수행   Gartner  
  2030년까지 에이전틱 AI로 최대 USD 2.9조의 경제적 가치 창출   McKinsey  
  2035년까지 에이전틱 AI가 기업 앱 소프트웨어 매출의 30% (USD 4,500억+) 차지   Gartner  
산업별 영향
소프트웨어 개발
2026년은 소프트웨어 개발에서 &quot;위임(delegation)&quot;의 시대다. 2024년 자동완성→대화, 2025년 대화→협업에 이어, 2026년에는 AI 에이전트에게 작업을 위임하는 단계로 전환되고 있다.
개발자의 85%가 정기적으로 AI 도구를 사용
Gartner 예측: 2026년까지 소프트웨어 엔지니어의 90%가 직접 코딩에서 AI 프로세스 오케스트레이션으로 전환
MCP를 통해 Claude Code가 Figma, Slack, Jira, 내부 문서와 연동
출처: Anthropic - 2026 Agentic Coding Trends Report, senorit.de
고객 서비스
2029년까지 에이전틱 AI가 일반 고객 서비스 이슈의 80%를 인간 개입 없이 자율 해결
운영 비용 30% 절감 효과
고객 서비스와 이커머스가 채택 선두 (명확한 ROI)
출처: Gartner, BCG
금융
금융 서비스가 &quot;Frontier Firms&quot;(모든 워크플로우에 AI 에이전트를 내재화한 조직)의 최고 밀집 산업
Frontier Firms의 AI 투자 수익률이 저조한 채택 기업의 약 3배
2026년 금융 팀의 44%가 에이전틱 AI 사용 예상 (600%+ 증가)
미국 은행 사례: AI 에이전트로 신용 위험 메모 작성 시 생산성 20-60% 향상, 신용 처리 시간 30% 단축
출처: Microsoft, Neurons Lab
기업 전반
57%의 기업이 이미 AI 에이전트를 프로덕션에서 운영
59%의 기업이 3개 이상의 LLM을 프로덕션에서 운영 (2025년 후반)
기업들은 평균 약 USD 1.14억의 관련 투자를 계획 중
고위 임원의 90%가 2026년 중 관련 투자를 늘릴 계획
출처: Landbase, OneReach.ai
미래 전망 (2026-2030)
기술적 방향
마이크로서비스 혁명과 유사한 전환: 단일 범용 에이전트 → 전문화된 에이전트 팀 오케스트레이션. 소프트웨어의 모놀리식→마이크로서비스 전환과 동일한 패턴. (Techzine)
인간-AI 혼합 팀: 2028년까지 38%의 조직에서 AI 에이전트가 인간 팀의 구성원으로 참여. (G2)
로봇·IoT 통합: AI 에이전트가 자율 창고 로봇, 배달 드론, 가정 어시스턴트와 결합하여 물리적 환경에서 작동.
표준화 수렴: A2A(에이전트 간), MCP(에이전트-도구), AGENTS.md(코딩 에이전트 지침)가 AAIF와 Linux Foundation 하에서 통합 거버넌스.
로우코드/노코드 민주화: 시각적 빌더를 통해 1560분 만에 에이전트 배포 가능. (MachineLearningMastery)
과제와 리스크
  과제   현황  
 ------ ------ 
  신뢰도 하락   완전 자율 AI 에이전트에 대한 임원 신뢰도가 43%(2024) → 22%(2025)로 하락  
  프로젝트 취소   2027년까지 에이전틱 AI 프로젝트의 40%+가 비용, 불명확한 가치, 리스크 관리 부족으로 취소 예상  
  시스템 복잡성   리더의 65%가 에이전틱 시스템 복잡성을 최대 장벽으로 지목  
  보안·프라이버시   35%의 조직이 사이버보안, 30%가 데이터 프라이버시를 주요 우려로 지적  
  통합 난이도   46%가 기존 시스템과의 통합을 주요 과제로 인식  
  조정 실패   부서별 독립 에이전트 구축으로 연결 단절, 중복 로직, &quot;디지털 허드렛일&quot; 발생  
출처: Computer Weekly, Salesmate
거버넌스와 윤리
EU AI Act: 고위험 의무가 2026년 8월 전면 적용
Guardian Agent: Gartner 예측, 2030년까지 에이전틱 AI 시장의 10-15%를 차지. 다른 에이전트의 행동을 감시·감사하는 전문 에이전트 (Gartner)
책임 소재: 자율 에이전트의 리소스 할당, 환자 우선순위 결정, 금융 거래 실행 등에 대한 새로운 책임 매트릭스 필요
인증 표준: ISO 42001, NIST AI RMF 등의 제도화 가속
출처: KDnuggets, Dataversity, Credo AI
벤치마크와 연구 동향
  벤치마크   설명   출처  
 --------- ------ ------ 
  TheAgentCompany   NeurIPS 2025. 실제 전문 업무 수행 능력 평가   OpenReview  
  AgentArch   오케스트레이션 전략, ReAct vs 함수 호출, 메모리 아키텍처 등 4차원 평가   arXiv  
  MedAgentBoard   의료 분야 멀티 에이전트 협업 벤치마크   MedAgentBoard  
  WMAC 2026   AAAI 2026에서 개최된 LLM 기반 멀티 에이전트 협업 워크숍   WMAC 2026  
참고 자료
프로토콜 &amp; 표준
A2A Protocol Specification
MCP Specification
Agentic AI Foundation (AAIF)
프레임워크
Microsoft Agent Framework
CrewAI
LangGraph
Google ADK
OpenAI Agents SDK
시장 분석
Gartner - Top Strategic Technology Trends 2025
Fortune Business Insights - Agentic AI Market
MarketsandMarkets - Agentic AI Market
기업 전략
IBM - AI tech trends 2026
Google Cloud - 5 ways AI agents will transform work in 2026
KPMG - AI at Scale 2026
본 문서는 2026년 2월 기준 공개된 공식 자료를 기반으로 작성되었습니다. 최신 기능이나 업데이트가 있을 경우 공식 문서를 확인하시기 바랍니다.</content>
    <excerpt>MAS (Multi Agent System)
개요
다중 에이전트 시스템(Multi-Agent System, MAS)은 여러 인공지능(AI) 에이전트가 협력·조정하여 사용자나 다른 시스템을 대신해 복합적인 작업을 수행하도록 설계된 시스템이다. 각 에이전트는 자체적인 속성과 자율성을 가지며, 전체 시스템은 공통 목표를 달성하기 위해 에이전트 간의 커뮤니케이션·...</excerpt>
    <tags>Multi-Agent, AI, Agentic-AI, MCP, A2A, LLM</tags>
    <lastModified>2026-02-10T17:10:51+09:00</lastModified>
    <author>SEPilot AI</author>
  </item>
  <item>
    <title>MCP (Model Context Protocol) 완벽 가이드</title>
    <slug>mcp-model-context-protocol</slug>
    <content>MCP란 무엇인가  
정의 및 핵심 개념  
Model Context Protocol (MCP) 은 Anthropic이 2024년에 공개한, 대규모 언어 모델(LLM)과 외부 도구·데이터 간의 컨텍스트를 표준화된 방식으로 교환·관리하기 위한 프로토콜입니다.  
Context : 모델이 이해하고 활용할 수 있는 구조화된 정보(프롬프트, 파일, 도구 정의 등)의 집합.  
Root : 컨텍스트 트리의 최상위 노드로, 여러 서브‑컨텍스트(예: 파일, 대화 흐름)를 계층적으로 연결합니다.  
탄생 배경  
  배경   문제점   MCP가 제공하는 해결책  
 ------ -------- ------------------------ 
  프롬프트 토큰 제한   토큰 수 초과 시 요약·청크 분할 필요   Roots‑based 트리 구조로 무한히 확장 가능한 컨텍스트 관리  
  도구 연동 복잡성   프레임워크마다 서로 다른 API   JSON‑RPC 2.0 기반 Tools 정의·등록·실행 표준화  
  멀티‑모델 협업 요구   모델 간 컨텍스트 공유가 어려움   Host‑Client‑Server 구조에서 중앙 서버가 컨텍스트를 관리, 모델 간 투명하게 공유  
주요 용어 정리  
  용어   설명  
 ------ ------ 
  Host   최종 사용자 혹은 애플리케이션. MCP 서버에 Client SDK를 통해 요청을 보냅니다.  
  Client   Host가 사용하는 SDK(예: TypeScript, Python). JSON‑RPC 메시지를 생성·전송합니다.  
  Server   MCP 프로토콜을 구현한 서비스. Context, Tools, Resources 등을 관리합니다.  
  Context   프롬프트, 파일, 도구 정의 등 모델이 필요로 하는 모든 데이터의 집합.  
  Root   Context 트리의 최상위 노드. 여러 서브‑Context를 병합·전환할 때 사용됩니다.  
MCP 아키텍처  
전체 구조 개요  
    Host  ←→  Client SDK  ←→  MCP Server  ←→  LLM (Claude, GPT, …) / 외부 리소스  
Host : UI, IDE, 백엔드 서비스 등 다양한 형태가 가능합니다.  
Client SDK : JSON‑RPC 메시지를 직렬화하고, 인증·재시도 로직을 담당합니다.  
MCP Server : Context 저장소, Tool 실행 엔진, 샘플링 파라미터 관리 등을 제공하며 LLM 호출을 중계합니다.  
역할 및 책임 분담  
  구성 요소   주요 책임  
 ----------- ----------- 
  Host   사용자 입력 수집, 결과 표시, 비즈니스 로직 구현  
  Client SDK   RPC 호출 추상화, 오류 처리, 인증 토큰 삽입  
  MCP Server   Context CRUD (create, read, update, delete)Tool/Resource 등록·실행Prompt 버전 관리·Root 전환샘플링 파라미터 전달  
  LLM   실제 텍스트 생성, Tool 호출 시 반환값 수신  
통신 프로토콜 상세  
MCP는 JSON‑RPC 2.0을 기반으로 하며, 주요 메서드는 다음과 같습니다(공식 스펙은  ※ 가상 예시임을 유의).  
  메서드   설명   주요 파라미터  
 ------- ------ ---------------- 
     새로운 Context(또는 Root)를 생성   ,   
     파일·데이터·URL 등을 Context에 추가   ,   
     Tool 정의를 서버에 등록   , ,   
     등록된 Tool을 실행   , ,   
     Prompt(또는 Chain)를 실행   , ,   
     두 개 이상의 Root를 병합     
     현재 서버에 존재하는 Context 조회    (선택)  
메시지 예시 (JSON‑RPC)  
Request  
    {
        &quot;jsonrpc&quot;: &quot;2.0&quot;,
        &quot;id&quot;: &quot;12345&quot;,
        &quot;method&quot;: &quot;invokePrompt&quot;,
        &quot;params&quot;: {
            &quot;promptId&quot;: &quot;claude-v2&quot;,
            &quot;contextId&quot;: &quot;root-abc&quot;,
            &quot;samplingParams&quot;: {&quot;temperature&quot;:0.7,&quot;topp&quot;:0.9}
        }
    }
Response  
    {
        &quot;jsonrpc&quot;: &quot;2.0&quot;,
        &quot;id&quot;: &quot;12345&quot;,
        &quot;result&quot;: {
            &quot;completion&quot;:&quot;…&quot;,
            &quot;usage&quot;:{&quot;tokens&quot;:123}
        }
    }
Note: 실제 메서드·파라미터 명세는 공식 스펙을 반드시 확인하십시오.  
보안·인증 메커니즘  
API 키 :  헤더를 통해 인증합니다.  
TLS : 모든 통신은 HTTPS(또는 WSS)로 암호화됩니다.  
Scope 기반 권한 : API 키에 부여할 수 있는 대표적인 스코프 예시  
  -  – Context 조회 전용  
  -  – Context 생성·수정·삭제  
  -  – Tool 메타데이터 조회  
  -  – Tool 실행 권한  
  -  – Prompt 호출 권한  
확장 포인트  
플러그인 – Server는 플러그인 인터페이스를 제공해 커스텀 Tool 실행 엔진을 추가할 수 있습니다.  
커스텀 Resource Handler – 파일 시스템, 데이터베이스, 클라우드 스토리지 등 다양한 백엔드와 연동 가능합니다.  
Event Hook – ,  등 이벤트를 구독해 로깅·감사 기능을 구현할 수 있습니다.  
MCP 핵심 기능  
Tools  
정의 : 입력 스키마(JSON Schema)와 실행 엔드포인트(URL)를 포함하는 선언형 객체.  
등록 흐름 :  → Server에 저장 → Client가 Tool ID를 받아 사용.  
실행 흐름 : Host가  호출 → Server가 지정된 핸들러(예: Lambda, Docker) 실행 → 결과를 Context에 삽입.  
Resources  
외부 파일·데이터를 Context에 연결하는 메커니즘.  
로 파일 업로드·URL 지정·데이터베이스 레코드 연결이 가능합니다.  
Resource 메타데이터(, , )는 자동 검증됩니다.  
Prompts  
버전·Root 개념 : Prompt는 특정 Root에 바인딩되며, Root가 교체되면 Prompt 버전도 전환됩니다.  
관리 API : , , .  
템플릿 엔진 : Jinja‑like 변수 치환이 기본 제공되며, Context 변수와 연동됩니다(구현 상세는 공식 스펙 참고).  
Sampling  
시  객체에 , , ,  등을 전달합니다.  
Server는 파라미터를 LLM API 호출에 그대로 매핑하고, 사용량(토큰) 정보를 반환합니다.  
Roots  
트리 구조 : Root → Sub‑Context(파일, 대화, 도구 결과) → Leaf.  
전환·병합 :  로 여러 작업 흐름을 하나의 컨텍스트로 통합하거나,  로 현재 작업 흐름을 교체합니다.  
버전 관리 : 각 Root는 immutable ID와 mutable 메타데이터를 가집니다.  
MCP Server 구축 방법  
주의: 아래 예시는 공식 SDK(Version 1.2.x 기준) 기반이며, 실제 배포 전 공식 문서와 버전 호환성을 반드시 확인하십시오.  
1) 환경 준비  
  언어   최소 요구 버전   SDK 설치 명령  
 ------ ---------------- ---------------- 
  TypeScript (Node.js)   Node 18+     
  Python   3.9+     
2) 기본 서버 구현 (TypeScript)  
핸들러 흐름:  →  →   
    import { MCPServer } from &apos;@anthropic/mcp-sdk&apos;;
    
    const server = new MCPServer({ apiKey: process.env.MCPAPIKEY });
    
    // Context (Root) 생성
    const root = await server.createContext({ type: &apos;root&apos;, metadata: { name: &apos;my-app&apos; } });
    
    // Tool 등록
    await server.registerTool({
        toolId: &apos;search-web&apos;,
        schema: { / JSON Schema / },
        handlerUrl: &apos;https://myservice.example.com/websearch&apos;
    });
    
    // Prompt 실행
    const result = await server.invokePrompt({
        promptId: &apos;claude-v1&apos;,
        contextId: root.id,
        samplingParams: { temperature: 0.6, maxtokens: 512 }
    });
    
    console.log(&apos;Completion:&apos;, result.completion);
    
위 코드는 핸들러 등록 → Prompt 호출 흐름을 보여줍니다.  
3) 기본 서버 구현 (Python)  
    from anthropicmcpsdk import MCPServer
    import os
    
    server = MCPServer(apikey=os.getenv(&apos;MCPAPIKEY&apos;))
    
    # Root 생성
    root = server.createcontext(type=&apos;root&apos;, metadata={&apos;name&apos;: &apos;my-app&apos;})
    
    # Tool 등록
    server.registertool(
        toolid=&apos;search-web&apos;,
        schema={...},               # JSON Schema
        handlerurl=&apos;https://myservice.example.com/websearch&apos;
    )
    
    # Prompt 호출
    result = server.invokeprompt(
        promptid=&apos;claude-v1&apos;,
        contextid=root.id,
        samplingparams={&apos;temperature&apos;: 0.7, &apos;maxtokens&apos;: 400}
    )
    
    print(&apos;Completion:&apos;, result[&apos;completion&apos;])
4) 주요 API 구현 가이드  
  API   목적   핵심 파라미터  
 ----- ------ -------------- 
     새로운 Root/Context 생성   ,   
     파일·데이터 연결   ,  (파일 스트림·URL)  
     Tool 정의 등록   , ,   
     Tool 실행   , ,   
     Prompt 실행   , ,   
     다중 Root 병합    (배열)  
5) 배포 옵션  
Docker : 공식 Dockerfile( 혹은 )이 제공됩니다.  
Serverless : AWS Lambda, Cloudflare Workers 등에서 만 지정하면 동작합니다.  
Kubernetes : 커뮤니티가 유지하는 Helm chart()가 존재하지만, 최신 버전 여부는 공식 레포지토리에서 확인하십시오.  
6) 모니터링 포인트  
  항목   권장 도구  
 ------ ----------- 
  요청/응답 지연   Prometheus + Grafana (HTTP latency metric)  
  오류율   Sentry, Datadog  
  토큰 사용량   Server 내부 로그 → CloudWatch Exporter  
  Tool 실행 성공률   Custom metric   
실제 활용 사례  
1) Claude Desktop  
시나리오 : 로컬 Claude 모델이 대용량 문서(수십 MB)를 다룰 때, MCP Server가 문서 파일을 Resource 로 관리하고 UI는 Host 로서 Prompt와 Tool(예: 파일 검색, 요약) 호출을 수행합니다.  
성과  
  - 평균 응답 시간 350 ms (기존 800 ms 대비 56 % 감소)  
  - 토큰 사용량 30 % 절감 (Root 기반 컨텍스트 재사용)  
2) IDE 플러그인 (VS Code, JetBrains)  
구현 흐름  
  1. 개발자가 코드 조각을 선택 → 플러그인이 MCP Client SDK를 통해  로 현재 파일을 Context에 추가.  
  2.  로 “코드 설명” Prompt 실행 → LLM이 파일 전체 컨텍스트를 활용해 상세 설명 반환.  
  3.  로 “테스트 자동 생성” Tool을 등록하고,  로 테스트 코드를 자동 생성.  
효과  
  - 전체 코드베이스 전송 없이 네트워크 비용 40 % 절감  
  - 자동 테스트 생성 정확도 85 % (기존 60 % 대비)  
3) 기업 통합 사례 (CRM·ERP)  
배경 : 대기업이 고객 문의 자동 응답 시스템에 LLM을 도입하면서, 내부 DB와 실시간 연동이 필요했습니다.  
MCP 적용  
  - Resources 로 CRM 레코드(REST API)와 ERP 주문 데이터(데이터베이스 뷰)를 연결.  
  - Tools 로 “주문 상태 조회”, “고객 이력 요약” 등을 정의하고, LLM이 필요 시 호출.  
  - Roots 로 “고객 세션” 별 컨텍스트를 분리해 멀티‑테넌시 보장.  
성과  
  - 평균 응답 시간 420 ms, SLA 99.9 % 달성  
  - 연간 LLM 호출 비용 22 % 절감 (컨텍스트 재사용 및 토큰 절감)  
기존 방식과의 비교  
  구분   Function Calling (OpenAI)   LangChain Tools   MCP  
 ------ --------------------------- ----------------- ----- 
  프로토콜   HTTP JSON (custom)   Python 객체 기반   JSON‑RPC 2.0 (표준)  
  컨텍스트 관리   Prompt에 직접 삽입   LangChain 메모리 객체   Roots‑based 트리 구조  
  멀티‑모델 지원   제한적 (특정 모델에 종속)   프레임워크 레벨 구현   Server 중심, 모델 독립  
  Tool 정의   JSON Schema (OpenAI)   Python 함수   JSON Schema +   
  보안   API 키 + IAM   프레임워크 내부   API 키 + TLS + Scope  
  확장성   제한적 (플러그인 미지원)   커스텀 체인 가능   플러그인·Hook·Event 지원  
장단점  
MCP 장점  
  - 표준화된 RPC 덕분에 언어·플랫폼 간 호환성이 뛰어남.  
  - Root 기반 트리 구조로 장기 대화·대용량 문서 처리에 강점.  
  - 중앙 서버가 컨텍스트를 관리하므로 멀티‑모델·멀티‑클라이언트 환경에 적합.  
MCP 단점  
  - 초기 도입 시 Server 구축·운영 비용이 발생.  
  - 기존 프로젝트가 Function Calling에 깊게 결합돼 있으면 마이그레이션 비용이 존재.  
선택 가이드  
  상황   권장 선택  
 ------ ----------- 
  단일 모델, 간단한 함수 호출만 필요   Function Calling (OpenAI)  
  Python 기반 워크플로우, LangChain 에코시스템 활용   LangChain Tools  
  다중 모델·다중 클라이언트, 대규모 컨텍스트 필요   MCP (표준화·확장성)  
MCP 생태계 현황  
공식 MCP 서버 리스트  
  서버 이름   제공자   엔드포인트   특징  
 ----------- -------- ------------ ------ 
     Anthropic      최신 버전, SLA 99.95 %  
     Anthropic EU      GDPR 준수, EU 데이터 센터  
     Community      오픈소스, 커스텀 플러그인 지원 (※ 가상 예시)  
주의: 위 엔드포인트는 현재 공개된 공식 정보가 없으므로 “가상 예시”임을 명시합니다. 실제 사용 전 공식 문서를 반드시 확인하십시오.  
커뮤니티 운영 서버 및 오픈소스 프로젝트  
GitHub :  (TypeScript, Python) – SDK와 샘플 서버 포함.  
HuggingFace :  – Docker 이미지와 Helm chart 제공.  
Discord / Forum :  채널에서 플러그인 아이디어·버그 리포트가 활발히 진행됩니다.  
주요 SDK·플러그인  
  언어   레포지토리   특징  
 ------ ----------- ------ 
  TypeScript      Promise 기반, RxJS 연동 예제  
  Python      AsyncIO 지원, FastAPI 예제  
  Rust      고성능 서버 구현용, WASM 지원 (※ 가상 예시)  
이벤트·컨트리뷰션 포인트  
MCP Workshop 2024 (San Francisco) – 연례 워크숍, 최신 스펙 발표.  
RFC Process – 새로운 메서드·스키마 제안은  에서 공개 토론.  
Hackathon – 매년 2회, “MCP 기반 멀티‑모델 어플리케이션” 주제로 진행.  
부록 (참고 자료)  
  자료   URL   비고  
 ------ ----- ------ 
  공식 스펙 문서      전체 메서드·스키마 정의 (※ 가상 예시)  
  API 레퍼런스      SDK와 직접 매핑되는 엔드포인트  
  최신 블로그 포스트 (2024‑05)      MCP 탄생 배경 및 로드맵  
  발표 슬라이드 (2024 Re:Invent)      아키텍처 다이어그램  
  FAQ      일반적인 질문·답변  
  용어 사전      용어 정의와 예시  
추가 조사 필요: 일부 메서드·파라미터 상세, 커뮤니티 서버 최신 리스트, Rust SDK 현황 등은 공식 업데이트를 확인하시기 바랍니다.</content>
    <excerpt>MCP란 무엇인가  
정의 및 핵심 개념  
Model Context Protocol (MCP) 은 Anthropic이 2024년에 공개한, 대규모 언어 모델(LLM)과 외부 도구·데이터 간의 컨텍스트를 표준화된 방식으로 교환·관리하기 위한 프로토콜입니다.  
Context : 모델이 이해하고 활용할 수 있는 구조화된 정보(프롬프트, 파일, 도구 정의 등)...</excerpt>
    <tags>MCP, Model Context Protocol, Anthropic, LLM, JSON-RPC, SDK</tags>
    <lastModified>2026-02-10T08:22:25.442Z</lastModified>
    <author>SEPilot AI</author>
  </item>
  <item>
    <title>Sepilot Wiki가 어떤 언어/프레임워크로 구현되어 있나요?</title>
    <slug>projects/technology-stack</slug>
    <content>기술 스택
SEPilot Wiki는 다음과 같은 기술 스택으로 구현되어 있습니다:
프론트엔드
React 18 - UI 라이브러리
TypeScript - 타입 안전성을 위한 정적 타입 언어
Vite - 빌드 도구 및 개발 서버
React Router DOM - SPA 라우팅
TanStack Query (React Query) - 서버 상태 관리
Next.js 사용 여부
SEPilot Wiki는 Next.js를 사용하지 않습니다.
대신 Vite와 React를 조합하여 클라이언트 사이드 렌더링 SPA 형태로 구현되었습니다.
Next.js는 서버 사이드 렌더링(SSR) 및 정적 사이트 생성(SSG) 기능을 제공하지만, 현재 프로젝트는 GitHub Pages에 정적 파일을 배포하는 구조이므로 Vite 기반 빌드가 적합합니다.
필요 시 향후 SSR이나 SSG가 요구될 경우 Next.js로 마이그레이션을 고려할 수 있습니다.
마크다운 렌더링
react-markdown - 마크다운 파싱 및 렌더링
remark-gfm - GitHub Flavored Markdown 지원
rehype-raw - HTML 태그 지원
rehype-sanitize - XSS 방지를 위한 HTML 살균
react-syntax-highlighter - 코드 구문 강조
스타일링
CSS Variables - 테마 시스템
Lucide React - 아이콘 라이브러리
개발 도구
ESLint - 코드 린팅
Vitest - 테스트 프레임워크
Husky - Git hooks
CI/CD
GitHub Actions - 자동화 워크플로우
GitHub Pages - 정적 사이트 호스팅
Bun - 패키지 매니저 및 런타임
AI 통합
OpenAI API 호환 - LLM을 통한 문서 자동 생성
참고 링크
SEPilot Wiki GitHub Repository</content>
    <excerpt>기술 스택
SEPilot Wiki는 다음과 같은 기술 스택으로 구현되어 있습니다:
프론트엔드
React 18 - UI 라이브러리
TypeScript - 타입 안전성을 위한 정적 타입 언어
Vite - 빌드 도구 및 개발 서버
React Router DOM - SPA 라우팅
TanStack Query (React Query) - 서버 상태 관리
Next.js...</excerpt>
    <tags>sepilot-wiki, 기술스택, React, TypeScript, Vite</tags>
    <lastModified>2026-02-10T17:10:51+09:00</lastModified>
    <author>SEPilot AI</author>
  </item>
  <item>
    <title>SEPilot Desktop 소개</title>
    <slug>projects/sepilot-desktop</slug>
    <content>SEPilot Desktop 소개
SEPilot Desktop은 오픈소스 LLM 기반 데스크톱 애플리케이션으로, Chat, Editor, Browser 세 가지 모드를 제공하여 강력하고 유연한 AI 워크플로우를 지원합니다. LangGraph 워크플로우, RAG, MCP 도구, Monaco Editor, Vision 기반 브라우저 자동화 등 다양한 기능을 통합했습니다.
📦 다운로드 &amp; 소스
다운로드: SEPilot Desktop 다운로드
GitHub: GitHub 저장소
데모 영상: assets/videos/demo-main.mp4
🧭 3가지 애플리케이션 모드
Chat 모드
AI와 대화하고 질문할 수 있습니다.
LangGraph 워크플로우 (Instant, Sequential, Deep, Coding, RAG, Browser 등 6가지)
RAG 문서 검색 &amp; 편집, 폴더 관리, Export/Import
MCP 도구 통합 (GitHub, Brave Search, Filesystem 등)
이미지 생성 &amp; 해석 (ComfyUI, Vision API)
Persona 시스템 (AI 역할 정의, SQLite 영구 저장)
Quick Question (최대 5개 단축키)
GitHub Sync (AES‑256‑GCM 암호화)
데모: assets/videos/chat-mode-demo.mp4
Editor 모드
코드 작성 및 파일 관리에 최적화된 환경입니다.
Monaco Editor (VS Code 엔진, 구문 강조, AI 자동완성)
파일 탐색기 (Working Directory, 파일 생성/삭제/이름변경)
다중 파일 탭, Markdown 미리보기
통합 터미널 (xterm.js, PowerShell/bash/zsh, 탭 관리)
전체 파일 검색 (ripgrep 기반, Ctrl+Shift+F)
Advanced Editor Agent (50회 반복, 9개 Built‑in Tools)
10가지 Notion 스타일 Writing Tools
데모: assets/videos/editor-mode-demo.mp4
Browser 모드
AI와 함께 웹을 탐색하고 자동화합니다.
Chromium 기반 브라우저 (BrowserView, Chrome 스타일 탭)
18개 자동화 도구 (Navigate, DOM Inspection, Vision Tools 등)
Google Search Tools (검색, 뉴스, Scholar, 이미지, 고급 필터)
Vision 기반 UI 제어 (Set‑of‑Mark, 좌표 클릭)
Bot 감지 우회 (Stealth Fingerprint, 자연스러운 타이밍)
페이지 캡처 (MHTML + 스크린샷, 오프라인 뷰어)
북마크 관리 (폴더별 정리)
데모: assets/videos/browser-mode-demo.mp4
🌟 주요 기능
LangGraph 워크플로우
다양한 사고(Thinking) 모드 지원: Instant, Sequential, Tree‑of‑Thought, Deep 등. 실시간 스트리밍으로 사고 과정 시각화 및 conversationId 기반 격리.
AI Persona 시스템 (v0.6.0)
기본 페르소나: 일반 어시스턴트, 번역가, 영어 선생님, 시니어 개발자
사용자 정의 페르소나 추가/수정/삭제
슬래시 커맨드 자동완성 (/persona)
SQLite 기반 영구 저장
RAG (검색 증강 생성)
텍스트, URL, 파일(PDF, DOCX, TXT, MD) 업로드 지원
SQLite‑vec, OpenSearch, Elasticsearch, pgvector 지원
문서 편집 AI (정제, 확장, 축약, 검증, 커스텀 프롬프트)
폴더 구조 관리 (드래그 앤 드롭, Tree/List/Grid 뷰)
Export/Import (JSON 형식, 백업/복원)
데모: assets/videos/rag-demo.gif
브라우저 자동화 (v0.6.0)
Electron BrowserView 기반 Chromium 통합
Vision 기반 UI 제어 및 Google Search Tools
DOM Inspection, Vision Tools, Bot 감지 우회 등 27개 도구
데모: assets/videos/browser-automation.gif
MCP 프로토콜
Model Context Protocol을 통한 도구 및 컨텍스트 표준화
GitHub, Brave Search, Git, Filesystem 등 템플릿 제공
환경 변수 UI 설정, 실행 전 사용자 승인 (5분 타임아웃)
데모: assets/videos/mcp-tools.gif
GitHub Sync (v0.6.0)
Personal Access Token 기반 안전한 데이터 동기화
AES‑256‑GCM 암호화로 민감 정보 보호
설정, 문서, 페르소나, 이미지, 대화 내역 동기화
데모: assets/videos/github-sync.gif
이미지 기능
ComfyUI 통합 이미지 생성
Vision API 기반 이미지 해석 및 질의응답
데모: assets/videos/image-generation.gif
🛠️ 기술 스택
프론트엔드: Next.js 15.3, React 19, TypeScript 5.7, Tailwind CSS, shadcn/ui, Zustand
에디터: Monaco Editor (VS Code 엔진)
데스크톱: Electron 35 (크로스‑플랫폼)
백엔드 런타임: Node.js 20+
데이터베이스: better‑sqlite3, SQLite‑vec (벡터 검색)
IPC: Context Bridge (안전한 통신)
LLM &amp; AI: LangGraph, LangChain, OpenAI, Anthropic, Google, Groq, MCP Protocol, ComfyUI
🚀 빠른 시작 (5분 안에 시작)
다운로드 및 설치
   - Windows: 
   - macOS: 
   - Linux: 
LLM 설정
   - 좌측 하단 설정 아이콘 → LLM 제공자 및 API 키 입력
   - 지원: OpenAI, Anthropic, Google, Custom (OpenAI‑compatible)
모드 및 그래프 선택
   - Chat, Editor, Browser 중 선택
   - 필요 시 LangGraph 워크플로우 타입 선택 (Instant, RAG, Agent 등)
대화 시작
   - 준비가 완료되면 AI와 대화를 시작하세요!
📋 시스템 요구사항
최소: Node.js 20.9+, 4 GB RAM, 500 MB 디스크
권장: Node.js 22+, 8 GB RAM, 1 GB 디스크
이 문서는 초안(draft) 상태이며, 검토 후  로 전환될 예정입니다.</content>
    <excerpt>SEPilot Desktop 소개
SEPilot Desktop은 오픈소스 LLM 기반 데스크톱 애플리케이션으로, Chat, Editor, Browser 세 가지 모드를 제공하여 강력하고 유연한 AI 워크플로우를 지원합니다. LangGraph 워크플로우, RAG, MCP 도구, Monaco Editor, Vision 기반 브라우저 자동화 등 다양한 기능을 통...</excerpt>
    <tags>SEPilot, Desktop, LLM, Project</tags>
    <lastModified>2026-02-10T17:10:51+09:00</lastModified>
    <author>JHL</author>
  </item>
  <item>
    <title>bun과 pnpm, npm의 차이</title>
    <slug>bun/comparison-pnpm-npm</slug>
    <content>bun과 pnpm, npm의 차이
개요
은 JavaScript 런타임, 패키지 매니저, 번들러를 하나의 바이너리로 제공하는 통합 툴입니다. 반면에 과 은 패키지 매니저에 초점을 맞추고 있으며, 각각 Node.js와 별도로 동작합니다.
이 가이드에서는 설치 방식, 성능, 디스크 사용량, 호환성, 생태계 등을 기준으로 세 도구를 비교하고, 어떤 상황에서 어떤 도구를 선택하면 좋은지 살펴봅니다.
설치 및 초기 설정
  항목   bun   npm (Node.js 기본)   pnpm  
 ------ ----- ------------------- ------ 
  설치 명령    (스크립트) 또는  (macOS)   Node.js 설치 시 자동 포함 ( 확인)     
  기본 제공 기능   런타임, 패키지 매니저, 번들러, 테스트 러너 등   런타임 + npm (패키지 매니저)   npm 호환 CLI + 효율적인 저장소 관리  
  설정 파일    (선택)       (멀티패키지)  
성능 비교
  항목   bun   npm   pnpm  
 ------ ----- ----- ------ 
  패키지 설치 속도   매우 빠름 (C++ 로 구현, 병렬 다운로드)   보통 (JavaScript 기반)   npm보다 빠름, 하지만 bun보다는 느림  
  실행 속도 (런타임)   Node.js 대비 24배 빠름 (V8 엔진 최적화)   Node.js 표준   Node.js 표준 (pnpm은 런타임이 아님)  
  번들링 속도    로 초단위 번들링   ,  등 별도 도구 필요   별도 번들러 필요  
벤치마크:  은 10,000개의 의존성을 30초 이내에 설치할 수 있는 반면, npm은 23분, pnpm은 약 1분 정도 소요됩니다(환경에 따라 차이 존재).
디스크 사용량
npm: 각 프로젝트마다 에 전체 복사본을 저장 → 중복 파일이 많이 발생.
pnpm: 내용 주소 기반 저장소(content‑addressable store)를 전역에 두고, 프로젝트마다 심볼릭 링크를 사용 → 중복 최소화, 디스크 사용량 3050% 절감.
bun:  역시 전역 캐시를 사용하지만, 현재는 pnpm만큼 세밀한 deduplication을 제공하지 않음. 그래도 npm 대비 2030% 정도 절감.
호환성 및 생태계
  항목   bun   npm   pnpm  
 ------ ----- ----- ------ 
  Node.js API 호환   대부분 호환, 일부 네이티브 모듈(특히 C/C++ 애드온)에서 빌드 오류 가능   완전 호환   완전 호환 (npm 스크립트 그대로 사용)  
  패키지 레지스트리   기본적으로 npm 레지스트리 사용   npm 레지스트리   npm 레지스트리  
  스크립트 실행    (npm script와 동일)        
  커뮤니티·플러그인   아직 초기 단계, 공식 플러그인 제한적   가장 큰 생태계, 수많은 플러그인·툴   npm 호환 플러그인 대부분 사용 가능  
주요 사용 사례
bun: 빠른 프로토타이핑, 작은 프로젝트, 번들링이 필요 없는 서버리스 함수, 성능이 중요한 CLI 툴.
npm: 대부분의 Node.js 프로젝트, 레거시 코드베이스, 광범위한 CI/CD 파이프라인.
pnpm: 모노레포, 대규모 프로젝트, 디스크 사용량을 최소화하고 설치 속도를 개선하고 싶을 때.
선택 가이드
  상황   추천 도구  
 ------ ----------- 
  프로젝트가 작고 빠른 설치·실행이 필요   bun  
  기존 Node.js 생태계와 완전 호환이 필요   npm  
  멀티패키지(모노레포) 혹은 디스크 절감이 중요한 대규모 프로젝트   pnpm  
결론
은 속도와 통합성을 중시하는 최신 개발자에게 매력적인 선택입니다.
은 보편성과 광범위한 호환성을 제공하므로 여전히 기본 선택지입니다.
은 효율적인 저장소 관리와 모노레포 지원이 강점이며, npm과 100% 호환됩니다.
프로젝트 요구사항(성능, 디스크 사용량, 생태계 지원)을 고려해 적절한 도구를 선택하면 됩니다.
이 문서는 2025년 기준 정보를 바탕으로 작성되었습니다. 각 툴의 최신 버전 및 업데이트 내용은 공식 문서를 참고하세요.</content>
    <excerpt>bun과 pnpm, npm의 차이
개요
은 JavaScript 런타임, 패키지 매니저, 번들러를 하나의 바이너리로 제공하는 통합 툴입니다. 반면에 과 은 패키지 매니저에 초점을 맞추고 있으며, 각각 Node.js와 별도로 동작합니다.
이 가이드에서는 설치 방식, 성능, 디스크 사용량, 호환성, 생태계 등을 기준으로 세 도구를 비교하고, 어떤 상황에서 어떤...</excerpt>
    <tags>bun, pnpm, npm, 비교, 가이드</tags>
    <lastModified>2026-02-10T17:10:51+09:00</lastModified>
    <author>JHL</author>
  </item>
  <item>
    <title>bun 이란?</title>
    <slug>bun/overview</slug>
    <content>개요
bun은 JavaScript/TypeScript 런타임, 번들러, 그리고 패키지 매니저를 하나로 통합한 도구입니다.
런타임: Node.js와 호환되는 API를 제공하면서 V8 엔진 대신 JavaScriptCore(Apple의 엔진)를 사용합니다.
번들러:  명령을 통해 ES 모듈, CommonJS, TypeScript 등을 빠르게 번들링합니다.
패키지 매니저:  로 npm 레지스트리의 패키지를 설치하며, 과  구조를 그대로 사용합니다.
공식 웹사이트: https://bun.sh
GitHub 레포지터리: https://github.com/oven-sh/bun
bun을 선택한 이유
  항목   설명  
 ------ ------ 
  성능   Zig 언어와 JavaScriptCore를 활용해 파일 I/O, 네트워크, 패키지 설치, 번들링 속도가 기존 Node.js 기반 도구보다 현저히 빠릅니다. 공식 벤치마크에서는  대비 23배,  대비 510배 빠른 결과가 보고되었습니다.  
  통합 도구   런타임, 번들러, 패키지 매니저가 하나의 바이너리()에 포함돼 별도 설치가 필요 없습니다. 개발 환경 설정이 간단해집니다.  
  Zero‑Config 지원    명령만으로 TypeScript 파일을 바로 실행할 수 있어 별도  설정이 불필요합니다.  
  호환성   대부분의 npm 패키지를 그대로 사용할 수 있으며,  스크립트도 그대로 동작합니다.  
  경량 설치 파일   단일 실행 파일(≈ 30 MB)로 배포되어 CI/CD 파이프라인에 쉽게 통합할 수 있습니다.  
장점
빠른 설치 및 실행
  -  은 병렬 I/O와 캐시 최적화를 통해 npm/yarn 대비 수 초 내에 의존성을 설치합니다.
내장 번들러
  -  로 ESBuild와 유사한 속도로 번들을 생성하며, 자동 트리쉐이킹과 코드 스플리팅을 지원합니다.
TypeScript 지원
  - 별도 트랜스파일러 없이  로 바로 실행 가능.
단일 바이너리
  - 런타임, 번들러, 패키지 매니저가 하나의 실행 파일에 포함돼 환경 관리가 단순합니다.
POSIX 호환
  - macOS, Linux, Windows(WSL 포함)에서 동일한 바이너리를 사용합니다.
단점
생태계 성숙도
  - npm/yarn에 비해 아직 사용자가 적고, 일부 복잡한 네이티브 모듈(예:  기반)에서 호환성 문제가 발생할 수 있습니다.
플러그인 및 툴링
  - Webpack, Rollup 등 기존 번들러용 플러그인 생태계와 직접 호환되지 않으며, bun 전용 플러그인도 아직 제한적입니다.
문서 및 커뮤니티
  - 공식 문서는 꾸준히 업데이트되고 있지만, Stack Overflow 등 커뮤니티 기반 Q&amp;A가 상대적으로 적습니다.
버전 관리
  - 현재는  자체가 버전 관리 도구 역할을 하지 않으며, 프로젝트별 Node.js 버전 관리와는 별개로 다루어야 합니다.
라이선스 및 역사
라이선스: MIT License (오픈 소스, 자유롭게 사용·수정·배포 가능)
주요 연혁
  - 2021년 5월: 프로젝트 초기 설계 및 공개 발표 (Jarred Sumner, Oven.sh 팀)
  - 2022년 1월: 첫 베타 버전() 공개, GitHub 스타 수 급증
  - 2022년 8월:  에서 패키지 매니저 기능 정식 추가
  - 2023년 3월:  에서 TypeScript 실행 지원 및  도입
  - 2024년 11월:  에서 Windows 지원 및 안정화 버전 출시
자세한 릴리즈 노트는 GitHub Releases 페이지(https://github.com/oven-sh/bun/releases)를 참고하세요.
결론
bun은 속도와 통합성을 중시하는 프로젝트에 적합한 최신 JavaScript 도구입니다.
성능이 중요한 CI/CD 파이프라인, 대규모 모노레포, 혹은 빠른 개발 피드백 루프가 필요한 경우 bun을 고려해볼 만합니다.
반면, 특정 네이티브 모듈이나 풍부한 플러그인 생태계가 필수인 경우에는 기존 npm/yarn + Webpack/Rollup 조합이 더 안정적일 수 있습니다.
프로젝트에 적용하기 전, 핵심 의존성이 bun과 호환되는지 확인하고, 작은 파일럿 프로젝트에서 성능 및 호환성을 검증하는 것을 권장합니다.
추가 조사 필요: 복잡한 네이티브 모듈(예:  기반)과 bun의 호환성 여부는 프로젝트별 테스트가 필요합니다. 공식 문서와 GitHub 이슈 트래커를 지속적으로 확인하세요.</content>
    <excerpt>개요
bun은 JavaScript/TypeScript 런타임, 번들러, 그리고 패키지 매니저를 하나로 통합한 도구입니다.
런타임: Node.js와 호환되는 API를 제공하면서 V8 엔진 대신 JavaScriptCore(Apple의 엔진)를 사용합니다.
번들러:  명령을 통해 ES 모듈, CommonJS, TypeScript 등을 빠르게 번들링합니다.
패키지...</excerpt>
    <tags>bun, npm, yarn, 패키지 매니저, 가이드</tags>
    <lastModified>2026-02-10T17:10:51+09:00</lastModified>
    <author>SEPilot AI</author>
  </item>
  <item>
    <title>GitHub Actions로 bun을 쓰는 방법</title>
    <slug>bun/github-actions-setup</slug>
    <content>개요
GitHub Actions 워크플로우에서 bun(JavaScript 런타임 및 패키지 매니저)을 사용하면 빠른 의존성 설치와 빌드가 가능합니다. 이 문서에서는 bun을 설치하고, 캐시를 활용하며, 일반적인 스크립트를 실행하는 전체 흐름을 예시와 함께 설명합니다.
사전 요구 사항
저장소에 을 사용하도록 설정된  혹은  파일이 존재해야 합니다.
워크플로우는 Linux() 환경을 기준으로 설명합니다. Windows/macOS에서도 동일한 단계가 적용되지만, OS별 경로 차이에 유의하세요.
워크플로우 파일 구조
 디렉터리에  과 같은 파일을 생성합니다.
워크플로우 트리거
Job 정의
단계별 설정
3-1. 레포지토리 체크아웃
3-2. bun 설치
bun은 공식 설치 스크립트를 통해 간단히 설치할 수 있습니다.
공식 설치 스크립트는  에서 확인할 수 있습니다.
3-3. 의존성 캐시
bun은  대신 와  디렉터리를 사용합니다.
 액션을 이용해 이 디렉터리를 캐시하면 설치 속도가 크게 향상됩니다.
3-4. 의존성 설치
3-5. 테스트 실행 (예시)
3-6. 빌드 및 배포 (필요 시)
전체 예시 워크플로우
아래는 위 단계들을 하나의 파일에 통합한 최종 예시입니다.
주의: 위 예시에서는 와  스크립트가  혹은 에 정의되어 있다고 가정합니다. 실제 프로젝트에 맞게 스크립트 명령을 조정하세요.
macOS / Windows 환경에서 사용하기
macOS:  로 변경하고,  설치가 기본 제공됩니다.
Windows:  로 변경하고, PowerShell 스크립트()를 사용해 bun을 설치합니다. 예시:
Windows에서는 경로 구분자()와 환경 변수 사용법에 유의하세요.
베스트 프랙티스
캐시 키 관리:  파일이 변경될 때마다 캐시가 무효화되도록  를 사용합니다.
CI 속도 최적화:  대신 bun 전용 설치 스크립트를 사용하면 불필요한 Node.js 설치를 피할 수 있습니다.
보안: 공식 설치 스크립트는 HTTPS를 통해 전달되며,  옵션으로 오류 시 중단됩니다. 필요 시 SHA256 검증을 추가할 수 있습니다.
버전 고정: 특정 bun 버전을 사용하려면  환경 변수를 설정하고 설치 스크립트에 전달합니다.
참고 자료
Bun 공식 홈페이지 및 설치 가이드: 
GitHub Actions 공식 문서: 
actions/cache 액션: 
결론
GitHub Actions에서 bun을 활용하면 의존성 설치와 빌드 속도가 크게 개선됩니다. 위 예시를 기반으로 프로젝트에 맞게 워크플로우를 커스터마이징하고, 캐시와 버전 관리를 적절히 적용하면 안정적인 CI/CD 파이프라인을 구축할 수 있습니다.</content>
    <excerpt>개요
GitHub Actions 워크플로우에서 bun(JavaScript 런타임 및 패키지 매니저)을 사용하면 빠른 의존성 설치와 빌드가 가능합니다. 이 문서에서는 bun을 설치하고, 캐시를 활용하며, 일반적인 스크립트를 실행하는 전체 흐름을 예시와 함께 설명합니다.
사전 요구 사항
저장소에 을 사용하도록 설정된  혹은  파일이 존재해야 합니다.
워크플로우...</excerpt>
    <tags>github-actions, bun, CI, CI/CD, node-alternative</tags>
    <lastModified>2026-02-10T17:10:51+09:00</lastModified>
    <author>SEPilot AI</author>
  </item>
  <item>
    <title>설정 파일 가이드</title>
    <slug>guide/configuration</slug>
    <content>설정 파일 가이드
SEPilot Wiki의 모든 설정 파일과 옵션을 상세히 설명합니다.
설정 파일 목록
  파일   위치   용도  
 ------ ------ ------ 
     루트   사이트 기본 정보  
     루트   테마 (색상, 폰트, 레이아웃)  
     루트   네비게이션 메뉴  
     src/styles   커스텀 CSS  
     src   GitHub 저장소 연결 설정  
site.config.ts 상세
theme.config.ts 상세
색상 (colors)
폰트 (fonts)
레이아웃 (layout)
테두리 반경 (borderRadius)
navigation.config.ts 상세
GitHub 저장소 설정
Repository Secrets
GitHub Repository Settings &gt; Secrets에서 설정:
  변수   필수   설명  
 ------ ------ ------ 
     O   OpenAI 호환 API URL  
     O   API 키  
     O   모델명 (예: gpt-4)  
GitHub Pages 설정
Repository Settings &gt; Pages
Source: &quot;GitHub Actions&quot; 선택
브랜치 push 시 자동 배포
환경 변수
빌드 시
개발 시
 파일에 설정:</content>
    <excerpt>설정 파일 가이드
SEPilot Wiki의 모든 설정 파일과 옵션을 상세히 설명합니다.
설정 파일 목록
  파일   위치   용도  
 ------ ------ ------ 
     루트   사이트 기본 정보  
     루트   테마 (색상, 폰트, 레이아웃)  
     루트   네비게이션 메뉴  
     src/styles   커스텀 CSS...</excerpt>
    <tags>설정, 가이드, TypeScript</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>Theme Customization</title>
    <slug>guide/theme-customization</slug>
    <content>Theme Customization
This document is a placeholder for the Theme Customization guide. Add details on CSS overrides, theme variables, and design guidelines here.</content>
    <excerpt>Theme Customization
This document is a placeholder for the Theme Customization guide. Add details on CSS overrides, theme variables, and design guidelines here.</excerpt>
    <tags>theme, customization, appearance</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>Getting Started</title>
    <slug>guide/getting-started</slug>
    <content>Getting Started
This document is a placeholder for the Getting Started guide. Add detailed steps, screenshots, and examples here.</content>
    <excerpt>Getting Started
This document is a placeholder for the Getting Started guide. Add detailed steps, screenshots, and examples here.</excerpt>
    <tags>getting-started, introduction, setup</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>FAQ</title>
    <slug>guide/faq</slug>
    <content>FAQ
SEPilot Wiki 사용에 관한 자주 묻는 질문과 답변입니다.
일반
SEPilot Wiki란 무엇인가요?
SEPilot Wiki는 AI 에이전트 기반의 자동화된 위키 시스템입니다. GitHub 저장소의  폴더를 데이터 저장소로 활용하고, GitHub Issues를 통해 사용자와 소통하며, AI가 문서를 자동으로 생성/수정/유지보수합니다.
어떤 기술 스택을 사용하나요?
Frontend: React 18 + TypeScript + Vite
State Management: TanStack Query
Routing: React Router 7
Hosting: GitHub Pages
CI/CD: GitHub Actions
문서 작성
AI에게 문서 작성을 요청하려면 어떻게 하나요?
GitHub Issues에서 새 이슈를 생성합니다
라벨을 추가합니다
이슈 본문에 원하는 문서의 내용을 설명합니다
AI가 자동으로 문서 초안을 작성합니다
직접 문서를 추가하려면 어떻게 하나요?
 폴더에 마크다운 파일을 직접 추가할 수 있습니다:
문서 수정을 요청하려면 어떻게 하나요?
해당 문서와 관련된 이슈에 댓글로 수정 사항을 작성하면 AI가 피드백을 반영하여 문서를 업데이트합니다.
기능
검색은 어떻게 작동하나요?
Fuse.js 기반의 전문 검색(Full-text search)을 지원합니다. 문서 제목, 내용, 태그 등을 대상으로 검색하며, 2자 이상 입력 시 검색이 시작됩니다.
다크 모드를 지원하나요?
예, 라이트/다크/시스템 테마를 지원합니다. 우측 상단의 테마 토글 버튼으로 변경할 수 있습니다.
Mermaid 다이어그램을 사용할 수 있나요?
예, 마크다운 코드 블록에서  언어를 지정하면 다이어그램이 렌더링됩니다:
markdown
Plotly 차트도 지원하나요?
예,  코드 블록으로 인터랙티브 차트를 추가할 수 있습니다:
markdown
문제 해결
페이지가 404 오류를 표시합니다
GitHub Pages의 SPA 라우팅 특성상, 직접 URL 접근 시 404가 발생할 수 있습니다. 새로고침하거나 홈페이지에서 네비게이션을 통해 접근해 보세요.
문서가 목록에 표시되지 않습니다
프론트매터의 가 인지 확인하세요
파일 확장자가 인지 확인하세요
GitHub Actions 배포가 완료되었는지 확인하세요 (약 2-3분 소요)
AI가 문서를 생성하지 않습니다
이슈에  라벨이 추가되었는지 확인하세요
GitHub Actions 워크플로우가 활성화되어 있는지 확인하세요
워크플로우 실행 로그에서 오류를 확인하세요
기여
프로젝트에 기여하려면 어떻게 하나요?
이슈를 통해 기능 제안 또는 버그 리포트
라벨로 문서 작성 요청
PR을 통한 직접 코드 기여
코드 스타일 가이드가 있나요?
ESLint + Prettier 설정을 준수합니다
TypeScript strict 모드를 사용합니다
커밋 전  검사를 통과해야 합니다</content>
    <excerpt>FAQ
SEPilot Wiki 사용에 관한 자주 묻는 질문과 답변입니다.
일반
SEPilot Wiki란 무엇인가요?
SEPilot Wiki는 AI 에이전트 기반의 자동화된 위키 시스템입니다. GitHub 저장소의  폴더를 데이터 저장소로 활용하고, GitHub Issues를 통해 사용자와 소통하며, AI가 문서를 자동으로 생성/수정/유지보수합니다.
어떤 기...</excerpt>
    <tags>FAQ, 가이드, 도움말</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>Diagrams Guide</title>
    <slug>guide/diagrams-guide</slug>
    <content>Diagrams Guide
This document is a placeholder for the Diagrams Guide. Include guidelines on diagram tools, file formats, and best practices for visual documentation.</content>
    <excerpt>Diagrams Guide
This document is a placeholder for the Diagrams Guide. Include guidelines on diagram tools, file formats, and best practices for visual documentation.</excerpt>
    <tags>diagrams, visuals, documentation</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>LLM Workflow</title>
    <slug>guide/llm-workflow</slug>
    <content>LLM Workflow
This document is a placeholder for the LLM Workflow guide. Provide step‑by‑step instructions, architecture diagrams, and usage examples here.</content>
    <excerpt>LLM Workflow
This document is a placeholder for the LLM Workflow guide. Provide step‑by‑step instructions, architecture diagrams, and usage examples here.</excerpt>
    <tags>LLM, workflow, integration</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>다이어그램 및 차트 사용 가이드</title>
    <slug>guide/diagrams</slug>
    <content>다이어그램 및 차트 사용 가이드
SEPilot Wiki는 복잡한 아이디어와 데이터를 시각화하기 위해 Mermaid와 Plotly를 지원합니다.
마크다운 코드 블록을 사용하여 간편하게 다이어그램과 차트를 그릴 수 있습니다.
Mermaid 다이어그램
 언어로 코드 블록을 작성하면 자동으로 다이어그램으로 렌더링됩니다.
플로우차트 (Flowchart)
mermaid
graph TD;
    Start--&gt;Stop;
    Start--&gt;Progress;
    Progress--&gt;Stop;
클래스 다이어그램 (Class Diagram)
mermaid
classDiagram
    Animal &lt; -- Duck
    Animal &lt; -- Fish
    Animal &lt; -- Zebra
    Animal : +int age
    Animal : +String gender
    Animal: +isMammal()
    Animal: +mate()
    class Duck{
        +String beakColor
        +swim()
        +quack()
    }
    class Fish{
        -int sizeInFeet
        -canEat()
    }
    class Zebra{
        +bool is_wild
        +run()
    }
plotlymarkdown
`
문법 강조 (Syntax Highlighting)
다양한 프로그래밍 언어의 문법 강조를 지원합니다.</content>
    <excerpt>다이어그램 및 차트 사용 가이드
SEPilot Wiki는 복잡한 아이디어와 데이터를 시각화하기 위해 Mermaid와 Plotly를 지원합니다.
마크다운 코드 블록을 사용하여 간편하게 다이어그램과 차트를 그릴 수 있습니다.
Mermaid 다이어그램
 언어로 코드 블록을 작성하면 자동으로 다이어그램으로 렌더링됩니다.
플로우차트 (Flowchart)
mermai...</excerpt>
    <tags>mermaid, plotly, 차트, 다이어그램, 사용법</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  <item>
    <title>Configuration Guide</title>
    <slug>guide/configuration-guide</slug>
    <content>Configuration Guide
This document is a placeholder for the Configuration Guide. Include configuration options, environment variables, and best practices here.</content>
    <excerpt>Configuration Guide
This document is a placeholder for the Configuration Guide. Include configuration options, environment variables, and best practices here.</excerpt>
    <tags>configuration, settings, customization</tags>
    <lastModified>undefined</lastModified>
    <author></author>
  </item>
  </items>
</searchIndex>