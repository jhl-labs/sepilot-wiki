[
  {
    "title": "MAS (Multi Agent System)",
    "slug": "mas-multi-agent-system",
    "content": "MAS (Multi Agent System)\n개요\n다중 에이전트 시스템(Multi-Agent System, MAS)은 여러 인공지능(AI) 에이전트가 협력·조정하여 사용자나 다른 시스템을 대신해 복합적인 작업을 수행하도록 설계된 시스템이다. 각 에이전트는 자체적인 속성과 자율성을 가지며, 전체 시스템은 공통 목표를 달성하기 위해 에이전트 간의 커뮤니케이션·협업을 활용한다.\n2025년이 \"에이전트의 해\"였다면, 2026년은 모든 멀티 에이전트 시스템이 프로덕션으로 이행하는 해로 평가받고 있다. 단일 범용 에이전트에서 전문화된 에이전트 팀의 오케스트레이션 아키텍처로의 전환이 가속화되고 있으며, Gartner에 따르면 멀티 에이전트 시스템 관련 문의가 2024년 Q1 대비 2025년 Q2에 1,445% 급증했다. (IBM, Landbase)\n핵심 구성 요소\n  요소   설명  \n ------ ------ \n  에이전트   LLM 기반 AI 에이전트로, 자연어 이해·생성, 도구 호출, 계획 수립 등을 수행한다  \n  지식·메모리   에이전트는 외부 데이터, API, 웹 검색 등 도구를 활용해 정보를 획득하고, 단기/장기/엔티티 메모리를 관리한다  \n  통신 프로토콜   에이전트 간 메시지를 주고받으며 목표·계획·결과를 공유한다 (A2A, MCP 등)  \n  조정 메커니즘   중앙 집중식·분산식·계층형·홀로닉·연합·팀 등 다양한 아키텍처가 존재한다  \n  도구(Tools)   에이전트가 외부 시스템과 상호작용하기 위한 인터페이스 (DB 쿼리, API 호출, 파일 시스템 등)  \n  오케스트레이터   에이전트 팀의 작업 분배, 진행 추적, 오류 복구를 위한 재계획을 담당하는 상위 에이전트  \n아키텍처 유형\n중앙 집중식 네트워크\n중앙 서버가 전역 지식 베이스와 에이전트 연결을 관리한다.\n장점: 통신이 쉽고 지식이 일관됨.\n단점: 중앙 서버 장애 시 전체 시스템이 중단될 위험이 있다.\n분산형 네트워크\n에이전트가 인접 에이전트와 직접 정보를 교환한다.\n장점: 견고하고 모듈성이 높으며 단일 장애점이 없음.\n단점: 협업을 위한 행동 조정이 복잡할 수 있다.\n계층형 구조\n트리 형태로 상위·하위 에이전트가 존재한다.\n상위 에이전트가 의사결정 권한을 갖고, 하위 에이전트는 구체 작업을 수행한다.\nMicrosoft의 Magentic-One이 대표적 예로, Orchestrator가 4개 전문 에이전트를 지휘한다.\n홀로닉 구조\n에이전트가 \"홀론\" 단위로 그룹화되어, 하나의 전체와 여러 하위 에이전트가 동시에 존재한다.\n연합·팀 구조\n에이전트가 일시적으로 연합하거나 팀을 이루어 특정 목표를 달성한다.\nClaude Code의 Agent Teams, CrewAI의 Crews 등이 이 구조에 해당한다.\n출처: IBM - 다중 에이전트 시스템이란?\nA2A, MCP, MAS의 관계\nMAS 생태계를 이해하기 위해서는 세 가지 핵심 개념의 관계를 파악해야 한다.\n개념 비교표\n  항목   MAS   A2A   MCP  \n ------ ----- ----- ----- \n  수준   개념/아키텍처   프로토콜   프로토콜  \n  발표   학술 개념 (1990년대)   Google, 2025.04   Anthropic, 2024.11  \n  목적   다중 에이전트 협업 시스템   에이전트 간 통신   에이전트와 도구/데이터 연결  \n  거버넌스   N/A   Linux Foundation   AAIF (Linux Foundation)  \n  기반 기술   프레임워크에 의존   HTTP, SSE, JSON-RPC, gRPC   JSON-RPC 2.0  \n  방향성   전체 시스템   수평적 (에이전트↔에이전트)   수직적 (에이전트↔도구)  \nMAS는 \"무엇을 만들 것인가(what)\"이고, A2A와 MCP는 \"어떻게 만들 것인가(how)\"에 해당하는 구체적 프로토콜이다.\nGoogle A2A (Agent-to-Agent) 프로토콜\n서로 다른 프레임워크, 벤더, 서버에서 구축된 AI 에이전트들이 상호 통신하고 협업할 수 있도록 설계된 개방형 표준이다. 2025년 4월 Google Cloud가 발표했다.\nAgent Card: 각 에이전트가 자신의 정체성, 기능, 스킬, 인증 요구사항을 기술한 JSON 메타데이터를 으로 발행\nTask 관리: 생명주기 상태를 통해 빠른 작업부터 장시간 심층 연구까지 관리\n지원 규모: 2025년 7월 기준 150개 이상의 조직이 지원 (Atlassian, Salesforce, SAP, PayPal, AWS, Microsoft 등)\n최신 상태: Linux Foundation 산하 프로젝트로 편입, v0.3에서 gRPC 지원 추가\n출처: Google Developers Blog, A2A Protocol, Linux Foundation\nAnthropic MCP (Model Context Protocol)\nAI 어시스턴트를 데이터 소스, 도구, 외부 서비스에 연결하기 위한 개방형 표준 프로토콜이다. Language Server Protocol(LSP)에서 영감을 받았다.\n3계층 아키텍처: Host(사용자 앱) → Client(연결 관리) → Server(도구/리소스 노출)\n핵심 기능: Tools(도구 호출), Resources(데이터 소스), Prompts(템플릿)\n채택 현황: OpenAI(2025.03), Google DeepMind(2025.04) 공식 채택. 10,000개 이상의 MCP 서버가 프로덕션 운영 중\n거버넌스: 2025년 12월 Agentic AI Foundation(AAIF)에 기증 (Anthropic, OpenAI, Block 공동 설립, Linux Foundation 산하)\n출처: Anthropic - MCP 발표, MCP Spec, Anthropic - AAIF\nA2A와 MCP는 보완적 관계\n두 프로토콜은 에이전틱 스택의 서로 다른 계층에서 작동한다:\n  시나리오   선택  \n ---------- ------ \n  단일 에이전트가 여러 도구/DB에 접근   MCP  \n  서로 다른 벤더의 에이전트들이 협업   A2A  \n  IDE에서 AI가 코드 분석 도구 호출   MCP  \n  구매 에이전트가 판매 에이전트와 협상   A2A  \n  복잡한 멀티 에이전트 기업 시스템   MCP + A2A 함께  \n출처: Auth0 - MCP vs A2A Guide, TrueFoundry, Clarifai\n주요 AI Agent 개발 도구\n상용 도구\n  도구   개발사   MAS 지원 수준   핵심 MAS 기능  \n ------ -------- -------------- -------------- \n  Claude Code   Anthropic   높음   Subagents, Agent Teams (실험적)  \n  Cursor   Cursor Inc.   높음   멀티 에이전트 병렬, Subagents, 자동 판정  \n  Google Antigravity   Google   높음   Manager View 멀티 에이전트 오케스트레이션  \n  GitHub Copilot   GitHub/MS   중상   Agent Mode, Agent Skills, Coding Agent  \n  Devin   Cognition Labs   중상   멀티 에이전트 디스패치, 병렬 실행  \n  Windsurf   Codeium   중간   Cascade 에이전트, Agent Skills  \nClaude Code (Anthropic)\nAnthropic의 공식 CLI 기반 AI 코딩 에이전트.\nSubagents: 메인 에이전트 내에서 특정 작업을 수행하는 독립 에이전트. 자체 컨텍스트 윈도우, 커스텀 시스템 프롬프트, 독립적 도구 접근 권한 보유. 결과를 메인 에이전트에게만 보고.\nAgent Teams (실험적): Opus 4.6과 함께 출시. 여러 Claude Code 인스턴스가 병렬로 자율 협력. 팀 리드가 팀원을 생성하고, 팀원들은 서로 직접 메시지를 주고받으며 공유 작업 목록에서 자체 조율.\n  구분   Context   Communication   Coordination  \n ------ --------- --------------- -------------- \n  Subagents   메인 세션 내   결과 → 메인만   메인 에이전트가 전체 관리  \n  Agent Teams   각 팀원 별도 컨텍스트   팀원 ↔ 팀원 직접   공유 작업 리스트, 자체 조정  \n출처: Claude Code Subagents 문서, Claude Code Agent Teams\nGoogle Antigravity\n2025년 11월 Gemini 3 출시와 함께 발표된 에이전틱 개발 플랫폼.\nVS Code 포크 기반의 완전한 독립 플랫폼\nEditor View: 에이전트 사이드바가 있는 일반적인 IDE 인터페이스\nManager View: 여러 에이전트를 병렬로 오케스트레이션하는 제어 센터. 비동기 작업 실행 가능\nGemini 3 기반, Anthropic Claude 및 OpenAI 모델도 지원\n현재 Public Preview로 무료 제공\n출처: Google Developers Blog - Antigravity, Wikipedia\nCursor\nVS Code 포크 기반 AI 코딩 IDE. 2026년 2월 기준 멀티 에이전트 기능 프리뷰 제공 중.\nAgent Mode (Composer): 다단계 코딩 작업을 자율적으로 처리\nMulti-Agent Interface: Cursor 2.0에서 도입. 여러 AI 에이전트가 병렬 작업 가능\n자동 판정 시스템: 여러 에이전트를 병렬 실행 후 최적 솔루션을 자동 평가·추천\n출처: Cursor 2.0 - InfoQ, Cursor 2.2 Changelog\nVS Code 1.109 - 멀티 에이전트 개발의 허브\n2026년 2월 VS Code 1.109에서 Microsoft는 VS Code를 \"멀티 에이전트 개발의 홈\"으로 선언했다.\nClaude, Codex, Copilot 에이전트를 동시에 실행\n여러 에이전트 세션을 로컬/백그라운드/클라우드에서 병렬 관리\nAgent Skills가 GA(일반 제공)로 전환\n출처: VS Code Blog, Visual Studio Magazine\n오픈소스 MAS 프레임워크\n  프레임워크   개발사   언어   아키텍처   특징  \n ----------- -------- ------ --------- ------ \n  AutoGen / MS Agent Framework   Microsoft   Python, .NET   비동기 이벤트 기반   Semantic Kernel과 통합, 2026 Q1 GA 목표  \n  CrewAI   CrewAI Inc.   Python   역할 기반, Crews + Flows   직관적 역할 설계, 100+ 내장 도구  \n  LangGraph   LangChain   Python, JS/TS   상태 기반 그래프   영속 상태, 타임트래블 디버깅, 1.0 출시  \n  OpenAI Agents SDK   OpenAI   Python, TS   핸드오프 기반   Swarm 후속, 가드레일, 트레이싱 내장  \n  Magentic-One   MS Research   Python   Orchestrator + 4 전문 에이전트   범용 작업 해결, 벤치마크 SOTA급  \n  Google ADK   Google   Python, TS, Go, Java   계층적 멀티 에이전트   처음부터 MAS 설계, Vertex AI 통합  \nAutoGen → Microsoft Agent Framework\nMicrosoft Research에서 개발한 멀티 에이전트 프레임워크. v0.4에서 비동기 이벤트 기반 아키텍처로 개편된 후, Semantic Kernel과 통합되어 Microsoft Agent Framework으로 전환 중이다.\nPython 및 .NET 지원, TypeScript 예정\n2026년 Q1 말까지 1.0 GA 출시 목표\nAutoGen은 안정 API를 유지하며 보안 패치만 받고, 신규 기능은 Agent Framework으로\n출처: Visual Studio Magazine, MS Agent Framework\nCrewAI\n역할 기반 멀티 에이전트 협업에 특화된 Python 프레임워크. LangChain에 독립적으로 구축.\n역할 기반 아키텍처: 에이전트에 역할(연구원, 작가, 분석가 등), 목표, 배경 이야기 부여\n협업 프로세스: Sequential(순차), Hierarchical(관리자 조율), Consensus(합의 기반)\nCrews + Flows 이중 구조: Crews(자율적 팀), Flows(이벤트 기반 워크플로우)\nGitHub 스타 20,000+\n출처: CrewAI 공식, CrewAI GitHub\nLangGraph (LangChain)\n상태 기반 그래프 아키텍처의 에이전트 오케스트레이션 프레임워크.\n사이클을 포함하는 LLM 워크플로우 생성 가능 (에이전트가 이전 단계를 재방문)\nDurable State: 실행 상태 자동 저장, 서버 재시작이나 장기 워크플로우 중단 시에도 이어서 실행\nTime-Travel Debugging: 과거 상태로 돌아가 디버깅 가능\n2025년 LangGraph 1.0 출시\n출처: LangGraph 공식, LangGraph Multi-Agent Workflows\nOpenCode\nGo 언어로 작성된 오픈소스 터미널 기반 AI 코딩 에이전트. Claude Code의 오픈소스 대안으로 부상.\n75개 이상 모델 지원 (Claude, GPT, Gemini, 로컬 모델 등)\nGitHub 스타 95,000+, 월 650,000명+ 개발자 사용\n전용 MAS 프레임워크라기보다 단일 에이전트 코딩 도구에 가까움\n출처: OpenCode 공식, OpenCode GitHub\nOpenClaw\n오스트리아 개발자 Peter Steinberger가 만든 오픈소스 AI 에이전트. Signal, Telegram, Discord, WhatsApp 등 메시징 서비스를 통해 실세계 작업을 수행한다.\n2025년 11월 \"Clawdbot\"으로 공개 → Anthropic 상표 항의 → \"OpenClaw\"로 이름 변경\n웹 브라우징, PDF 요약, 캘린더 관리, 에이전틱 쇼핑, 이메일 관리 등 수행\n독립적 MAS 프레임워크가 아닌, 에이전틱 인터페이스\n출처: OpenClaw Wikipedia, CNBC\n주요 기업의 MAS 전략 (2025-2026)\nGoogle - A2A + ADK\nA2A 프로토콜: 에이전트 간 통신 오픈 표준, 150+ 기업 지원\nAgent Development Kit (ADK): 오픈소스 멀티 에이전트 프레임워크 (Python, TS, Go, Java)\nAntigravity IDE: Manager View를 통한 멀티 에이전트 오케스트레이션\n출처: Google ADK\nMicrosoft - Copilot Studio + Agent Framework\nCopilot Studio: 멀티 에이전트 시스템 구축 기능 (프리뷰), 에이전트 간 작업 위임\nMicrosoft Agent Framework: AutoGen + Semantic Kernel 통합, Python/.NET 지원\n2026년 전환: 개별 명령 응답에서 자율적 멀티스텝 프로세스 처리로의 주요 아키텍처 전환\n출처: Microsoft Copilot Blog, 6 core capabilities for 2026\nOpenAI - Agents SDK + AGENTS.md\nAgents SDK: Swarm의 프로덕션 후속. 핸드오프, 가드레일, 트레이싱, 음성 에이전트 내장\nAGENTS.md: 코딩 에이전트 지침 규격. 60,000+ 오픈소스 프로젝트에서 채택\nAAIF(Agentic AI Foundation) 공동 설립\n출처: OpenAI - New tools for building agents, OpenAI - AAIF\nAmazon AWS - Bedrock AgentCore\nAmazon Bedrock: 멀티 에이전트 협업 기능 2025년 3월 GA. Supervisor 기반 아키텍처\nAgentCore: re:Invent 2025에서 발표. 에이전트 경계 관리, 메모리, 평가 기능\n출처: AWS - Multi-agent collaboration\nNVIDIA - Nemotron 3\nMAS 구축을 위한 Nemotron 3 오픈 모델 패밀리 (Nano, Super, Ultra) 발표\nHybrid Latent Mixture-of-Experts 아키텍처\nSuper와 Ultra는 2026년 상반기 출시 예정\n출처: NVIDIA\nAgentic AI Foundation (AAIF)\n2025년 12월 Linux Foundation 산하에 설립. OpenAI, Anthropic, Block이 공동 창설하고, Google, Microsoft, AWS, Bloomberg, Cloudflare가 지원한다.\n주요 프로젝트: MCP (Anthropic), Goose (Block), AGENTS.md (OpenAI)\nAI 에이전트 표준화를 위한 업계 최대 협력체\n출처: OpenAI - AAIF, TechCrunch\n시장 규모와 성장 전망\n시장 규모 예측\n  연도   시장 규모   출처  \n ------ ---------- ------ \n  2025년   USD 72.9억   Fortune Business Insights  \n  2026년   USD 91.4억   Fortune Business Insights  \n  2030년   USD 520억+   MachineLearningMastery  \n  2032년   USD 932억 (CAGR 44.6%)   MarketsandMarkets  \n  2034년   USD 1,391.9억 (CAGR 40.5%)   Fortune Business Insights  \n핵심 예측 (Gartner, McKinsey 등)\n  예측   출처  \n ------ ------ \n  2026년 말까지 엔터프라이즈 앱의 40%에 태스크 전용 AI 에이전트 탑재 (2025년 5% 미만)   Gartner  \n  2028년까지 AI 에이전트가 B2B 구매에서 USD 15조 규모 주도   Gartner  \n  2028년까지 일상 업무 의사결정의 15%가 에이전틱 AI로 자율 수행   Gartner  \n  2030년까지 에이전틱 AI로 최대 USD 2.9조의 경제적 가치 창출   McKinsey  \n  2035년까지 에이전틱 AI가 기업 앱 소프트웨어 매출의 30% (USD 4,500억+) 차지   Gartner  \n산업별 영향\n소프트웨어 개발\n2026년은 소프트웨어 개발에서 \"위임(delegation)\"의 시대다. 2024년 자동완성→대화, 2025년 대화→협업에 이어, 2026년에는 AI 에이전트에게 작업을 위임하는 단계로 전환되고 있다.\n개발자의 85%가 정기적으로 AI 도구를 사용\nGartner 예측: 2026년까지 소프트웨어 엔지니어의 90%가 직접 코딩에서 AI 프로세스 오케스트레이션으로 전환\nMCP를 통해 Claude Code가 Figma, Slack, Jira, 내부 문서와 연동\n출처: Anthropic - 2026 Agentic Coding Trends Report, senorit.de\n고객 서비스\n2029년까지 에이전틱 AI가 일반 고객 서비스 이슈의 80%를 인간 개입 없이 자율 해결\n운영 비용 30% 절감 효과\n고객 서비스와 이커머스가 채택 선두 (명확한 ROI)\n출처: Gartner, BCG\n금융\n금융 서비스가 \"Frontier Firms\"(모든 워크플로우에 AI 에이전트를 내재화한 조직)의 최고 밀집 산업\nFrontier Firms의 AI 투자 수익률이 저조한 채택 기업의 약 3배\n2026년 금융 팀의 44%가 에이전틱 AI 사용 예상 (600%+ 증가)\n미국 은행 사례: AI 에이전트로 신용 위험 메모 작성 시 생산성 20-60% 향상, 신용 처리 시간 30% 단축\n출처: Microsoft, Neurons Lab\n기업 전반\n57%의 기업이 이미 AI 에이전트를 프로덕션에서 운영\n59%의 기업이 3개 이상의 LLM을 프로덕션에서 운영 (2025년 후반)\n기업들은 평균 약 USD 1.14억의 관련 투자를 계획 중\n고위 임원의 90%가 2026년 중 관련 투자를 늘릴 계획\n출처: Landbase, OneReach.ai\n미래 전망 (2026-2030)\n기술적 방향\n마이크로서비스 혁명과 유사한 전환: 단일 범용 에이전트 → 전문화된 에이전트 팀 오케스트레이션. 소프트웨어의 모놀리식→마이크로서비스 전환과 동일한 패턴. (Techzine)\n인간-AI 혼합 팀: 2028년까지 38%의 조직에서 AI 에이전트가 인간 팀의 구성원으로 참여. (G2)\n로봇·IoT 통합: AI 에이전트가 자율 창고 로봇, 배달 드론, 가정 어시스턴트와 결합하여 물리적 환경에서 작동.\n표준화 수렴: A2A(에이전트 간), MCP(에이전트-도구), AGENTS.md(코딩 에이전트 지침)가 AAIF와 Linux Foundation 하에서 통합 거버넌스.\n로우코드/노코드 민주화: 시각적 빌더를 통해 1560분 만에 에이전트 배포 가능. (MachineLearningMastery)\n과제와 리스크\n  과제   현황  \n ------ ------ \n  신뢰도 하락   완전 자율 AI 에이전트에 대한 임원 신뢰도가 43%(2024) → 22%(2025)로 하락  \n  프로젝트 취소   2027년까지 에이전틱 AI 프로젝트의 40%+가 비용, 불명확한 가치, 리스크 관리 부족으로 취소 예상  \n  시스템 복잡성   리더의 65%가 에이전틱 시스템 복잡성을 최대 장벽으로 지목  \n  보안·프라이버시   35%의 조직이 사이버보안, 30%가 데이터 프라이버시를 주요 우려로 지적  \n  통합 난이도   46%가 기존 시스템과의 통합을 주요 과제로 인식  \n  조정 실패   부서별 독립 에이전트 구축으로 연결 단절, 중복 로직, \"디지털 허드렛일\" 발생  \n출처: Computer Weekly, Salesmate\n거버넌스와 윤리\nEU AI Act: 고위험 의무가 2026년 8월 전면 적용\nGuardian Agent: Gartner 예측, 2030년까지 에이전틱 AI 시장의 10-15%를 차지. 다른 에이전트의 행동을 감시·감사하는 전문 에이전트 (Gartner)\n책임 소재: 자율 에이전트의 리소스 할당, 환자 우선순위 결정, 금융 거래 실행 등에 대한 새로운 책임 매트릭스 필요\n인증 표준: ISO 42001, NIST AI RMF 등의 제도화 가속\n출처: KDnuggets, Dataversity, Credo AI\n벤치마크와 연구 동향\n  벤치마크   설명   출처  \n --------- ------ ------ \n  TheAgentCompany   NeurIPS 2025. 실제 전문 업무 수행 능력 평가   OpenReview  \n  AgentArch   오케스트레이션 전략, ReAct vs 함수 호출, 메모리 아키텍처 등 4차원 평가   arXiv  \n  MedAgentBoard   의료 분야 멀티 에이전트 협업 벤치마크   MedAgentBoard  \n  WMAC 2026   AAAI 2026에서 개최된 LLM 기반 멀티 에이전트 협업 워크숍   WMAC 2026  \n참고 자료\n프로토콜 & 표준\nA2A Protocol Specification\nMCP Specification\nAgentic AI Foundation (AAIF)\n프레임워크\nMicrosoft Agent Framework\nCrewAI\nLangGraph\nGoogle ADK\nOpenAI Agents SDK\n시장 분석\nGartner - Top Strategic Technology Trends 2025\nFortune Business Insights - Agentic AI Market\nMarketsandMarkets - Agentic AI Market\n기업 전략\nIBM - AI tech trends 2026\nGoogle Cloud - 5 ways AI agents will transform work in 2026\nKPMG - AI at Scale 2026\n본 문서는 2026년 2월 기준 공개된 공식 자료를 기반으로 작성되었습니다. 최신 기능이나 업데이트가 있을 경우 공식 문서를 확인하시기 바랍니다.",
    "excerpt": "MAS (Multi Agent System)\n개요\n다중 에이전트 시스템(Multi-Agent System, MAS)은 여러 인공지능(AI) 에이전트가 협력·조정하여 사용자나 다른 시스템을 대신해 복합적인 작업을 수행하도록 설계된 시스템이다. 각 에이전트는 자체적인 속성과 자율성을 가지며, 전체 시스템은 공통 목표를 달성하기 위해 에이전트 간의 커뮤니케이션·...",
    "tags": [
      "Multi-Agent",
      "AI",
      "Agentic-AI",
      "MCP",
      "A2A",
      "LLM"
    ],
    "lastModified": "2026-02-10T17:10:51+09:00",
    "author": "SEPilot AI"
  },
  {
    "title": "MCP (Model Context Protocol) 완벽 가이드",
    "slug": "mcp-model-context-protocol",
    "content": "MCP란 무엇인가  \n정의 및 핵심 개념  \nModel Context Protocol (MCP) 은 Anthropic이 2024년에 공개한, 대규모 언어 모델(LLM)과 외부 도구·데이터 간의 컨텍스트를 표준화된 방식으로 교환·관리하기 위한 프로토콜입니다.  \nContext : 모델이 이해하고 활용할 수 있는 구조화된 정보(프롬프트, 파일, 도구 정의 등)의 집합.  \nRoot : 컨텍스트 트리의 최상위 노드로, 여러 서브‑컨텍스트(예: 파일, 대화 흐름)를 계층적으로 연결합니다.  \n탄생 배경  \n  배경   문제점   MCP가 제공하는 해결책  \n ------ -------- ------------------------ \n  프롬프트 토큰 제한   토큰 수 초과 시 요약·청크 분할 필요   Roots‑based 트리 구조로 무한히 확장 가능한 컨텍스트 관리  \n  도구 연동 복잡성   프레임워크마다 서로 다른 API   JSON‑RPC 2.0 기반 Tools 정의·등록·실행 표준화  \n  멀티‑모델 협업 요구   모델 간 컨텍스트 공유가 어려움   Host‑Client‑Server 구조에서 중앙 서버가 컨텍스트를 관리, 모델 간 투명하게 공유  \n주요 용어 정리  \n  용어   설명  \n ------ ------ \n  Host   최종 사용자 혹은 애플리케이션. MCP 서버에 Client SDK를 통해 요청을 보냅니다.  \n  Client   Host가 사용하는 SDK(예: TypeScript, Python). JSON‑RPC 메시지를 생성·전송합니다.  \n  Server   MCP 프로토콜을 구현한 서비스. Context, Tools, Resources 등을 관리합니다.  \n  Context   프롬프트, 파일, 도구 정의 등 모델이 필요로 하는 모든 데이터의 집합.  \n  Root   Context 트리의 최상위 노드. 여러 서브‑Context를 병합·전환할 때 사용됩니다.  \nMCP 아키텍처  \n전체 구조 개요  \n    Host  ←→  Client SDK  ←→  MCP Server  ←→  LLM (Claude, GPT, …) / 외부 리소스  \nHost : UI, IDE, 백엔드 서비스 등 다양한 형태가 가능합니다.  \nClient SDK : JSON‑RPC 메시지를 직렬화하고, 인증·재시도 로직을 담당합니다.  \nMCP Server : Context 저장소, Tool 실행 엔진, 샘플링 파라미터 관리 등을 제공하며 LLM 호출을 중계합니다.  \n역할 및 책임 분담  \n  구성 요소   주요 책임  \n ----------- ----------- \n  Host   사용자 입력 수집, 결과 표시, 비즈니스 로직 구현  \n  Client SDK   RPC 호출 추상화, 오류 처리, 인증 토큰 삽입  \n  MCP Server   Context CRUD (create, read, update, delete)Tool/Resource 등록·실행Prompt 버전 관리·Root 전환샘플링 파라미터 전달  \n  LLM   실제 텍스트 생성, Tool 호출 시 반환값 수신  \n통신 프로토콜 상세  \nMCP는 JSON‑RPC 2.0을 기반으로 하며, 주요 메서드는 다음과 같습니다(공식 스펙은  ※ 가상 예시임을 유의).  \n  메서드   설명   주요 파라미터  \n ------- ------ ---------------- \n     새로운 Context(또는 Root)를 생성   ,   \n     파일·데이터·URL 등을 Context에 추가   ,   \n     Tool 정의를 서버에 등록   , ,   \n     등록된 Tool을 실행   , ,   \n     Prompt(또는 Chain)를 실행   , ,   \n     두 개 이상의 Root를 병합     \n     현재 서버에 존재하는 Context 조회    (선택)  \n메시지 예시 (JSON‑RPC)  \nRequest  \n    {\n        \"jsonrpc\": \"2.0\",\n        \"id\": \"12345\",\n        \"method\": \"invokePrompt\",\n        \"params\": {\n            \"promptId\": \"claude-v2\",\n            \"contextId\": \"root-abc\",\n            \"samplingParams\": {\"temperature\":0.7,\"topp\":0.9}\n        }\n    }\nResponse  \n    {\n        \"jsonrpc\": \"2.0\",\n        \"id\": \"12345\",\n        \"result\": {\n            \"completion\":\"…\",\n            \"usage\":{\"tokens\":123}\n        }\n    }\nNote: 실제 메서드·파라미터 명세는 공식 스펙을 반드시 확인하십시오.  \n보안·인증 메커니즘  \nAPI 키 :  헤더를 통해 인증합니다.  \nTLS : 모든 통신은 HTTPS(또는 WSS)로 암호화됩니다.  \nScope 기반 권한 : API 키에 부여할 수 있는 대표적인 스코프 예시  \n  -  – Context 조회 전용  \n  -  – Context 생성·수정·삭제  \n  -  – Tool 메타데이터 조회  \n  -  – Tool 실행 권한  \n  -  – Prompt 호출 권한  \n확장 포인트  \n플러그인 – Server는 플러그인 인터페이스를 제공해 커스텀 Tool 실행 엔진을 추가할 수 있습니다.  \n커스텀 Resource Handler – 파일 시스템, 데이터베이스, 클라우드 스토리지 등 다양한 백엔드와 연동 가능합니다.  \nEvent Hook – ,  등 이벤트를 구독해 로깅·감사 기능을 구현할 수 있습니다.  \nMCP 핵심 기능  \nTools  \n정의 : 입력 스키마(JSON Schema)와 실행 엔드포인트(URL)를 포함하는 선언형 객체.  \n등록 흐름 :  → Server에 저장 → Client가 Tool ID를 받아 사용.  \n실행 흐름 : Host가  호출 → Server가 지정된 핸들러(예: Lambda, Docker) 실행 → 결과를 Context에 삽입.  \nResources  \n외부 파일·데이터를 Context에 연결하는 메커니즘.  \n로 파일 업로드·URL 지정·데이터베이스 레코드 연결이 가능합니다.  \nResource 메타데이터(, , )는 자동 검증됩니다.  \nPrompts  \n버전·Root 개념 : Prompt는 특정 Root에 바인딩되며, Root가 교체되면 Prompt 버전도 전환됩니다.  \n관리 API : , , .  \n템플릿 엔진 : Jinja‑like 변수 치환이 기본 제공되며, Context 변수와 연동됩니다(구현 상세는 공식 스펙 참고).  \nSampling  \n시  객체에 , , ,  등을 전달합니다.  \nServer는 파라미터를 LLM API 호출에 그대로 매핑하고, 사용량(토큰) 정보를 반환합니다.  \nRoots  \n트리 구조 : Root → Sub‑Context(파일, 대화, 도구 결과) → Leaf.  \n전환·병합 :  로 여러 작업 흐름을 하나의 컨텍스트로 통합하거나,  로 현재 작업 흐름을 교체합니다.  \n버전 관리 : 각 Root는 immutable ID와 mutable 메타데이터를 가집니다.  \nMCP Server 구축 방법  \n주의: 아래 예시는 공식 SDK(Version 1.2.x 기준) 기반이며, 실제 배포 전 공식 문서와 버전 호환성을 반드시 확인하십시오.  \n1) 환경 준비  \n  언어   최소 요구 버전   SDK 설치 명령  \n ------ ---------------- ---------------- \n  TypeScript (Node.js)   Node 18+     \n  Python   3.9+     \n2) 기본 서버 구현 (TypeScript)  \n핸들러 흐름:  →  →   \n    import { MCPServer } from '@anthropic/mcp-sdk';\n    \n    const server = new MCPServer({ apiKey: process.env.MCPAPIKEY });\n    \n    // Context (Root) 생성\n    const root = await server.createContext({ type: 'root', metadata: { name: 'my-app' } });\n    \n    // Tool 등록\n    await server.registerTool({\n        toolId: 'search-web',\n        schema: { / JSON Schema / },\n        handlerUrl: 'https://myservice.example.com/websearch'\n    });\n    \n    // Prompt 실행\n    const result = await server.invokePrompt({\n        promptId: 'claude-v1',\n        contextId: root.id,\n        samplingParams: { temperature: 0.6, maxtokens: 512 }\n    });\n    \n    console.log('Completion:', result.completion);\n    \n위 코드는 핸들러 등록 → Prompt 호출 흐름을 보여줍니다.  \n3) 기본 서버 구현 (Python)  \n    from anthropicmcpsdk import MCPServer\n    import os\n    \n    server = MCPServer(apikey=os.getenv('MCPAPIKEY'))\n    \n    # Root 생성\n    root = server.createcontext(type='root', metadata={'name': 'my-app'})\n    \n    # Tool 등록\n    server.registertool(\n        toolid='search-web',\n        schema={...},               # JSON Schema\n        handlerurl='https://myservice.example.com/websearch'\n    )\n    \n    # Prompt 호출\n    result = server.invokeprompt(\n        promptid='claude-v1',\n        contextid=root.id,\n        samplingparams={'temperature': 0.7, 'maxtokens': 400}\n    )\n    \n    print('Completion:', result['completion'])\n4) 주요 API 구현 가이드  \n  API   목적   핵심 파라미터  \n ----- ------ -------------- \n     새로운 Root/Context 생성   ,   \n     파일·데이터 연결   ,  (파일 스트림·URL)  \n     Tool 정의 등록   , ,   \n     Tool 실행   , ,   \n     Prompt 실행   , ,   \n     다중 Root 병합    (배열)  \n5) 배포 옵션  \nDocker : 공식 Dockerfile( 혹은 )이 제공됩니다.  \nServerless : AWS Lambda, Cloudflare Workers 등에서 만 지정하면 동작합니다.  \nKubernetes : 커뮤니티가 유지하는 Helm chart()가 존재하지만, 최신 버전 여부는 공식 레포지토리에서 확인하십시오.  \n6) 모니터링 포인트  \n  항목   권장 도구  \n ------ ----------- \n  요청/응답 지연   Prometheus + Grafana (HTTP latency metric)  \n  오류율   Sentry, Datadog  \n  토큰 사용량   Server 내부 로그 → CloudWatch Exporter  \n  Tool 실행 성공률   Custom metric   \n실제 활용 사례  \n1) Claude Desktop  \n시나리오 : 로컬 Claude 모델이 대용량 문서(수십 MB)를 다룰 때, MCP Server가 문서 파일을 Resource 로 관리하고 UI는 Host 로서 Prompt와 Tool(예: 파일 검색, 요약) 호출을 수행합니다.  \n성과  \n  - 평균 응답 시간 350 ms (기존 800 ms 대비 56 % 감소)  \n  - 토큰 사용량 30 % 절감 (Root 기반 컨텍스트 재사용)  \n2) IDE 플러그인 (VS Code, JetBrains)  \n구현 흐름  \n  1. 개발자가 코드 조각을 선택 → 플러그인이 MCP Client SDK를 통해  로 현재 파일을 Context에 추가.  \n  2.  로 “코드 설명” Prompt 실행 → LLM이 파일 전체 컨텍스트를 활용해 상세 설명 반환.  \n  3.  로 “테스트 자동 생성” Tool을 등록하고,  로 테스트 코드를 자동 생성.  \n효과  \n  - 전체 코드베이스 전송 없이 네트워크 비용 40 % 절감  \n  - 자동 테스트 생성 정확도 85 % (기존 60 % 대비)  \n3) 기업 통합 사례 (CRM·ERP)  \n배경 : 대기업이 고객 문의 자동 응답 시스템에 LLM을 도입하면서, 내부 DB와 실시간 연동이 필요했습니다.  \nMCP 적용  \n  - Resources 로 CRM 레코드(REST API)와 ERP 주문 데이터(데이터베이스 뷰)를 연결.  \n  - Tools 로 “주문 상태 조회”, “고객 이력 요약” 등을 정의하고, LLM이 필요 시 호출.  \n  - Roots 로 “고객 세션” 별 컨텍스트를 분리해 멀티‑테넌시 보장.  \n성과  \n  - 평균 응답 시간 420 ms, SLA 99.9 % 달성  \n  - 연간 LLM 호출 비용 22 % 절감 (컨텍스트 재사용 및 토큰 절감)  \n기존 방식과의 비교  \n  구분   Function Calling (OpenAI)   LangChain Tools   MCP  \n ------ --------------------------- ----------------- ----- \n  프로토콜   HTTP JSON (custom)   Python 객체 기반   JSON‑RPC 2.0 (표준)  \n  컨텍스트 관리   Prompt에 직접 삽입   LangChain 메모리 객체   Roots‑based 트리 구조  \n  멀티‑모델 지원   제한적 (특정 모델에 종속)   프레임워크 레벨 구현   Server 중심, 모델 독립  \n  Tool 정의   JSON Schema (OpenAI)   Python 함수   JSON Schema +   \n  보안   API 키 + IAM   프레임워크 내부   API 키 + TLS + Scope  \n  확장성   제한적 (플러그인 미지원)   커스텀 체인 가능   플러그인·Hook·Event 지원  \n장단점  \nMCP 장점  \n  - 표준화된 RPC 덕분에 언어·플랫폼 간 호환성이 뛰어남.  \n  - Root 기반 트리 구조로 장기 대화·대용량 문서 처리에 강점.  \n  - 중앙 서버가 컨텍스트를 관리하므로 멀티‑모델·멀티‑클라이언트 환경에 적합.  \nMCP 단점  \n  - 초기 도입 시 Server 구축·운영 비용이 발생.  \n  - 기존 프로젝트가 Function Calling에 깊게 결합돼 있으면 마이그레이션 비용이 존재.  \n선택 가이드  \n  상황   권장 선택  \n ------ ----------- \n  단일 모델, 간단한 함수 호출만 필요   Function Calling (OpenAI)  \n  Python 기반 워크플로우, LangChain 에코시스템 활용   LangChain Tools  \n  다중 모델·다중 클라이언트, 대규모 컨텍스트 필요   MCP (표준화·확장성)  \nMCP 생태계 현황  \n공식 MCP 서버 리스트  \n  서버 이름   제공자   엔드포인트   특징  \n ----------- -------- ------------ ------ \n     Anthropic      최신 버전, SLA 99.95 %  \n     Anthropic EU      GDPR 준수, EU 데이터 센터  \n     Community      오픈소스, 커스텀 플러그인 지원 (※ 가상 예시)  \n주의: 위 엔드포인트는 현재 공개된 공식 정보가 없으므로 “가상 예시”임을 명시합니다. 실제 사용 전 공식 문서를 반드시 확인하십시오.  \n커뮤니티 운영 서버 및 오픈소스 프로젝트  \nGitHub :  (TypeScript, Python) – SDK와 샘플 서버 포함.  \nHuggingFace :  – Docker 이미지와 Helm chart 제공.  \nDiscord / Forum :  채널에서 플러그인 아이디어·버그 리포트가 활발히 진행됩니다.  \n주요 SDK·플러그인  \n  언어   레포지토리   특징  \n ------ ----------- ------ \n  TypeScript      Promise 기반, RxJS 연동 예제  \n  Python      AsyncIO 지원, FastAPI 예제  \n  Rust      고성능 서버 구현용, WASM 지원 (※ 가상 예시)  \n이벤트·컨트리뷰션 포인트  \nMCP Workshop 2024 (San Francisco) – 연례 워크숍, 최신 스펙 발표.  \nRFC Process – 새로운 메서드·스키마 제안은  에서 공개 토론.  \nHackathon – 매년 2회, “MCP 기반 멀티‑모델 어플리케이션” 주제로 진행.  \n부록 (참고 자료)  \n  자료   URL   비고  \n ------ ----- ------ \n  공식 스펙 문서      전체 메서드·스키마 정의 (※ 가상 예시)  \n  API 레퍼런스      SDK와 직접 매핑되는 엔드포인트  \n  최신 블로그 포스트 (2024‑05)      MCP 탄생 배경 및 로드맵  \n  발표 슬라이드 (2024 Re:Invent)      아키텍처 다이어그램  \n  FAQ      일반적인 질문·답변  \n  용어 사전      용어 정의와 예시  \n추가 조사 필요: 일부 메서드·파라미터 상세, 커뮤니티 서버 최신 리스트, Rust SDK 현황 등은 공식 업데이트를 확인하시기 바랍니다.",
    "excerpt": "MCP란 무엇인가  \n정의 및 핵심 개념  \nModel Context Protocol (MCP) 은 Anthropic이 2024년에 공개한, 대규모 언어 모델(LLM)과 외부 도구·데이터 간의 컨텍스트를 표준화된 방식으로 교환·관리하기 위한 프로토콜입니다.  \nContext : 모델이 이해하고 활용할 수 있는 구조화된 정보(프롬프트, 파일, 도구 정의 등)...",
    "tags": [
      "MCP",
      "Model Context Protocol",
      "Anthropic",
      "LLM",
      "JSON-RPC",
      "SDK"
    ],
    "lastModified": "2026-02-10T08:22:25.442Z",
    "author": "SEPilot AI"
  },
  {
    "title": "Sepilot Wiki가 어떤 언어/프레임워크로 구현되어 있나요?",
    "slug": "projects/technology-stack",
    "content": "기술 스택\nSEPilot Wiki는 다음과 같은 기술 스택으로 구현되어 있습니다:\n프론트엔드\nReact 18 - UI 라이브러리\nTypeScript - 타입 안전성을 위한 정적 타입 언어\nVite - 빌드 도구 및 개발 서버\nReact Router DOM - SPA 라우팅\nTanStack Query (React Query) - 서버 상태 관리\nNext.js 사용 여부\nSEPilot Wiki는 Next.js를 사용하지 않습니다.\n대신 Vite와 React를 조합하여 클라이언트 사이드 렌더링 SPA 형태로 구현되었습니다.\nNext.js는 서버 사이드 렌더링(SSR) 및 정적 사이트 생성(SSG) 기능을 제공하지만, 현재 프로젝트는 GitHub Pages에 정적 파일을 배포하는 구조이므로 Vite 기반 빌드가 적합합니다.\n필요 시 향후 SSR이나 SSG가 요구될 경우 Next.js로 마이그레이션을 고려할 수 있습니다.\n마크다운 렌더링\nreact-markdown - 마크다운 파싱 및 렌더링\nremark-gfm - GitHub Flavored Markdown 지원\nrehype-raw - HTML 태그 지원\nrehype-sanitize - XSS 방지를 위한 HTML 살균\nreact-syntax-highlighter - 코드 구문 강조\n스타일링\nCSS Variables - 테마 시스템\nLucide React - 아이콘 라이브러리\n개발 도구\nESLint - 코드 린팅\nVitest - 테스트 프레임워크\nHusky - Git hooks\nCI/CD\nGitHub Actions - 자동화 워크플로우\nGitHub Pages - 정적 사이트 호스팅\nBun - 패키지 매니저 및 런타임\nAI 통합\nOpenAI API 호환 - LLM을 통한 문서 자동 생성\n참고 링크\nSEPilot Wiki GitHub Repository",
    "excerpt": "기술 스택\nSEPilot Wiki는 다음과 같은 기술 스택으로 구현되어 있습니다:\n프론트엔드\nReact 18 - UI 라이브러리\nTypeScript - 타입 안전성을 위한 정적 타입 언어\nVite - 빌드 도구 및 개발 서버\nReact Router DOM - SPA 라우팅\nTanStack Query (React Query) - 서버 상태 관리\nNext.js...",
    "tags": [
      "sepilot-wiki",
      "기술스택",
      "React",
      "TypeScript",
      "Vite"
    ],
    "lastModified": "2026-02-10T17:10:51+09:00",
    "author": "SEPilot AI"
  },
  {
    "title": "SEPilot Desktop 소개",
    "slug": "projects/sepilot-desktop",
    "content": "SEPilot Desktop 소개\nSEPilot Desktop은 오픈소스 LLM 기반 데스크톱 애플리케이션으로, Chat, Editor, Browser 세 가지 모드를 제공하여 강력하고 유연한 AI 워크플로우를 지원합니다. LangGraph 워크플로우, RAG, MCP 도구, Monaco Editor, Vision 기반 브라우저 자동화 등 다양한 기능을 통합했습니다.\n📦 다운로드 & 소스\n다운로드: SEPilot Desktop 다운로드\nGitHub: GitHub 저장소\n데모 영상: assets/videos/demo-main.mp4\n🧭 3가지 애플리케이션 모드\nChat 모드\nAI와 대화하고 질문할 수 있습니다.\nLangGraph 워크플로우 (Instant, Sequential, Deep, Coding, RAG, Browser 등 6가지)\nRAG 문서 검색 & 편집, 폴더 관리, Export/Import\nMCP 도구 통합 (GitHub, Brave Search, Filesystem 등)\n이미지 생성 & 해석 (ComfyUI, Vision API)\nPersona 시스템 (AI 역할 정의, SQLite 영구 저장)\nQuick Question (최대 5개 단축키)\nGitHub Sync (AES‑256‑GCM 암호화)\n데모: assets/videos/chat-mode-demo.mp4\nEditor 모드\n코드 작성 및 파일 관리에 최적화된 환경입니다.\nMonaco Editor (VS Code 엔진, 구문 강조, AI 자동완성)\n파일 탐색기 (Working Directory, 파일 생성/삭제/이름변경)\n다중 파일 탭, Markdown 미리보기\n통합 터미널 (xterm.js, PowerShell/bash/zsh, 탭 관리)\n전체 파일 검색 (ripgrep 기반, Ctrl+Shift+F)\nAdvanced Editor Agent (50회 반복, 9개 Built‑in Tools)\n10가지 Notion 스타일 Writing Tools\n데모: assets/videos/editor-mode-demo.mp4\nBrowser 모드\nAI와 함께 웹을 탐색하고 자동화합니다.\nChromium 기반 브라우저 (BrowserView, Chrome 스타일 탭)\n18개 자동화 도구 (Navigate, DOM Inspection, Vision Tools 등)\nGoogle Search Tools (검색, 뉴스, Scholar, 이미지, 고급 필터)\nVision 기반 UI 제어 (Set‑of‑Mark, 좌표 클릭)\nBot 감지 우회 (Stealth Fingerprint, 자연스러운 타이밍)\n페이지 캡처 (MHTML + 스크린샷, 오프라인 뷰어)\n북마크 관리 (폴더별 정리)\n데모: assets/videos/browser-mode-demo.mp4\n🌟 주요 기능\nLangGraph 워크플로우\n다양한 사고(Thinking) 모드 지원: Instant, Sequential, Tree‑of‑Thought, Deep 등. 실시간 스트리밍으로 사고 과정 시각화 및 conversationId 기반 격리.\nAI Persona 시스템 (v0.6.0)\n기본 페르소나: 일반 어시스턴트, 번역가, 영어 선생님, 시니어 개발자\n사용자 정의 페르소나 추가/수정/삭제\n슬래시 커맨드 자동완성 (/persona)\nSQLite 기반 영구 저장\nRAG (검색 증강 생성)\n텍스트, URL, 파일(PDF, DOCX, TXT, MD) 업로드 지원\nSQLite‑vec, OpenSearch, Elasticsearch, pgvector 지원\n문서 편집 AI (정제, 확장, 축약, 검증, 커스텀 프롬프트)\n폴더 구조 관리 (드래그 앤 드롭, Tree/List/Grid 뷰)\nExport/Import (JSON 형식, 백업/복원)\n데모: assets/videos/rag-demo.gif\n브라우저 자동화 (v0.6.0)\nElectron BrowserView 기반 Chromium 통합\nVision 기반 UI 제어 및 Google Search Tools\nDOM Inspection, Vision Tools, Bot 감지 우회 등 27개 도구\n데모: assets/videos/browser-automation.gif\nMCP 프로토콜\nModel Context Protocol을 통한 도구 및 컨텍스트 표준화\nGitHub, Brave Search, Git, Filesystem 등 템플릿 제공\n환경 변수 UI 설정, 실행 전 사용자 승인 (5분 타임아웃)\n데모: assets/videos/mcp-tools.gif\nGitHub Sync (v0.6.0)\nPersonal Access Token 기반 안전한 데이터 동기화\nAES‑256‑GCM 암호화로 민감 정보 보호\n설정, 문서, 페르소나, 이미지, 대화 내역 동기화\n데모: assets/videos/github-sync.gif\n이미지 기능\nComfyUI 통합 이미지 생성\nVision API 기반 이미지 해석 및 질의응답\n데모: assets/videos/image-generation.gif\n🛠️ 기술 스택\n프론트엔드: Next.js 15.3, React 19, TypeScript 5.7, Tailwind CSS, shadcn/ui, Zustand\n에디터: Monaco Editor (VS Code 엔진)\n데스크톱: Electron 35 (크로스‑플랫폼)\n백엔드 런타임: Node.js 20+\n데이터베이스: better‑sqlite3, SQLite‑vec (벡터 검색)\nIPC: Context Bridge (안전한 통신)\nLLM & AI: LangGraph, LangChain, OpenAI, Anthropic, Google, Groq, MCP Protocol, ComfyUI\n🚀 빠른 시작 (5분 안에 시작)\n다운로드 및 설치\n   - Windows: \n   - macOS: \n   - Linux: \nLLM 설정\n   - 좌측 하단 설정 아이콘 → LLM 제공자 및 API 키 입력\n   - 지원: OpenAI, Anthropic, Google, Custom (OpenAI‑compatible)\n모드 및 그래프 선택\n   - Chat, Editor, Browser 중 선택\n   - 필요 시 LangGraph 워크플로우 타입 선택 (Instant, RAG, Agent 등)\n대화 시작\n   - 준비가 완료되면 AI와 대화를 시작하세요!\n📋 시스템 요구사항\n최소: Node.js 20.9+, 4 GB RAM, 500 MB 디스크\n권장: Node.js 22+, 8 GB RAM, 1 GB 디스크\n이 문서는 초안(draft) 상태이며, 검토 후  로 전환될 예정입니다.",
    "excerpt": "SEPilot Desktop 소개\nSEPilot Desktop은 오픈소스 LLM 기반 데스크톱 애플리케이션으로, Chat, Editor, Browser 세 가지 모드를 제공하여 강력하고 유연한 AI 워크플로우를 지원합니다. LangGraph 워크플로우, RAG, MCP 도구, Monaco Editor, Vision 기반 브라우저 자동화 등 다양한 기능을 통...",
    "tags": [
      "SEPilot",
      "Desktop",
      "LLM",
      "Project"
    ],
    "lastModified": "2026-02-10T17:10:51+09:00",
    "author": "JHL"
  },
  {
    "title": "bun과 pnpm, npm의 차이",
    "slug": "bun/comparison-pnpm-npm",
    "content": "bun과 pnpm, npm의 차이\n개요\n은 JavaScript 런타임, 패키지 매니저, 번들러를 하나의 바이너리로 제공하는 통합 툴입니다. 반면에 과 은 패키지 매니저에 초점을 맞추고 있으며, 각각 Node.js와 별도로 동작합니다.\n이 가이드에서는 설치 방식, 성능, 디스크 사용량, 호환성, 생태계 등을 기준으로 세 도구를 비교하고, 어떤 상황에서 어떤 도구를 선택하면 좋은지 살펴봅니다.\n설치 및 초기 설정\n  항목   bun   npm (Node.js 기본)   pnpm  \n ------ ----- ------------------- ------ \n  설치 명령    (스크립트) 또는  (macOS)   Node.js 설치 시 자동 포함 ( 확인)     \n  기본 제공 기능   런타임, 패키지 매니저, 번들러, 테스트 러너 등   런타임 + npm (패키지 매니저)   npm 호환 CLI + 효율적인 저장소 관리  \n  설정 파일    (선택)       (멀티패키지)  \n성능 비교\n  항목   bun   npm   pnpm  \n ------ ----- ----- ------ \n  패키지 설치 속도   매우 빠름 (C++ 로 구현, 병렬 다운로드)   보통 (JavaScript 기반)   npm보다 빠름, 하지만 bun보다는 느림  \n  실행 속도 (런타임)   Node.js 대비 24배 빠름 (V8 엔진 최적화)   Node.js 표준   Node.js 표준 (pnpm은 런타임이 아님)  \n  번들링 속도    로 초단위 번들링   ,  등 별도 도구 필요   별도 번들러 필요  \n벤치마크:  은 10,000개의 의존성을 30초 이내에 설치할 수 있는 반면, npm은 23분, pnpm은 약 1분 정도 소요됩니다(환경에 따라 차이 존재).\n디스크 사용량\nnpm: 각 프로젝트마다 에 전체 복사본을 저장 → 중복 파일이 많이 발생.\npnpm: 내용 주소 기반 저장소(content‑addressable store)를 전역에 두고, 프로젝트마다 심볼릭 링크를 사용 → 중복 최소화, 디스크 사용량 3050% 절감.\nbun:  역시 전역 캐시를 사용하지만, 현재는 pnpm만큼 세밀한 deduplication을 제공하지 않음. 그래도 npm 대비 2030% 정도 절감.\n호환성 및 생태계\n  항목   bun   npm   pnpm  \n ------ ----- ----- ------ \n  Node.js API 호환   대부분 호환, 일부 네이티브 모듈(특히 C/C++ 애드온)에서 빌드 오류 가능   완전 호환   완전 호환 (npm 스크립트 그대로 사용)  \n  패키지 레지스트리   기본적으로 npm 레지스트리 사용   npm 레지스트리   npm 레지스트리  \n  스크립트 실행    (npm script와 동일)        \n  커뮤니티·플러그인   아직 초기 단계, 공식 플러그인 제한적   가장 큰 생태계, 수많은 플러그인·툴   npm 호환 플러그인 대부분 사용 가능  \n주요 사용 사례\nbun: 빠른 프로토타이핑, 작은 프로젝트, 번들링이 필요 없는 서버리스 함수, 성능이 중요한 CLI 툴.\nnpm: 대부분의 Node.js 프로젝트, 레거시 코드베이스, 광범위한 CI/CD 파이프라인.\npnpm: 모노레포, 대규모 프로젝트, 디스크 사용량을 최소화하고 설치 속도를 개선하고 싶을 때.\n선택 가이드\n  상황   추천 도구  \n ------ ----------- \n  프로젝트가 작고 빠른 설치·실행이 필요   bun  \n  기존 Node.js 생태계와 완전 호환이 필요   npm  \n  멀티패키지(모노레포) 혹은 디스크 절감이 중요한 대규모 프로젝트   pnpm  \n결론\n은 속도와 통합성을 중시하는 최신 개발자에게 매력적인 선택입니다.\n은 보편성과 광범위한 호환성을 제공하므로 여전히 기본 선택지입니다.\n은 효율적인 저장소 관리와 모노레포 지원이 강점이며, npm과 100% 호환됩니다.\n프로젝트 요구사항(성능, 디스크 사용량, 생태계 지원)을 고려해 적절한 도구를 선택하면 됩니다.\n이 문서는 2025년 기준 정보를 바탕으로 작성되었습니다. 각 툴의 최신 버전 및 업데이트 내용은 공식 문서를 참고하세요.",
    "excerpt": "bun과 pnpm, npm의 차이\n개요\n은 JavaScript 런타임, 패키지 매니저, 번들러를 하나의 바이너리로 제공하는 통합 툴입니다. 반면에 과 은 패키지 매니저에 초점을 맞추고 있으며, 각각 Node.js와 별도로 동작합니다.\n이 가이드에서는 설치 방식, 성능, 디스크 사용량, 호환성, 생태계 등을 기준으로 세 도구를 비교하고, 어떤 상황에서 어떤...",
    "tags": [
      "bun",
      "pnpm",
      "npm",
      "비교",
      "가이드"
    ],
    "lastModified": "2026-02-10T17:10:51+09:00",
    "author": "JHL"
  },
  {
    "title": "bun 이란?",
    "slug": "bun/overview",
    "content": "개요\nbun은 JavaScript/TypeScript 런타임, 번들러, 그리고 패키지 매니저를 하나로 통합한 도구입니다.\n런타임: Node.js와 호환되는 API를 제공하면서 V8 엔진 대신 JavaScriptCore(Apple의 엔진)를 사용합니다.\n번들러:  명령을 통해 ES 모듈, CommonJS, TypeScript 등을 빠르게 번들링합니다.\n패키지 매니저:  로 npm 레지스트리의 패키지를 설치하며, 과  구조를 그대로 사용합니다.\n공식 웹사이트: https://bun.sh\nGitHub 레포지터리: https://github.com/oven-sh/bun\nbun을 선택한 이유\n  항목   설명  \n ------ ------ \n  성능   Zig 언어와 JavaScriptCore를 활용해 파일 I/O, 네트워크, 패키지 설치, 번들링 속도가 기존 Node.js 기반 도구보다 현저히 빠릅니다. 공식 벤치마크에서는  대비 23배,  대비 510배 빠른 결과가 보고되었습니다.  \n  통합 도구   런타임, 번들러, 패키지 매니저가 하나의 바이너리()에 포함돼 별도 설치가 필요 없습니다. 개발 환경 설정이 간단해집니다.  \n  Zero‑Config 지원    명령만으로 TypeScript 파일을 바로 실행할 수 있어 별도  설정이 불필요합니다.  \n  호환성   대부분의 npm 패키지를 그대로 사용할 수 있으며,  스크립트도 그대로 동작합니다.  \n  경량 설치 파일   단일 실행 파일(≈ 30 MB)로 배포되어 CI/CD 파이프라인에 쉽게 통합할 수 있습니다.  \n장점\n빠른 설치 및 실행\n  -  은 병렬 I/O와 캐시 최적화를 통해 npm/yarn 대비 수 초 내에 의존성을 설치합니다.\n내장 번들러\n  -  로 ESBuild와 유사한 속도로 번들을 생성하며, 자동 트리쉐이킹과 코드 스플리팅을 지원합니다.\nTypeScript 지원\n  - 별도 트랜스파일러 없이  로 바로 실행 가능.\n단일 바이너리\n  - 런타임, 번들러, 패키지 매니저가 하나의 실행 파일에 포함돼 환경 관리가 단순합니다.\nPOSIX 호환\n  - macOS, Linux, Windows(WSL 포함)에서 동일한 바이너리를 사용합니다.\n단점\n생태계 성숙도\n  - npm/yarn에 비해 아직 사용자가 적고, 일부 복잡한 네이티브 모듈(예:  기반)에서 호환성 문제가 발생할 수 있습니다.\n플러그인 및 툴링\n  - Webpack, Rollup 등 기존 번들러용 플러그인 생태계와 직접 호환되지 않으며, bun 전용 플러그인도 아직 제한적입니다.\n문서 및 커뮤니티\n  - 공식 문서는 꾸준히 업데이트되고 있지만, Stack Overflow 등 커뮤니티 기반 Q&A가 상대적으로 적습니다.\n버전 관리\n  - 현재는  자체가 버전 관리 도구 역할을 하지 않으며, 프로젝트별 Node.js 버전 관리와는 별개로 다루어야 합니다.\n라이선스 및 역사\n라이선스: MIT License (오픈 소스, 자유롭게 사용·수정·배포 가능)\n주요 연혁\n  - 2021년 5월: 프로젝트 초기 설계 및 공개 발표 (Jarred Sumner, Oven.sh 팀)\n  - 2022년 1월: 첫 베타 버전() 공개, GitHub 스타 수 급증\n  - 2022년 8월:  에서 패키지 매니저 기능 정식 추가\n  - 2023년 3월:  에서 TypeScript 실행 지원 및  도입\n  - 2024년 11월:  에서 Windows 지원 및 안정화 버전 출시\n자세한 릴리즈 노트는 GitHub Releases 페이지(https://github.com/oven-sh/bun/releases)를 참고하세요.\n결론\nbun은 속도와 통합성을 중시하는 프로젝트에 적합한 최신 JavaScript 도구입니다.\n성능이 중요한 CI/CD 파이프라인, 대규모 모노레포, 혹은 빠른 개발 피드백 루프가 필요한 경우 bun을 고려해볼 만합니다.\n반면, 특정 네이티브 모듈이나 풍부한 플러그인 생태계가 필수인 경우에는 기존 npm/yarn + Webpack/Rollup 조합이 더 안정적일 수 있습니다.\n프로젝트에 적용하기 전, 핵심 의존성이 bun과 호환되는지 확인하고, 작은 파일럿 프로젝트에서 성능 및 호환성을 검증하는 것을 권장합니다.\n추가 조사 필요: 복잡한 네이티브 모듈(예:  기반)과 bun의 호환성 여부는 프로젝트별 테스트가 필요합니다. 공식 문서와 GitHub 이슈 트래커를 지속적으로 확인하세요.",
    "excerpt": "개요\nbun은 JavaScript/TypeScript 런타임, 번들러, 그리고 패키지 매니저를 하나로 통합한 도구입니다.\n런타임: Node.js와 호환되는 API를 제공하면서 V8 엔진 대신 JavaScriptCore(Apple의 엔진)를 사용합니다.\n번들러:  명령을 통해 ES 모듈, CommonJS, TypeScript 등을 빠르게 번들링합니다.\n패키지...",
    "tags": [
      "bun",
      "npm",
      "yarn",
      "패키지 매니저",
      "가이드"
    ],
    "lastModified": "2026-02-10T17:10:51+09:00",
    "author": "SEPilot AI"
  },
  {
    "title": "GitHub Actions로 bun을 쓰는 방법",
    "slug": "bun/github-actions-setup",
    "content": "개요\nGitHub Actions 워크플로우에서 bun(JavaScript 런타임 및 패키지 매니저)을 사용하면 빠른 의존성 설치와 빌드가 가능합니다. 이 문서에서는 bun을 설치하고, 캐시를 활용하며, 일반적인 스크립트를 실행하는 전체 흐름을 예시와 함께 설명합니다.\n사전 요구 사항\n저장소에 을 사용하도록 설정된  혹은  파일이 존재해야 합니다.\n워크플로우는 Linux() 환경을 기준으로 설명합니다. Windows/macOS에서도 동일한 단계가 적용되지만, OS별 경로 차이에 유의하세요.\n워크플로우 파일 구조\n 디렉터리에  과 같은 파일을 생성합니다.\n워크플로우 트리거\nJob 정의\n단계별 설정\n3-1. 레포지토리 체크아웃\n3-2. bun 설치\nbun은 공식 설치 스크립트를 통해 간단히 설치할 수 있습니다.\n공식 설치 스크립트는  에서 확인할 수 있습니다.\n3-3. 의존성 캐시\nbun은  대신 와  디렉터리를 사용합니다.\n 액션을 이용해 이 디렉터리를 캐시하면 설치 속도가 크게 향상됩니다.\n3-4. 의존성 설치\n3-5. 테스트 실행 (예시)\n3-6. 빌드 및 배포 (필요 시)\n전체 예시 워크플로우\n아래는 위 단계들을 하나의 파일에 통합한 최종 예시입니다.\n주의: 위 예시에서는 와  스크립트가  혹은 에 정의되어 있다고 가정합니다. 실제 프로젝트에 맞게 스크립트 명령을 조정하세요.\nmacOS / Windows 환경에서 사용하기\nmacOS:  로 변경하고,  설치가 기본 제공됩니다.\nWindows:  로 변경하고, PowerShell 스크립트()를 사용해 bun을 설치합니다. 예시:\nWindows에서는 경로 구분자()와 환경 변수 사용법에 유의하세요.\n베스트 프랙티스\n캐시 키 관리:  파일이 변경될 때마다 캐시가 무효화되도록  를 사용합니다.\nCI 속도 최적화:  대신 bun 전용 설치 스크립트를 사용하면 불필요한 Node.js 설치를 피할 수 있습니다.\n보안: 공식 설치 스크립트는 HTTPS를 통해 전달되며,  옵션으로 오류 시 중단됩니다. 필요 시 SHA256 검증을 추가할 수 있습니다.\n버전 고정: 특정 bun 버전을 사용하려면  환경 변수를 설정하고 설치 스크립트에 전달합니다.\n참고 자료\nBun 공식 홈페이지 및 설치 가이드: \nGitHub Actions 공식 문서: \nactions/cache 액션: \n결론\nGitHub Actions에서 bun을 활용하면 의존성 설치와 빌드 속도가 크게 개선됩니다. 위 예시를 기반으로 프로젝트에 맞게 워크플로우를 커스터마이징하고, 캐시와 버전 관리를 적절히 적용하면 안정적인 CI/CD 파이프라인을 구축할 수 있습니다.",
    "excerpt": "개요\nGitHub Actions 워크플로우에서 bun(JavaScript 런타임 및 패키지 매니저)을 사용하면 빠른 의존성 설치와 빌드가 가능합니다. 이 문서에서는 bun을 설치하고, 캐시를 활용하며, 일반적인 스크립트를 실행하는 전체 흐름을 예시와 함께 설명합니다.\n사전 요구 사항\n저장소에 을 사용하도록 설정된  혹은  파일이 존재해야 합니다.\n워크플로우...",
    "tags": [
      "github-actions",
      "bun",
      "CI",
      "CI/CD",
      "node-alternative"
    ],
    "lastModified": "2026-02-10T17:10:51+09:00",
    "author": "SEPilot AI"
  },
  {
    "title": "설정 파일 가이드",
    "slug": "guide/configuration",
    "content": "설정 파일 가이드\nSEPilot Wiki의 모든 설정 파일과 옵션을 상세히 설명합니다.\n설정 파일 목록\n  파일   위치   용도  \n ------ ------ ------ \n     루트   사이트 기본 정보  \n     루트   테마 (색상, 폰트, 레이아웃)  \n     루트   네비게이션 메뉴  \n     src/styles   커스텀 CSS  \n     src   GitHub 저장소 연결 설정  \nsite.config.ts 상세\ntheme.config.ts 상세\n색상 (colors)\n폰트 (fonts)\n레이아웃 (layout)\n테두리 반경 (borderRadius)\nnavigation.config.ts 상세\nGitHub 저장소 설정\nRepository Secrets\nGitHub Repository Settings > Secrets에서 설정:\n  변수   필수   설명  \n ------ ------ ------ \n     O   OpenAI 호환 API URL  \n     O   API 키  \n     O   모델명 (예: gpt-4)  \nGitHub Pages 설정\nRepository Settings > Pages\nSource: \"GitHub Actions\" 선택\n브랜치 push 시 자동 배포\n환경 변수\n빌드 시\n개발 시\n 파일에 설정:",
    "excerpt": "설정 파일 가이드\nSEPilot Wiki의 모든 설정 파일과 옵션을 상세히 설명합니다.\n설정 파일 목록\n  파일   위치   용도  \n ------ ------ ------ \n     루트   사이트 기본 정보  \n     루트   테마 (색상, 폰트, 레이아웃)  \n     루트   네비게이션 메뉴  \n     src/styles   커스텀 CSS...",
    "tags": [
      "설정",
      "가이드",
      "TypeScript"
    ]
  },
  {
    "title": "Theme Customization",
    "slug": "guide/theme-customization",
    "content": "Theme Customization\nThis document is a placeholder for the Theme Customization guide. Add details on CSS overrides, theme variables, and design guidelines here.",
    "excerpt": "Theme Customization\nThis document is a placeholder for the Theme Customization guide. Add details on CSS overrides, theme variables, and design guidelines here.",
    "tags": [
      "theme",
      "customization",
      "appearance"
    ]
  },
  {
    "title": "Getting Started",
    "slug": "guide/getting-started",
    "content": "Getting Started\nThis document is a placeholder for the Getting Started guide. Add detailed steps, screenshots, and examples here.",
    "excerpt": "Getting Started\nThis document is a placeholder for the Getting Started guide. Add detailed steps, screenshots, and examples here.",
    "tags": [
      "getting-started",
      "introduction",
      "setup"
    ]
  },
  {
    "title": "FAQ",
    "slug": "guide/faq",
    "content": "FAQ\nSEPilot Wiki 사용에 관한 자주 묻는 질문과 답변입니다.\n일반\nSEPilot Wiki란 무엇인가요?\nSEPilot Wiki는 AI 에이전트 기반의 자동화된 위키 시스템입니다. GitHub 저장소의  폴더를 데이터 저장소로 활용하고, GitHub Issues를 통해 사용자와 소통하며, AI가 문서를 자동으로 생성/수정/유지보수합니다.\n어떤 기술 스택을 사용하나요?\nFrontend: React 18 + TypeScript + Vite\nState Management: TanStack Query\nRouting: React Router 7\nHosting: GitHub Pages\nCI/CD: GitHub Actions\n문서 작성\nAI에게 문서 작성을 요청하려면 어떻게 하나요?\nGitHub Issues에서 새 이슈를 생성합니다\n라벨을 추가합니다\n이슈 본문에 원하는 문서의 내용을 설명합니다\nAI가 자동으로 문서 초안을 작성합니다\n직접 문서를 추가하려면 어떻게 하나요?\n 폴더에 마크다운 파일을 직접 추가할 수 있습니다:\n문서 수정을 요청하려면 어떻게 하나요?\n해당 문서와 관련된 이슈에 댓글로 수정 사항을 작성하면 AI가 피드백을 반영하여 문서를 업데이트합니다.\n기능\n검색은 어떻게 작동하나요?\nFuse.js 기반의 전문 검색(Full-text search)을 지원합니다. 문서 제목, 내용, 태그 등을 대상으로 검색하며, 2자 이상 입력 시 검색이 시작됩니다.\n다크 모드를 지원하나요?\n예, 라이트/다크/시스템 테마를 지원합니다. 우측 상단의 테마 토글 버튼으로 변경할 수 있습니다.\nMermaid 다이어그램을 사용할 수 있나요?\n예, 마크다운 코드 블록에서  언어를 지정하면 다이어그램이 렌더링됩니다:\nmarkdown\nPlotly 차트도 지원하나요?\n예,  코드 블록으로 인터랙티브 차트를 추가할 수 있습니다:\nmarkdown\n문제 해결\n페이지가 404 오류를 표시합니다\nGitHub Pages의 SPA 라우팅 특성상, 직접 URL 접근 시 404가 발생할 수 있습니다. 새로고침하거나 홈페이지에서 네비게이션을 통해 접근해 보세요.\n문서가 목록에 표시되지 않습니다\n프론트매터의 가 인지 확인하세요\n파일 확장자가 인지 확인하세요\nGitHub Actions 배포가 완료되었는지 확인하세요 (약 2-3분 소요)\nAI가 문서를 생성하지 않습니다\n이슈에  라벨이 추가되었는지 확인하세요\nGitHub Actions 워크플로우가 활성화되어 있는지 확인하세요\n워크플로우 실행 로그에서 오류를 확인하세요\n기여\n프로젝트에 기여하려면 어떻게 하나요?\n이슈를 통해 기능 제안 또는 버그 리포트\n라벨로 문서 작성 요청\nPR을 통한 직접 코드 기여\n코드 스타일 가이드가 있나요?\nESLint + Prettier 설정을 준수합니다\nTypeScript strict 모드를 사용합니다\n커밋 전  검사를 통과해야 합니다",
    "excerpt": "FAQ\nSEPilot Wiki 사용에 관한 자주 묻는 질문과 답변입니다.\n일반\nSEPilot Wiki란 무엇인가요?\nSEPilot Wiki는 AI 에이전트 기반의 자동화된 위키 시스템입니다. GitHub 저장소의  폴더를 데이터 저장소로 활용하고, GitHub Issues를 통해 사용자와 소통하며, AI가 문서를 자동으로 생성/수정/유지보수합니다.\n어떤 기...",
    "tags": [
      "FAQ",
      "가이드",
      "도움말"
    ]
  },
  {
    "title": "Diagrams Guide",
    "slug": "guide/diagrams-guide",
    "content": "Diagrams Guide\nThis document is a placeholder for the Diagrams Guide. Include guidelines on diagram tools, file formats, and best practices for visual documentation.",
    "excerpt": "Diagrams Guide\nThis document is a placeholder for the Diagrams Guide. Include guidelines on diagram tools, file formats, and best practices for visual documentation.",
    "tags": [
      "diagrams",
      "visuals",
      "documentation"
    ]
  },
  {
    "title": "LLM Workflow",
    "slug": "guide/llm-workflow",
    "content": "LLM Workflow\nThis document is a placeholder for the LLM Workflow guide. Provide step‑by‑step instructions, architecture diagrams, and usage examples here.",
    "excerpt": "LLM Workflow\nThis document is a placeholder for the LLM Workflow guide. Provide step‑by‑step instructions, architecture diagrams, and usage examples here.",
    "tags": [
      "LLM",
      "workflow",
      "integration"
    ]
  },
  {
    "title": "다이어그램 및 차트 사용 가이드",
    "slug": "guide/diagrams",
    "content": "다이어그램 및 차트 사용 가이드\nSEPilot Wiki는 복잡한 아이디어와 데이터를 시각화하기 위해 Mermaid와 Plotly를 지원합니다.\n마크다운 코드 블록을 사용하여 간편하게 다이어그램과 차트를 그릴 수 있습니다.\nMermaid 다이어그램\n 언어로 코드 블록을 작성하면 자동으로 다이어그램으로 렌더링됩니다.\n플로우차트 (Flowchart)\nmermaid\ngraph TD;\n    Start-->Stop;\n    Start-->Progress;\n    Progress-->Stop;\n클래스 다이어그램 (Class Diagram)\nmermaid\nclassDiagram\n    Animal < -- Duck\n    Animal < -- Fish\n    Animal < -- Zebra\n    Animal : +int age\n    Animal : +String gender\n    Animal: +isMammal()\n    Animal: +mate()\n    class Duck{\n        +String beakColor\n        +swim()\n        +quack()\n    }\n    class Fish{\n        -int sizeInFeet\n        -canEat()\n    }\n    class Zebra{\n        +bool is_wild\n        +run()\n    }\nplotlymarkdown\n`\n문법 강조 (Syntax Highlighting)\n다양한 프로그래밍 언어의 문법 강조를 지원합니다.",
    "excerpt": "다이어그램 및 차트 사용 가이드\nSEPilot Wiki는 복잡한 아이디어와 데이터를 시각화하기 위해 Mermaid와 Plotly를 지원합니다.\n마크다운 코드 블록을 사용하여 간편하게 다이어그램과 차트를 그릴 수 있습니다.\nMermaid 다이어그램\n 언어로 코드 블록을 작성하면 자동으로 다이어그램으로 렌더링됩니다.\n플로우차트 (Flowchart)\nmermai...",
    "tags": [
      "mermaid",
      "plotly",
      "차트",
      "다이어그램",
      "사용법"
    ]
  },
  {
    "title": "Configuration Guide",
    "slug": "guide/configuration-guide",
    "content": "Configuration Guide\nThis document is a placeholder for the Configuration Guide. Include configuration options, environment variables, and best practices here.",
    "excerpt": "Configuration Guide\nThis document is a placeholder for the Configuration Guide. Include configuration options, environment variables, and best practices here.",
    "tags": [
      "configuration",
      "settings",
      "customization"
    ]
  }
]