{
  "pages": [
    {
      "title": "Wiki 페이지 API 라우트 상세 가이드",
      "slug": "backend/wiki-api-route-guide",
      "content": "\n## 1. 문서 개요\n**목적**  \n`app/api/wiki/[...slug]/route.ts` 파일이 제공하는 Wiki 페이지 API 엔드포인트의 사용 방법을 외부 개발자와 내부 팀에게 명확히 안내합니다.  \n\n**대상 독자**  \n- 프론트엔드·백엔드 개발자  \n- API 소비자(외부 파트너)  \n- 운영·보안 담당자  \n\n**주요 기능 요약**  \n- Wiki 페이지 조회, 생성, 수정, 삭제 지원  \n- 계층형 경로(`slug`)를 통한 페이지 식별  \n- JWT 기반 인증·인가 적용 및 표준화된 응답 포맷  \n\n**버전 정보 및 적용 범위**  \n- 현재 API 버전: `v1` (프로젝트 루트 `package.json`에 정의)  \n- 적용 범위: `app/api/wiki/[...slug]/route.ts`에 매핑된 모든 HTTP 메서드  \n\n> **참고**: 본 가이드는 로버트의 API 문서 작성 가이드라인을 참고하여 구성되었습니다[[API 문서 작성을 위한 로버트의 가이드라인](https://koko8829.tistory.com/2496)].\n\n---\n\n## 2. 인증·인가 흐름\n| 항목 | 내용 |\n|------|------|\n| **지원 인증 방식** | **JWT (JSON Web Token)** 를 `Authorization: Bearer <token>` 헤더에 담아 전달합니다. 토큰은 `HS256` 알고리즘으로 서명되며, `exp` 클레임을 통해 만료 시간이 관리됩니다. |\n| **토큰 전달 방법** | - `Authorization` 헤더 (권장) <br> - HTTP‑Only `session_token` 쿠키 (옵션, SameSite=Lax) |\n| **권한 레벨 별 접근 제한** | - **읽기**(GET): 인증된 모든 사용자 허용 <br> - **작성·수정·삭제**(POST, PUT/PATCH, DELETE): `editor` 또는 `admin` 역할 필요 |\n| **인증 실패 시 응답** | `401 Unauthorized` 와 아래와 같은 JSON 바디 반환 <br> ```json { \"errorCode\":\"UNAUTHORIZED\", \"message\":\"Invalid or missing token.\" }``` |\n\n**요약**  \nAPI는 JWT 기반 Bearer 토큰을 기본 인증 수단으로 사용합니다. 토큰이 없거나 유효하지 않을 경우 401 오류가 반환되며, 쓰기·삭제 작업은 `editor` 이상 권한이 요구됩니다.\n\n---\n\n## 3. 라우트 구조 및 파라미터\n- **파일 위치**: `app/api/wiki/[...slug]/route.ts`  \n- **라우트 매핑**: Next.js App Router의 와일드카드 `[...]` 로 `/api/wiki/*` 경로 전체를 처리합니다.  \n\n### `slug` 파라미터\n- **형식**: 계층형 경로 문자열 배열 (`string[]`). 예시: `/api/wiki/technology/web/react` → `slug = [\"technology\",\"web\",\"react\"]`.  \n- **역할**: Wiki 페이지의 고유 경로를 식별하며, 페이지 트리 구조를 그대로 반영합니다.  \n\n### 지원 HTTP 메서드\n| 메서드 | 동작 |\n|-------|------|\n| **GET** | 페이지 조회 |\n| **POST** | 새 페이지 생성 |\n| **PUT** / **PATCH** | 기존 페이지 전체/부분 업데이트 |\n| **DELETE** | 페이지 삭제 (soft / hard) |\n\n### 지원 쿼리 파라미터\n| 파라미터 | 타입 | 설명 | 기본값 |\n|----------|------|------|--------|\n| `preview` | boolean | 미발행(초안) 페이지를 조회할 때 `true` 로 설정 | `false` |\n| `includeDeleted` | boolean | 소프트 삭제된 페이지를 포함해 조회 (`true` 시) | `false` |\n| `mode` | string (`soft` \\| `hard`) | DELETE 요청 시 삭제 방식 지정. 지정하지 않으면 `soft` 가 기본 | `soft` |\n\n**요약**  \n`slug` 로 페이지를 식별하고, `preview`, `includeDeleted`, `mode` 같은 쿼리 파라미터로 조회·삭제 동작을 세밀하게 제어할 수 있습니다.\n\n---\n\n## 4. 엔드포인트 상세\n\n### 4‑1. Wiki 페이지 조회 (GET)\n- **요청 URL**: `GET /api/wiki/{slug...}`  \n- **필수 파라미터**: `slug` (경로)  \n- **선택 파라미터**: `preview`, `includeDeleted`  \n\n**성공 응답** (`200 OK`)  \n\n    {\n        \"title\": \"React 소개\",\n        \"content\": \"React는 ...\",\n        \"metadata\": {\n            \"authorId\": \"u123\",\n            \"createdAt\": \"2024-02-01T12:34:56Z\",\n            \"updatedAt\": \"2024-02-10T08:20:00Z\",\n            \"version\": 3,\n            \"deleted\": false\n        }\n    }\n\n- **ETag** 헤더가 포함되어 낙관적 잠금에 활용됩니다.  \n- **캐시**: `Cache-Control: private, max-age=60`  \n\n**요약**  \nGET 은 `slug` 로 페이지를 조회하고, `preview`·`includeDeleted` 로 초안·삭제된 페이지 접근을 제어합니다. 성공 시 페이지 데이터와 메타데이터를 반환합니다.\n\n---\n\n### 4‑2. Wiki 페이지 생성 (POST)\n- **요청 URL**: `POST /api/wiki/{slug...}`  \n- **요청 헤더**: `Content-Type: application/json`  \n- **요청 바디**  \n\n    {\n        \"title\": \"새 페이지 제목\",\n        \"content\": \"본문 내용\",\n        \"metadata\": {\n            \"tags\": [\"frontend\", \"react\"]\n        }\n    }\n\n- **자동 메타데이터**: 서버가 `authorId`(토큰에서 추출), `createdAt`, `updatedAt`, `version(=1)`, `deleted(false)` 를 삽입합니다.  \n\n**성공 응답** (`201 Created`)  \n\n- `Location` 헤더에 새 페이지 URL (`/api/wiki/{slug...}`) 제공  \n- 응답 본문에 생성된 리소스 전체 반환 (위 GET 응답과 동일 포맷)  \n\n**요약**  \nPOST 로 새 페이지를 만들 때 클라이언트는 `title`, `content`, 선택적 `metadata.tags` 만 제공하면 됩니다. 서버는 인증 토큰에서 사용자 정보를 추출해 메타데이터를 자동 채웁니다.\n\n---\n\n### 4‑3. Wiki 페이지 수정 (PUT / PATCH)\n- **요청 URL**: `PUT /api/wiki/{slug...}` (전체 교체) 또는 `PATCH /api/wiki/{slug...}` (부분 업데이트)  \n- **필수 헤더**: `If-Match: \"<ETag>\"` (버전 충돌 방지)  \n- **요청 바디** (예시)  \n\n    {\n        \"title\": \"수정된 제목\",\n        \"content\": \"수정된 내용\",\n        \"metadata\": {\n            \"tags\": [\"updated\"]\n        }\n    }\n\n- **동시성 제어**: `If-Match` 값이 현재 `ETag` 와 일치하지 않으면 `409 Conflict` 반환.  \n\n**성공 응답** (`200 OK`)  \n\n    {\n        \"title\": \"수정된 제목\",\n        \"content\": \"수정된 내용\",\n        \"metadata\": {\n            \"authorId\": \"u123\",\n            \"updatedAt\": \"2024-05-01T10:15:30Z\",\n            \"version\": 4,\n            \"deleted\": false\n        }\n    }\n\n**요약**  \nPUT/PATCH 는 `If-Match` 헤더를 통해 낙관적 잠금을 구현합니다. 전체 교체는 PUT, 부분 업데이트는 PATCH 로 구분됩니다.\n\n---\n\n### 4‑4. Wiki 페이지 삭제 (DELETE)\n- **요청 URL**: `DELETE /api/wiki/{slug...}`  \n- **쿼리 파라미터**: `mode=soft` (기본) 혹은 `mode=hard`  \n\n**동작**  \n- **soft**: `deleted` 플래그를 `true` 로 설정하고 `deletedAt` 타임스탬프 기록.  \n- **hard**: 데이터베이스에서 영구 삭제.  \n\n**성공 응답**  \n\n- **soft delete**: `204 No Content` (본문 없음)  \n- **hard delete**: `202 Accepted` 와 작업 ID 반환 (비동기 처리 시)  \n\n    {\n        \"taskId\": \"del-20240501-abc123\",\n        \"status\": \"queued\"\n    }\n\n**요약**  \nDELETE 은 기본적으로 소프트 삭제를 수행합니다. `mode=hard` 를 지정하면 즉시 영구 삭제가 진행되며, 비동기 처리 시 202 응답과 작업 ID가 반환됩니다.\n\n---\n\n## 5. 요청·응답 예시\n### cURL 예시\n- **GET (preview 포함)**  \n\n    curl -X GET \"https://api.example.com/api/wiki/technology/web/react?preview=true\" \\\n         -H \"Authorization: Bearer <token>\"\n\n- **POST**  \n\n    curl -X POST \"https://api.example.com/api/wiki/technology/web/react\" \\\n         -H \"Content-Type: application/json\" \\\n         -H \"Authorization: Bearer <token>\" \\\n         -d '{\"title\":\"React 소개\",\"content\":\"...\",\"metadata\":{\"tags\":[\"frontend\"]}}'\n\n- **PATCH (ETag 사용)**  \n\n    curl -X PATCH \"https://api.example.com/api/wiki/technology/web/react\" \\\n         -H \"Content-Type: application/json\" \\\n         -H \"Authorization: Bearer <token>\" \\\n         -H 'If-Match: \"W/\\\"3\\\"\"' \\\n         -d '{\"content\":\"업데이트된 내용\"}'\n\n- **DELETE (hard)**  \n\n    curl -X DELETE \"https://api.example.com/api/wiki/technology/web/react?mode=hard\" \\\n         -H \"Authorization: Bearer <token>\"\n\n### JavaScript fetch 예시\n```javascript\n// GET with preview\nfetch('/api/wiki/technology/web/react?preview=true', {\n  method: 'GET',\n  headers: { 'Authorization': `Bearer ${token}` }\n})\n  .then(r => r.json())\n  .then(console.log);\n\n// POST new page\nfetch('/api/wiki/technology/web/react', {\n  method: 'POST',\n  headers: {\n    'Content-Type': 'application/json',\n    'Authorization': `Bearer ${token}`\n  },\n  body: JSON.stringify({\n    title: 'React 소개',\n    content: '...',\n    metadata: { tags: ['frontend'] }\n  })\n})\n  .then(r => r.json())\n  .then(console.log);\n```\n\n### 응답 JSON 샘플\n- **성공 (200)**  \n\n    {\n        \"title\": \"React 소개\",\n        \"content\": \"React는 ...\",\n        \"metadata\": {\n            \"authorId\": \"u123\",\n            \"createdAt\": \"2024-02-01T12:34:56Z\",\n            \"updatedAt\": \"2024-05-01T10:15:30Z\",\n            \"version\": 4,\n            \"deleted\": false\n        }\n    }\n\n- **오류 (404)**  \n\n    {\n        \"errorCode\": \"PAGE_NOT_FOUND\",\n        \"message\": \"Requested wiki page does not exist.\",\n        \"details\": { \"slug\": [\"technology\",\"web\",\"react\"] }\n    }\n\n---\n\n## 6. 오류 처리 및 상태 코드\n| 코드 | 의미 | 응답 예시 |\n|------|------|-----------|\n| **400** | 잘못된 요청(파라미터 누락·형식 오류) | `{ \"errorCode\":\"INVALID_REQUEST\", \"message\":\"Missing title.\", \"details\":{...} }` |\n| **401** | 인증 실패 | `{ \"errorCode\":\"UNAUTHORIZED\", \"message\":\"Invalid or missing token.\" }` |\n| **403** | 권한 부족 | `{ \"errorCode\":\"FORBIDDEN\", \"message\":\"Insufficient permissions.\" }` |\n| **404** | 페이지 미존재 | `{ \"errorCode\":\"PAGE_NOT_FOUND\", \"message\":\"...\", \"details\":{ \"slug\": [...] } }` |\n| **409** | 버전 충돌(If-Match 불일치) | `{ \"errorCode\":\"VERSION_CONFLICT\", \"message\":\"ETag mismatch.\", \"details\":{ \"currentVersion\":5 } }` |\n| **410** | 소프트 삭제된 페이지 접근 | `{ \"errorCode\":\"PAGE_GONE\", \"message\":\"Page has been soft‑deleted.\", \"details\":{ \"slug\": [...] } }` |\n| **500** | 서버 내부 오류 | `{ \"errorCode\":\"INTERNAL_ERROR\", \"message\":\"Unexpected error.\", \"details\":null }` |\n\n**권장 대응 방안**  \n\n- `400` → 파라미터 검증 로직 강화 (스키마 검증)  \n- `401/403` → 토큰 재발급·권한 재검토  \n- `409` → 최신 버전 조회 후 `If-Match` 재전송  \n- `410` → 복구 API(soft delete 복원) 사용 검토  \n- `500` → 로그 확인 후 운영팀에 보고  \n\n---\n\n## 7. 베스트 프랙티스\n- **Rate Limiting**: 1분당 60건 이하 요청 권장. 초과 시 `429 Too Many Requests` 반환.  \n- **재시도 전략**: 5xx 오류 시 지수 백오프 적용 (예: 100 ms → 200 ms → 400 ms).  \n- **데이터 검증**: 서버와 클라이언트 모두 Zod·Joi 등 스키마 검증 사용.  \n- **보안**  \n  - 입력값에 대한 **SQL/NoSQL 인젝션 방지** 및 **XSS sanitization** 적용.  \n  - CSRF 방지를 위해 `SameSite=Lax` 쿠키 또는 `X-CSRF-Token` 헤더 사용 권장.  \n\n**요약**  \n안정적인 서비스 운영을 위해 레이트 제한, 재시도 정책, 입력 검증, 그리고 CSRF·XSS 방어를 반드시 적용하십시오.\n\n---\n\n## 8. 테스트·샘플 코드\n### 로컬 개발 환경 설정\n1. `node` ≥ 18, `pnpm` 설치  \n2. 레포지토리 클론 후 `pnpm install` 실행  \n3. `.env.local`에 `NEXT_PUBLIC_API_BASE=/api` 등 환경 변수 설정  \n4. `pnpm dev` 로 개발 서버 실행 (`http://localhost:3000`)  \n\n### 통합 테스트 시나리오 예시\n| 시나리오 | 기대 결과 |\n|----------|-----------|\n| **GET 존재 페이지** | `200 OK` + 페이지 데이터 |\n| **GET 비존재 페이지** | `404 NOT FOUND` |\n| **POST 인증된 사용자** | `201 Created` + `Location` 헤더 |\n| **PUT 버전 충돌** (`If-Match` 불일치) | `409 CONFLICT` |\n| **DELETE soft** | `204 No Content` |\n| **DELETE hard** (비동기) | `202 Accepted` + 작업 ID |\n\n### Mock 서버 활용\n`msw`(Mock Service Worker) 로 `GET /api/wiki/*` 등 핸들러를 등록해 프론트엔드 테스트에 활용합니다.\n\n**요약**  \n위 절차대로 로컬 환경을 구성하고, 표에 제시된 시나리오를 자동화 테스트에 포함하면 API 구현 검증이 용이합니다.\n\n---\n\n## 9. 변경 로그 & 버전 관리\n| 날짜 | 버전 | 변경 내용 | 영향 |\n|------|------|-----------|------|\n| 2024-02-20 | v1.0.0 | 최초 문서 초안 작성 | 전체 가이드 제공 |\n| 2024-03-05 | v1.1.0 | 인증·인가 섹션에 JWT 상세 추가 | 보안 가이드 보강 |\n| 2024-04-12 | v1.2.0 | 오류 코드 표에 409·410 추가 | 개발자 오류 처리 개선 |\n| 2024-05-08 | v1.3.0 | 쿼리 파라미터(`preview`, `includeDeleted`, `mode`) 및 soft/hard delete 설명 추가 | 사용성 향상 |\n\n**마이그레이션 가이드**  \n- 기존 `slug` 기반 경로는 그대로 유지됩니다.  \n- 삭제 옵션이 새롭게 `mode` 파라미터로 노출되므로, 기존 클라이언트는 기본 soft delete 동작에 영향이 없습니다.  \n- `preview` 와 `includeDeleted` 파라미터는 선택 사항이며, 기존 호출에 영향을 주지 않습니다.  \n\n---\n\n## 10. 참고 자료\n- **API 문서 작성 가이드라인** – 로버트의 가이드라인[[API 문서 작성을 위한 로버트의 가이드라인](https://koko8829.tistory.com/2496)]  \n- **Next.js App Router 문서** – 공식 문서([Next.js Docs](https://nextjs.org/docs/app/building-your-application/routing))  \n- **OAuth 2.0 표준** – RFC 6749([IETF RFC 6749](https://datatracker.ietf.org/doc/html/rfc6749))  \n- **JWT (JSON Web Token)** – RFC 7519([IETF RFC 7519](https://datatracker.ietf.org/doc/html/rfc7519))  \n\n> **주의**: 본 문서는 현재 확인 가능한 구현을 기반으로 작성되었습니다. 향후 코드 변경 시 해당 섹션을 업데이트하십시오.",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "API",
        "Wiki",
        "라우트",
        "인증",
        "문서화"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "OpenTelemetry 개요 및 실전 가이드",
      "slug": "observability/open-telemetry-guide",
      "content": "\n## 개요\n관측성(Observability)은 과거 **로그용 에이전트**, **메트릭용 라이브러리**, **분산 추적 전용 SDK** 등 서로 다른 도구가 산재해 있어 **“조각난 혼란”**을 초래했습니다. 벤더를 교체하려면 기존 계측 코드를 모두 다시 작성해야 하는 번거로움이 있었습니다. 이러한 문제를 해결하기 위해 등장한 것이 **OpenTelemetry (OTel)** 입니다. OTel은 **CNCF**에서 Kubernetes 바로 뒤로 두 번째로 활발한 프로젝트가 되었으며, 애플리케이션이 텔레메트리 데이터를 생성·전송하는 방식을 표준화해 **데이터는 사용자의 것이고, 벤더가 아니라는** 원칙을 보장합니다[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)].\n\n## OpenTelemetry란?\n- **정의**: 오픈‑소스 관측 프레임워크로, **트레이스, 메트릭, 로그**와 같은 텔레메트리 데이터를 **생성, 수집, 내보내기** 할 수 있습니다.  \n- **역할**: 스토리지 백엔드나 시각화 도구가 아니라, **텔레메트리 데이터를 위한 범용 언어 및 전달 시스템** 역할을 합니다.  \n- **비유**: 배관에 비유하면, 애플리케이션·인프라에서 데이터를 **수집 → 처리 → 선택한 백엔드(예: SigNoz, Prometheus, Jaeger 등)로 전달**하는 파이프라인이라고 할 수 있습니다[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)].\n\n## 역사와 프로젝트 통합\n- **2019년**에 **OpenCensus(구글)**와 **OpenTracing(CNCF)** 두 주요 프로젝트가 합병하면서 OpenTelemetry가 탄생했습니다.  \n- 목표는 **계측을 위한 단일 표준**을 제공해 산업 전반을 통합하는 것이었습니다[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)].\n- 현재 CNCF 내에서 **Kubernetes** 뒤로 두 번째로 활발히 활동하는 프로젝트이며, 다양한 언어·플랫폼 지원을 지속적으로 확대하고 있습니다.\n\n## 관측성의 세 가지 핵심 기둥\n| Pillar | What It Does | Example |\n|--------|--------------|---------|\n| **Traces** | 분산 시스템에서 요청이 이동하는 과정을 추적합니다. 트레이스는 **스팬**(예: DB 쿼리, HTTP 요청)으로 구성됩니다. | 특정 HTTP 요청이 여러 마이크로서비스를 거쳐 처리되는 흐름을 시각화 |\n| **Metrics** | 시간에 따라 측정되는 수치 데이터 포인트(예: CPU 사용량, 메모리 소비, 요청 속도) | 시스템 부하가 급증한 시점을 파악 |\n| **Logs** | 타임스탬프가 포함된 텍스트 기록으로, 오류 메시지나 상태 업데이트를 포함합니다. | 에러 발생 원인 분석 |\n\nOTel을 이용하면 **세 가지 데이터를 동일한 컨텍스트 태그**로 연결할 수 있어, 트레이스를 확인하면 같은 시점에 생성된 로그와 메트릭을 즉시 조회할 수 있습니다[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)].\n\n## 아키텍처 개요\n- **API**: 계측 인터페이스. 구현이 없을 경우 **no‑op** 동작(코드는 실행되지만 데이터는 전송되지 않음)으로 동작합니다.  \n- **SDK**: 실제 구현체. 자동·수동 계측 옵션을 제공하며, 언어별로 제공됩니다.  \n- **Collector**: 데이터 **수집·처리·버퍼링** 역할을 수행하며, 다양한 Exporter와 연결됩니다.  \n- **Exporter**: Jaeger, Prometheus, SigNoz 등 **관측 백엔드**로 데이터를 전송합니다.\n\n## 언어 및 플랫폼 지원\n| 언어 | SDK 특징 | 설치 방법 (예시) |\n|------|----------|-------------------|\n| **Java** | 자동 인스트루멘테이션 지원, OpenTelemetry Java Agent 제공 | Maven/Gradle 의존성 추가 |\n| **Go** | 경량 SDK, 컨텍스트 전파가 기본 | `go get go.opentelemetry.io/otel` |\n| **Python** | 동적 언어 특성에 맞춘 자동 계측 플러그인 | `pip install opentelemetry-sdk` |\n| **JavaScript/Node.js** | Express, Koa 등 웹 프레임워크와 손쉬운 통합 | `npm install @opentelemetry/api @opentelemetry/sdk-node` |\n\n(각 언어별 상세 설치 방법은 공식 문서([OpenTelemetry 공식 사이트](https://opentelemetry.io))를 참고)\n\n## 계측 방법\n- **수동 계측**: 개발자가 직접 API를 호출해 스팬·메트릭·로그를 기록합니다.  \n- **자동 계측(자동 인스트루멘테이션)**: 언어별 에이전트 또는 플러그인을 사용해 프레임워크(HTTP 서버, DB, 메시징 등)와 자동으로 연동합니다.  \n- 주요 프레임워크와의 통합 포인트는 **HTTP 서버**, **데이터베이스 드라이버**, **메시징 시스템(Kafka, RabbitMQ)** 등이며, 자동 계측을 통해 **코드 변경 없이** 관측 데이터를 수집할 수 있습니다[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)].\n\n## 벤더 중립성 및 플러그‑앤‑플레이\n- **Exporter 교체 시** 기존 계측 코드 수정이 거의 필요 없습니다.  \n- 멀티벤더 환경에서는 **Collector**를 중앙에 두고 여러 Exporter를 동시에 구성해 **다양한 백엔드**에 데이터를 전송할 수 있습니다.  \n- 이는 **“데이터는 여러분의 것이고, 벤더가 아니라”**는 OTel의 핵심 원칙을 실현합니다[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)].\n\n## 배포 옵션 및 운영 모델\n- **Agent 형태**: 애플리케이션 프로세스와 동일한 호스트에 배포, 최소 지연으로 데이터 전송.  \n- **Collector 독립 실행**: 별도 컨테이너/서비스로 배포해 **배치, 버퍼링, 변환** 기능을 중앙 집중화.  \n- **클라우드**: Managed Collector(예: AWS Distro for OpenTelemetry) 사용 권장.  \n- **온프레미스**: 자체 호스팅 Collector와 Exporter 조합으로 운영.\n\n## 기존 관측 솔루션과 비교\n| 구분 | 전통 도구 | OpenTelemetry |\n|------|----------|---------------|\n| **로그** | 파일 기반, 벤더 전용 포맷 | 표준화된 로그 API, 다중 백엔드 지원 |\n| **메트릭** | Prometheus, Graphite 등 별도 설치 | SDK를 통한 메트릭 자동 수집, Exporter로 전송 |\n| **트레이스** | Jaeger, Zipkin 전용 SDK | 단일 API/SDK로 트레이스·메트릭·로그 동시 수집 |\n| **벤더 종속성** | 높은 종속성 | 벤더 중립, 플러그‑앤‑플레이 |\n\nOTel 도입 시 **통합 관리**, **벤더 교체 비용 절감**, **관측 데이터 상관관계 강화** 등의 효과를 기대할 수 있습니다.\n\n## 시작하기 가이드\n1. **프로젝트에 OTel SDK 추가**  \n   - 예: Java → `implementation \"io.opentelemetry:opentelemetry-sdk\"`  \n2. **TracerProvider 초기화**  \n   - `OpenTelemetrySdk.builder().setTracerProvider(...).buildAndRegisterGlobal()` (언어별 문법에 맞게)  \n3. **스팬 생성**  \n   - `Tracer tracer = GlobalOpenTelemetry.getTracer(\"example\");`  \n   - `Span span = tracer.spanBuilder(\"myOperation\").startSpan();`  \n4. **메트릭 기록**  \n   - `Meter meter = GlobalOpenTelemetry.getMeter(\"example\");`  \n   - `LongCounter requestCounter = meter.counterBuilder(\"requests\").setDescription(\"Number of requests\").build();`  \n   - `requestCounter.add(1);`  \n5. **Collector/Exporter 설정**  \n   - `otel-collector-config.yaml`에 Exporter(Jaeger, Prometheus 등) 추가 후 Collector 실행.  \n\n위 단계는 **공식 가이드**([OpenTelemetry Documentation](https://opentelemetry.io/docs/))에 자세히 나와 있습니다.\n\n## 베스트 프랙티스\n- **샘플링 전략**: 고트래픽 서비스에서는 **Probabilistic Sampling** 또는 **Rate Limiting**을 적용해 오버헤드 최소화.  \n- **컨텍스트 전파**: `traceparent` 헤더를 이용해 서비스 간 **분산 트레이스 연결**을 보장.  \n- **메타데이터 관리**: 공통 태그(예: `service.name`, `environment`)를 일관되게 설정해 검색·대시보드 구축을 용이하게 함.  \n- **성능 최적화**: no‑op API 사용 시 비용이 거의 없으므로, 프로덕션 환경에서는 **Exporter 비활성화**만으로도 안전하게 테스트 가능.\n\n## 생태계와 커뮤니티\n- **주요 오픈소스 프로젝트**: OpenTelemetry Collector, SDKs, Instrumentation Libraries.  \n- **CNCF 활동**: 정기적인 릴리즈, SIG(OpenTelemetry) 회의, 기여 가이드 제공.  \n- **기여 방법**: GitHub 레포지토리([opentelemetry-go](https://github.com/open-telemetry/opentelemetry-go) 등)에서 이슈·PR 제출.  \n- **지원 채널**: 공식 Slack, CNCF 토론 포럼, GitHub Discussions.  \n\n## 참고 자료\n- **공식 스펙 및 문서**: https://opentelemetry.io/docs/  \n- **관측 백엔드 연동 가이드**: Jaeger(https://www.jaegertracing.io/docs/), Prometheus(https://prometheus.io/docs/), SigNoz(https://signoz.io/docs/)  \n- **커뮤니티 블로그·튜토리얼**: euno.news 기사[[euno.news](https://euno.news/posts/ko/what-is-opentelemetry-everything-you-need-to-know-2d60c8)]  \n\n*본 문서는 제공된 리서치 자료를 기반으로 작성되었습니다. 추가적인 세부 구현 예시나 최신 릴리즈 정보는 공식 문서를 참고하시기 바랍니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "OpenTelemetry",
        "Observability",
        "Distributed Tracing",
        "CNCF"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Dependabot 라벨 설정 가이드",
      "slug": "github/dependabot-labels",
      "content": "\n# Dependabot 라벨 설정 가이드\n\n이 문서는 **Dependabot**이 Pull Request에 자동으로 라벨을 붙일 수 있도록 설정하는 방법과, 라벨이 존재하지 않을 때 발생하는 오류를 해결하는 절차를 설명합니다.\n\n## 1. 문제 상황\n\nDependabot이 PR에 `dependencies` 라벨을 추가하려고 시도했지만, 해당 라벨이 레포지토리에 존재하지 않아 다음과 같은 오류가 발생했습니다.\n\n```\nThe following labels could not be found: `dependencies`. Please create it before Dependabot can add it to a pull request.\nPlease fix the above issues or remove invalid values from `dependabot.yml`.\n```\n\n## 2. 라벨 생성 방법\n\n### 2.1 GitHub UI를 이용한 라벨 생성\n1. 레포지토리 메인 페이지에서 **Issues** 탭을 클릭합니다.\n2. 오른쪽 사이드바에 **Labels** 링크가 있습니다. 클릭합니다.\n3. **New label** 버튼을 눌러 라벨을 생성합니다.\n4. **Name**에 `dependencies` 를 입력하고, 필요에 따라 색상을 선택합니다.\n5. **Create label**을 클릭합니다.\n\n### 2.2 `gh` CLI를 이용한 라벨 생성\n```bash\ngh label create dependencies --color \"BFD4F2\" --description \"Dependabot dependency updates\"\n```\n위 명령을 실행하면 `dependencies` 라벨이 바로 생성됩니다.\n\n## 3. `dependabot.yml` 파일 검토\n\n라벨이 정상적으로 생성된 후에도 오류가 지속된다면 `dependabot.yml` 파일에 잘못된 라벨 이름이 지정되어 있는지 확인합니다.\n\n```yaml\n# .github/dependabot.yml\nversion: 2\nupdates:\n  - package-ecosystem: \"npm\"\n    directory: \"/\"\n    schedule:\n      interval: \"weekly\"\n    labels:\n      - \"dependencies\"   # 여기 라벨 이름이 정확히 일치해야 합니다.\n```\n- 라벨 이름은 **대소문자와 공백을 정확히 일치**시켜야 합니다.\n- 필요 없는 라벨이 포함돼 있다면 해당 항목을 삭제하거나 올바른 라벨 이름으로 교체합니다.\n\n## 4. 라벨 자동 생성 (옵션)\n\n프로젝트에 라벨이 아직 없을 경우, CI 워크플로우에서 자동으로 라벨을 생성하도록 스크립트를 추가할 수 있습니다.\n\n```yaml\n# .github/workflows/create-label.yml\nname: Create Dependabot Labels\non:\n  push:\n    branches: [ main ]\njobs:\n  create-label:\n    runs-on: ubuntu-latest\n    steps:\n      - name: Checkout repo\n        uses: actions/checkout@v3\n      - name: Create dependencies label if missing\n        run: |\n          if ! gh label list | grep -q \"dependencies\"; then\n            gh label create dependencies --color \"BFD4F2\" --description \"Dependabot dependency updates\"\n          fi\n        env:\n          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n```\n위 워크플로우는 `main` 브랜치에 푸시될 때마다 `dependencies` 라벨이 존재하지 않으면 자동으로 생성합니다.\n\n## 5. 검증\n1. 라벨을 생성한 뒤, Dependabot이 새 PR을 열면 자동으로 `dependencies` 라벨이 붙는지 확인합니다.\n2. 라벨이 정상적으로 붙지 않으면 **Actions** 로그와 **Dependabot** 설정을 다시 검토합니다.\n\n## 6. 참고 자료\n- [GitHub Docs: Managing labels for issues and pull requests](https://docs.github.com/en/issues/tracking-your-work-with-issues/creating-and-editing-labels)\n- [GitHub Docs: Configuring Dependabot](https://docs.github.com/en/code-security/dependabot/configuration-options)\n\n---\n*이 문서는 Dependabot 라벨 설정 문제를 해결하기 위한 가이드이며, 필요에 따라 프로젝트에 맞게 수정해서 사용하세요.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "Dependabot",
        "라벨",
        "GitHub",
        "CI"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Introducing Node Readiness Controller",
      "slug": "kubernetes/node-readiness-controller",
      "content": "\n## 1. 서론\n이 문서는 **Node Readiness Controller**(NRC)를 처음 접하는 클러스터 운영자와 플랫폼 엔지니어를 대상으로 합니다.  \nNRC는 기존 “Ready” 조건만으로는 충분히 표현되지 않는 복합 인프라 의존성을 선언형으로 관리하도록 설계되었습니다. 이를 통해 **스케줄링 정확성**과 **서비스 안정성**을 크게 향상시킬 수 있습니다 [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/).\n\n## 2. 기존 Kubernetes “Ready” 상태 한계\n- **단일 이진 Ready 조건**: 현재 Kubernetes는 `NodeReady` 라는 하나의 불리언 플래그만을 사용해 노드가 워크로드를 받을 수 있는지를 판단합니다 [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/).\n- **복합 인프라 의존성**: 현대 클러스터에서는 네트워크 에이전트, 스토리지 드라이버, GPU 펌웨어, 사용자 정의 헬스 체크 등 여러 요소가 모두 정상이어야 실제로 “준비된” 상태가 됩니다.  \n- **운영상의 문제**: Ready 플래그가 `True`라 하더라도 아직 초기화되지 않은 DaemonSet이나 드라이버가 존재하면, 워크로드가 조기에 스케줄링되어 서비스 장애가 발생할 수 있습니다 [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/).\n\n## 3. Node Readiness Controller 개요\n- **프로젝트 소개**: Kubernetes 커뮤니티가 발표한 새로운 컨트롤 플레인 기능으로, 노드 부팅 과정에서 **맞춤형 스케줄링 게이트**를 선언형으로 정의합니다 [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/).\n- **핵심 목표**  \n  1. **Custom Readiness** – 플랫폼별 “준비됨” 정의를 가능하게 함.  \n  2. **자동 Taint 관리** – 조건 변화에 따라 노드에 자동으로 taint를 적용·제거.  \n  3. **Declarative Bootstrapping** – 다단계 초기화 흐름을 명확히 관찰 가능하게 함.  \n- **설계 원칙**: Node‑centric, 선언형 API를 통해 운영자가 복잡한 부팅 로직을 코드가 아닌 YAML로 관리하도록 합니다.\n\n## 4. 핵심 개념 및 아키텍처\n| 개념 | 설명 |\n|------|------|\n| **Readiness Gate** | 사용자가 정의하는 커스텀 조건(예: DaemonSet 상태, 외부 HTTP 헬스 체크 등)을 `NodeReadinessGate` CRD 형태로 선언합니다. |\n| **Taint & Toleration 자동화** | 조건이 만족되지 않으면 `node-readiness.kubernetes.io/not-ready` taint가 자동으로 부여되고, 조건이 충족되면 자동 제거됩니다. |\n| **Controller Loop** | API Server를 watch하고, `NodeReadinessGate`와 실제 노드 상태를 비교해 리컨실리시에이션을 수행합니다. |\n| **구성 요소 간 인터페이스** | - **API Server**: CRD와 노드 상태를 저장·조회.<br>- **Scheduler**: taint 기반으로 스케줄링 결정을 내림.<br>- **Kubelet**: 기본 `Ready` 조건을 지속적으로 업데이트. |\n\n## 5. Custom Readiness 정의 방법\n### CRD: `NodeReadinessGate`\n- **apiVersion**: `node.k8s.io/v1alpha1`  \n- **kind**: `NodeReadinessGate`  \n- **spec**:  \n  - `nodeSelector`: 대상 노드 그룹을 라벨로 지정.  \n  - `conditions`: 배열 형태로 정의된 개별 체크 항목. 각 항목은 `type`(HealthCheck, DaemonSet, ExternalSignal 등)과 `target`(예: DaemonSet 이름, HTTP endpoint) 등을 포함합니다.  \n\n> **예시** (핵심 포인트만)  \n```yaml\napiVersion: node.k8s.io/v1alpha1\nkind: NodeReadinessGate\nmetadata:\n  name: gpu-node-gate\nspec:\n  nodeSelector:\n    node.kubernetes.io/instance-type: gpu\n  conditions:\n  - type: DaemonSet\n    name: nvidia-driver-installer\n  - type: ExternalSignal\n    url: https://health.example.com/gpu\n```  \n※ 실제 필드 상세는 공식 CRD 스키마를 참고하십시오 [공식 문서](https://kubernetes.io/docs/reference/).\n\n## 6. 자동 Taint 관리 메커니즘\n- **기본 Taint**: `node-readiness.kubernetes.io/not-ready:NoSchedule` 가 자동으로 생성됩니다.  \n- **트리거**:  \n  - **조건 변화**: 모든 `Readiness Gate`가 `True`가 되면 taint가 제거됩니다.  \n  - **타임아웃**: 지정된 기간 내에 조건이 충족되지 않으면 taint가 유지됩니다.  \n- **충돌 방지**: 기존 사용자 정의 taint와 네임스페이스가 겹치지 않도록 `node-readiness.kubernetes.io/` 네임스페이스를 전용으로 사용합니다.\n\n## 7. 선언형 노드 부트스트래핑 워크플로우\n1. **네트워크 초기화** – 네트워크 에이전트 DaemonSet이 `Ready`가 될 때까지 `not-ready` taint 유지.  \n2. **스토리지 연결** – CSI 플러그인 헬스 체크가 성공하면 두 번째 gate가 해제.  \n3. **특수 하드웨어** – GPU 드라이버, FPGA 펌웨어 등 추가 조건이 모두 만족될 때 최종적으로 taint가 제거되어 스케줄링이 가능해집니다.  \n\n> **상태 전이 다이어그램**: `NotReady → (조건1 OK) → (조건2 OK) → Ready`  \n> **관찰 포인트**: `kubectl get nodes -o wide` 로 현재 taint 상태 확인, `kubectl describe node <name>` 로 개별 gate 상태 확인.\n\n## 8. 실사용 사례\n- **GPU 노드**: `NodeReadinessGate`에 NVIDIA 드라이버 DaemonSet과 외부 펌웨어 검증 endpoint을 지정해, 드라이버가 완전히 로드된 뒤에만 GPU 워크로드가 스케줄됩니다.  \n- **스토리지 전용 노드**: CSI 플러그인 헬스 체크를 `ExternalSignal` 로 연결해, 스토리지 서비스가 정상 작동할 때만 PVC를 바인딩합니다.  \n- **Edge/5G 노드**: 네트워크 에이전트(예: Open5GS) 가용성을 `DaemonSet` 조건으로 지정해, 네트워크 연결이 확보된 시점에만 엣지 워크로드가 배포됩니다.  \n- **다중 클러스터/하이브리드**: 각 클러스터별 라벨링 전략과 `NodeReadinessGate`를 조합해, 동일한 워크로드가 서로 다른 준비 조건을 갖는 노드에 자동으로 맞춤 배포됩니다.  \n\n## 9. 설치 및 설정 가이드\n1. **배포 방법**  \n   - **Helm Chart**: `helm repo add node-readiness-controller https://charts.k8s.io` → `helm install nrc node-readiness-controller`  \n   - **Kustomize**: `kustomize build ./config/default | kubectl apply -f -`  \n2. **필수 RBAC**  \n   - `node-readiness-controller` ServiceAccount에 `nodes`, `nodeprovisioners`, `customresourcedefinitions`에 대한 `get/list/watch` 권한 부여.  \n3. **API Server 설정**  \n   - `--runtime-config=node.k8s.io/v1alpha1=true` 플래그를 활성화해야 CRD가 인식됩니다.  \n4. **기본값 vs 커스텀**  \n   - 기본값: 모든 노드에 `node-readiness.kubernetes.io/not-ready` taint 적용, `NodeReadinessGate`가 없으면 기존 `Ready`와 동일하게 동작.  \n   - 커스텀: 특정 라벨에만 적용, 조건 타임아웃 조정, 추가 taint 키 지정 가능.  \n\n## 10. 운영 베스트 프랙티스\n- **조건 설계**: 지연 허용 범위와 실패 재시도 정책을 명확히 정의하고, 중요한 인프라(예: 스토리지)에서는 보수적인 타임아웃을 설정합니다.  \n- **Taint/Toleration 호환성**: 기존 워크로드가 새로운 `node-readiness.kubernetes.io/not-ready` taint를 tolerates하도록 `PodSpec.tolerations`에 추가하거나, 필요 시 워크로드 별로 별도 toleration을 선언합니다.  \n- **CI/CD 연계**: PR 검증 단계에서 `kubectl wait --for=condition=Ready node/<node>` 대신 `NodeReadinessGate`가 모두 `True`가 되는지 확인하는 스크립트를 포함합니다.  \n\n## 11. 보안 및 접근 제어\n- **CRD 접근 최소화**: `NodeReadinessGate`는 `cluster-admin` 수준이 아닌, 특정 네임스페이스에 제한된 Role을 통해 관리합니다.  \n- **외부 신호 연동**: HTTP 기반 헬스 체크는 TLS와 인증 토큰을 사용해 보호해야 하며, API Server는 해당 endpoint에 대한 네트워크 정책을 적용합니다.  \n- **권한 상승 방지**: 악의적인 사용자가 임의의 taint를 삽입하지 못하도록 `node-readiness.kubernetes.io/` 네임스페이스에 대한 `create`/`update` 권한을 제한합니다.  \n\n## 12. 모니터링·관찰성\n- **주요 메트릭** (kube‑state‑metrics, Prometheus)  \n  - `node_readiness_gate_status{node=\"<name>\",condition=\"<type>\",status=\"true|false\"}`  \n  - `node_readiness_taint_active{node=\"<name>\"}`  \n- **이벤트 로그**: `kubectl get events --field-selector involvedObject.kind=Node` 로 taint 적용·제거 이벤트 확인.  \n- **Grafana 대시보드**: 노드별 gate 진행 상황, 현재 taint 상태, 조건 실패 비율 등을 시각화하는 템플릿이 공식 레포지토리에서 제공됩니다 [공식 문서](https://kubernetes.io/docs/).  \n\n## 13. 업그레이드·마이그레이션 가이드\n1. **단계적 적용**: 먼저 비핵심 워크로드가 있는 테스트 클러스터에 NRC를 배포하고, `NodeReadinessGate` 없이 기본 동작을 확인합니다.  \n2. **버전 호환성**: NRC는 Kubernetes 1.28 이상에서 지원됩니다 [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/).  \n3. **롤백**: `helm uninstall nrc` 혹은 `kubectl delete -f <nrc-manifests>` 로 컨트롤러를 제거하면 기존 `Ready` 플래그만 남게 됩니다. 기존 taint는 자동으로 정리됩니다.  \n\n## 14. 트러블슈팅 FAQ\n- **조건이 인식되지 않음**  \n  - `kubectl describe node <name>` 에서 `Readiness Gates` 섹션을 확인하고, CRD가 올바르게 적용됐는지 검증합니다.  \n- **Taint가 남아 있음**  \n  - 조건이 `True`가 되더라도 타임아웃이 설정돼 있으면 자동 제거가 지연될 수 있습니다. `NodeReadinessGate.spec.timeoutSeconds` 값을 확인합니다.  \n- **Controller 로그 확인**  \n  - 컨트롤러 Pod의 로그 레벨을 `--v=4` 로 높이면 상세 이벤트를 확인할 수 있습니다.  \n\n## 15. 기존 Ready 조건과 비교\n| 항목 | 기존 Ready | Node Readiness Controller |\n|------|------------|---------------------------|\n| 정의 범위 | 단일 이진 플래그 | 다중 커스텀 조건 (Readiness Gate) |\n| 자동 Taint | 없음 (수동) | `node-readiness.kubernetes.io/not-ready` 자동 적용/제거 |\n| 가시성 | `kubectl get nodes` 에서 Ready/NotReady만 표시 | 각 Gate 별 상태와 메트릭 제공 |\n| 사용 시점 | 모든 노드에 적용 | 특정 라벨/노드 그룹에 선택적 적용 가능 |\n\n**언제 기존 Ready만으로 충분한가?**  \n- 단순한 클러스터(네트워크, 스토리지, 하드웨어 의존성이 거의 없는 경우)에서는 기존 Ready가 충분합니다.  \n- 복합 인프라(전용 GPU, CSI, 엣지 네트워크 등)에서는 NRC 도입을 권장합니다.\n\n## 16. 향후 로드맵 및 커뮤니티 참여\n- **예정 기능**  \n  - 멀티‑Gate 조합을 통한 정책 기반 스케줄링.  \n  - Gate 상태에 따른 자동 스케일링 정책 연동.  \n- **기여 방법**  \n  - GitHub `kubernetes-sigs/node-readiness-controller` 레포지토리에서 이슈 제기 및 PR 제출.  \n  - SIG‑Node 토론에 참여해 피드백을 공유합니다.  \n\n## 17. 참고 자료 및 링크\n- **공식 블로그 포스트**: [Introducing Node Readiness Controller](https://kubernetes.io/blog/2026/02/03/introducing-node-readiness-controller/)  \n- **GitHub 레포지토리**: `https://github.com/kubernetes-sigs/node-readiness-controller` (공식 구현)  \n- **CRD 스키마 문서**: `https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.28/#nodereadinessgate-v1alpha1`  \n- **관련 사례 블로그**: Jerry Lee의 “Node Ready를 믿지 마세요!” (LinkedIn) [링크](https://www.linkedin.com/posts/jeeunglee_node-ready%EB%A5%BC-%EB%AF%BF%EC%A7%80-%EB%A7%88%EC%84%B8%EC%9A%94-node-readiness-activity-7426756404750897152-SRxo)  \n\n---",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Kubernetes",
        "NodeReadiness",
        "Scheduler",
        "Reliability"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Ingress NGINX 은퇴 선언 및 마이그레이션 가이드",
      "slug": "kubernetes/ingress-nginx-deprecation-guide",
      "content": "\n## 개요\n이 문서는 **Kubernetes Steering Committee**와 **Security Response Committee**가 2026년 3월에 발표한 *Ingress NGINX 은퇴* 선언을 기반으로 작성되었습니다.  \n대상 독자는 현재 클러스터에서 Ingress NGINX를 사용하고 있거나, 향후 도입을 고려하고 있는 클라우드‑네이티브 엔지니어, 플랫폼 운영팀, 보안 담당자입니다.\n\n**핵심 발표 요약**  \n- 2026년 3월, Ingress NGINX 프로젝트는 공식적으로 은퇴합니다.  \n- 은퇴 이후에는 버그 수정, 보안 패치, 신규 릴리스가 제공되지 않으며, 유지보수는 “베스트‑에포트”(best‑effort) 수준으로 종료됩니다.  \n- 기존 배포는 계속 동작하지만, 보안 취약점에 대한 대응이 불가능해지므로 즉시 마이그레이션이 필요합니다.  \n\n> 출처: [Kubernetes Blog – Ingress NGINX Statement (2026‑01‑29)](https://kubernetes.io/blog/2026/01/29/ingress-nginx-statement/)\n\n## 배경 및 현황\n### Ingress NGINX의 역할 및 시장 점유율\n- Ingress NGINX는 Kubernetes 클러스터에서 외부 트래픽을 서비스로 라우팅하는 **Ingress Controller** 중 가장 널리 사용되는 구현체였습니다.  \n- 내부 Datadog 조사에 따르면 **전체 클라우드‑네이티브 환경의 약 50%**가 Ingress NGINX에 의존하고 있습니다.  \n\n### 기존 유지보수 현황 및 기여자 부족 문제\n- 2025년 11월 발표된 사전 안내 글에 따르면, 프로젝트는 1~2명의 자원봉사자에 의해 유지보수되고 있었으며, 충분한 기여자를 확보하지 못해 은퇴가 결정되었습니다.  \n- 공식 블로그: [Ingress NGINX Retirement: What You Need to Know (2025‑11‑11)](https://kubernetes.io/blog/2025/11/11/ingress-nginx-retirement/)\n\n### 커뮤니티·스테어링 위원회와 보안 대응 위원회의 역할\n- **SIG Network**와 **Security Response Committee**가 은퇴 일정을 관리하고, 마이그레이션 가이드를 제공하고 있습니다.  \n- 이들 위원회는 은퇴 이후 발생할 수 있는 보안 위험을 최소화하기 위해 대체 솔루션을 권고하고 있습니다.\n\n## 은퇴 선언 상세\n| 항목 | 내용 |\n|------|------|\n| 공식 발표 일자 | 2026‑01‑29 (Kubernetes Blog) |\n| 발표 채널 | Kubernetes 공식 블로그, SIG Network 메일링 리스트 |\n| 은퇴 일정 | 2026‑03‑01까지 베스트‑에포트 유지보수 제공, 이후 모든 업데이트 중단 |\n| 지원 종료 이후 제공되지 않을 사항 | 버그 수정, 보안 패치, 신규 릴리스, 공식 이미지 업데이트 |\n\n## 영향 분석\n1. **운영 위험**  \n   - 보안 취약점이 발견되어도 패치가 제공되지 않음 → 공격 표면 확대.  \n   - 기존 배포는 계속 동작하지만, **취약점 노출** 시 복구가 어려움.  \n\n2. **가용성 위험**  \n   - 코드 베이스가 더 이상 업데이트되지 않으므로, Kubernetes 버전 업그레이드 시 호환성 문제가 발생할 가능성이 있음.  \n\n3. **운영 비용 및 인력 부담**  \n   - 마이그레이션 작업에 필요한 엔지니어링 시간(예상 2~4주)과 테스트 인프라 비용이 추가 발생.  \n\n## 사전 점검 방법\n### Ingress NGINX 사용 여부 확인\n```bash\nkubectl get pods --all-namespaces --selector app.kubernetes.io/name=ingress-nginx\n```\n- 위 명령이 결과를 반환하면 해당 클러스터에 Ingress NGINX가 배포되어 있음을 의미합니다.\n\n### 의존성 파악 절차\n1. `kubectl get ingress -A -o yaml` 로 모든 Ingress 리소스를 확인.  \n2. Ingress 리소스에 `ingressClassName: nginx` 혹은 `kubernetes.io/ingress.class: nginx` 어노테이션이 있는지 검토.  \n3. 서비스, ConfigMap, Secret 등 연관된 리소스도 함께 파악.\n\n### 영향도 평가 체크리스트\n- [ ] Ingress NGINX 파드 존재 여부  \n- [ ] Ingress 리소스가 `nginx` 클래스를 사용 중인지  \n- [ ] 현재 사용 중인 TLS 인증서 관리 방식  \n- [ ] 외부 DNS/로드밸런서와의 연동 구조  \n\n## 마이그레이션 전략\n### 전환 기간 (2개월) 주요 작업\n| 단계 | 기간 | 주요 작업 |\n|------|------|-----------|\n| 평가 | 1주 | 현재 사용 현황 파악, 대체 솔루션 후보 선정 |\n| 파일럿 | 3주 | 선택한 대체 솔루션을 별도 네임스페이스에 배포, 테스트 트래픽 전환 |\n| 전면 전환 | 2주 | 단계적 트래픽 이동, 기존 Ingress NGINX 종료 |\n| 정리 | 1주 | 모니터링 설정 검증, 문서 정비 |\n\n### 단계별 마이그레이션 플랜\n1. **평가** – 현재 Ingress NGINX 설정(Annotations, ConfigMap, Custom Templates) 목록화.  \n2. **파일럿** – `Gateway API` 혹은 서드파티 Ingress Controller(예: Contour, Traefik) 중 하나를 선택하고, **GatewayClass**와 **Gateway** 리소스를 정의.  \n3. **전면 전환** – `kubectl rollout restart` 등을 활용해 트래픽을 새 컨트롤러로 점진적 전환.  \n4. **롤백** – 문제가 발생하면 파일럿 단계에서 사용한 네임스페이스로 즉시 복구 가능하도록 설계.  \n\n### 비상 대응 방안\n- **스냅샷**: 기존 Ingress NGINX 매니페스트와 ConfigMap을 Git에 보관.  \n- **읽기 전용 모드**: 은퇴 전 마지막 2주 동안은 새로운 Ingress 리소스 생성을 차단하고, 기존 리소스만 유지.  \n\n## 대체 솔루션 비교\n| 솔루션 | 장점 | 제한 사항 |\n|--------|------|-----------|\n| **Gateway API** (공식) | 표준화된 API, 확장성, 향후 Kubernetes와 긴밀히 연동 | 기존 Ingress 매니페스트와 1:1 매핑이 어려움, 학습 곡선 |\n| **Contour** | Envoy 기반 고성능, Gateway API 지원 | 일부 고급 NGINX 전용 기능 미지원 |\n| **Traefik** | 자동 서비스 디스커버리, 다중 프로토콜 지원 | 복잡한 라우팅 규칙 구현 시 설정 난이도 |\n| **Istio IngressGateway** | 서비스 메시와 통합 가능 | 전체 Istio 설치 필요, 리소스 오버헤드 |\n\n**선택 기준**  \n- 현재 사용 중인 라우팅 기능(예: TLS Passthrough, Rewrite)과의 매핑 가능성  \n- 운영팀의 기술 스택 및 학습 비용  \n- 클라우드 제공자와의 호환성  \n\n> **참고**: Ingress NGINX 레포지토리(`https://github.com/kubernetes/ingress-nginx`)의 *Usage warnings* 섹션에서도 “이미 사용 중이 아닌 경우 배포하지 말고, 대신 Gateway API 구현을 찾아 사용하라”는 권고가 있습니다. 마이그레이션 계획 수립 시 이 권고를 반영해 사전 검토를 진행하십시오.\n\n## 구현 가이드 개요\n### Gateway API 도입 기본 흐름\n1. **GatewayClass** 정의 (예: `gatewayclass: nginx-gateway` 혹은 `gatewayclass: envoy-gateway`).  \n2. **Gateway** 리소스 생성 – 로드밸런서 IP/Hostname 지정.  \n3. **HTTPRoute** 혹은 **TCPRoute** 정의 – 기존 Ingress 규칙을 변환.  \n\n### 기존 Ingress 리소스 변환 도구\n- 공식 `k8s.io/ingress-nginx` 레포지토리에서 제공하는 `ingress-nginx-to-gateway` 변환 스크립트(추가 조사가 필요합니다).  \n- 커뮤니티가 만든 `kubectl ingress-to-gateway` 플러그인(추가 조사가 필요합니다).  \n\n### CI/CD 파이프라인 자동화\n- **GitOps**: `kustomize` 혹은 `helm` 차트에 Gateway API 매니페스트를 포함하고, Argo CD 혹은 FluxCD를 통해 자동 배포.  \n- **검증 단계**: `kubeval` 혹은 `conftest`를 이용해 Gateway 리소스 스키마 검증.  \n\n## 커뮤니티 및 지원 리소스\n- **SIG Network**: https://github.com/kubernetes/community/tree/master/sig-network  \n- **Security Response Committee**: https://github.com/kubernetes/kubernetes/tree/master/security  \n- **공식 문서**:  \n  - Gateway API 소개 – https://gateway-api.sigs.k8s.io/  \n  - Ingress NGINX 은퇴 FAQ – https://kubernetes.io/blog/2026/01/29/ingress-nginx-statement/  \n- **포럼·Slack**: `#sig-network` 채널, `#kubernetes-security` 채널  \n- **기여 방법**: 프로젝트 레포지토리 이슈 트래킹, PR 템플릿 활용 (추가 조사가 필요합니다).  \n\n## FAQ\n**Q1. 은퇴 이후 기존 배포는 계속 동작하나요?**  \nA: 네, 기존 파드와 서비스는 그대로 동작합니다. 다만 보안 패치가 제공되지 않으므로 위험에 노출됩니다.\n\n**Q2. 보안 패치가 제공되지 않을 경우 어떻게 대응해야 하나요?**  \nA: 가능한 빨리 대체 솔루션(Gateway API 등)으로 마이그레이션하고, 외부 보안 스캐너로 취약점 모니터링을 강화합니다.\n\n**Q3. 마이그레이션 시 예상되는 다운타임은?**  \nA: 단계적 트래픽 전환을 적용하면 다운타임은 거의 없으며, 파일럿 단계에서 충분히 검증한 뒤 전면 전환 시 최소 1~2분 수준으로 제한할 수 있습니다.\n\n## 참고 자료 및 링크\n- **공식 발표 블로그 포스트 (2026‑01‑29)** – https://kubernetes.io/blog/2026/01/29/ingress-nginx-statement/  \n- **2025‑11‑11 은퇴 사전 안내 글** – https://kubernetes.io/blog/2025/11/11/ingress-nginx-retirement/  \n- **Datadog 내부 조사 결과 요약** – (추가 조사가 필요합니다)  \n- **Gateway API 공식 문서** – https://gateway-api.sigs.k8s.io/  \n- **Ingress NGINX GitHub 레포지토리** – https://github.com/kubernetes/ingress-nginx  \n\n---  \n\n*이 문서는 SEPilot Wiki 유지보수를 위해 자동 생성된 초안이며, 실제 적용 전 반드시 내부 검토를 거쳐 주세요.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Ingress",
        "NGINX",
        "Kubernetes",
        "Migration",
        "Security",
        "guide",
        "deprecation",
        "k8s",
        "networking",
        "load-balancer"
      ],
      "menu": "Ingress NGINX 마이그레이션",
      "order": 2,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Kubernetes/Api Governance",
      "slug": "kubernetes/api-governance",
      "content": "---\ntitle: Spotlight on SIG Architecture: API Governance – 위키 유지보수 가이드\nauthor: SEPilot AI\nstatus: published\ntags: [SIG Architecture, API Governance, Kubernetes, 위키 유지보수, 커뮤니티]\nredirect_from:\n  - spotlight-on-sig-architecture-api-governance\norder: 3\nrelated_docs: [\"release-notes.md\", \"node-readiness-controller.md\", \"cgroup-migration.md\"]\n---\n\n## 개요\n이 문서는 **SIG Architecture: API Governance** 서브프로젝트에 대한 최신 정보를 위키에 반영하기 위해 작성되었습니다.  \n- **대상 독자**: 클러스터 운영자, Kubernetes API 개발자, SIG Architecture 참여자, 위키 유지보수 담당자  \n- **요청 요약**: 2026년 2월 12일 Kubernetes 블로그에 게시된 인터뷰(“Spotlight on SIG Architecture: API Governance”)를 기반으로 API Governance의 역할, 프로세스, 최신 동향을 위키에 추가·업데이트 [출처](https://kubernetes.io/blog/2026/02/12/sig-architecture-api-spotlight/)  \n- **중요도**: 80/100 (핵심 아키텍처 주제이며 현재 위키에 부재)\n\n## 배경 및 필요성\n- **위키 부재 이유**: 기존 위키는 주로 KEP, API 스펙, 운영 가이드에 집중했으며, API Governance 전용 섹션이 별도로 존재하지 않았음.  \n- **운영·개발 영향**: API 안정성·호환성 보장은 클러스터 업그레이드와 사용자 경험에 직접적인 영향을 미침. Governance 프로세스를 명확히 문서화하면 리뷰 지연·버전 충돌을 예방할 수 있음.  \n- **트렌드 반영 필요성**: 2026년 인터뷰에서 제시된 최신 정책·툴링(예: 자동화 CI 연계)과 커뮤니티 논의가 활발히 진행 중이므로, 위키에 즉시 반영해야 최신 정보를 제공할 수 있음 [출처](https://kubernetes.io/blog/2026/02/12/sig-architecture-api-spotlight/).\n\n## SIG Architecture와 API Governance 소개\n- **SIG Architecture 전체 구조**: SIG Architecture는 Kubernetes 전체 설계와 코드 조직을 담당하는 여러 서브프로젝트(예: API Governance, Code Organization, API Review 등)로 구성됨 [GitHub README](https://github.com/kubernetes/community/blob/master/sig-architecture/README.md#architecture-and-api-governance-1).  \n- **API Governance 서브프로젝트 정의**: API의 **안정성, 일관성, 폐기 정책**을 관리하고, 설계·리뷰 프로세스를 표준화하는 역할을 수행함.  \n- **주요 참여자·리더**: Jordan Liggitt (API Governance Lead, SIG Auth Tech Lead) – 2019년부터 참여, 2016년 API Reviewer, 2017년 API Approver [블로그 인터뷰](https://kubernetes.io/blog/2026/02/12/sig-architecture-api-spotlight/).\n\n## 주요 목표 및 원칙\n| 목표 | 설명 |\n|------|------|\n| **API 안정성·호환성 보장** | 버전 업그레이드 시 기존 클라이언트가 중단되지 않도록 정책 정의 |\n| **설계·리뷰 프로세스 표준화** | KEP 기반 설계, API Review 단계 도입 |\n| **API 진화와 폐기 정책** | 명시적 deprecation 일정과 가이드 제공 |\n| **문서·버전 관리 일관성** | 위키와 공식 문서의 동기화 유지 |\n\n## 프로세스와 워크플로우\n1. **KEP 작성·제출** – 새로운 API 혹은 기존 API 변경 시 KEP(Kubernetes Enhancement Proposal)를 작성하고 SIG Architecture에 제출 [블로그 내용](https://kubernetes.io/blog/2026/02/12/sig-architecture-api-spotlight/).  \n2. **API Review 단계** – API Reviewer가 설계·구현을 검토하고, 필요 시 구조적 변경을 권고.  \n3. **승인 흐름** – API Approver(주로 SIG Architecture Lead)와 SIG Architecture Lead가 최종 승인.  \n4. **변경 관리** – 버전 업그레이드와 deprecation 절차는 별도 가이드에 따라 진행.  \n5. **자동화·CI 연계** – CI 파이프라인에 API Review 체크를 포함시켜 PR 단계에서 자동 검증을 수행 [다른 기사 요약](https://www.devopschat.co/articles/spotlight-on-sig-architecture-api-governance).\n\n## 핵심 역할 및 책임\n| 역할 | 주요 책임 |\n|------|-----------|\n| **API Reviewer** | 설계·코드 리뷰, 호환성 검증 |\n| **API Approver** | 최종 승인, 정책 적용 여부 판단 |\n| **SIG Architecture Lead** | 전체 서브프로젝트 조정, 커뮤니티 가이드 제공 |\n| **커뮤니티 기여자·외부 협력자** | KEP 제안, 피드백 제공 |\n| **문서 담당자·위키 유지보수 담당** | 위키 페이지 생성·업데이트, 변경 로그 관리 |\n\n## 현재 진행 중인 작업 및 최신 업데이트\n- **2026년 인터뷰에서 언급된 이슈**: API Governance 팀이 “안정성·일관성·교차‑cutting sanity”을 강화하기 위한 정책 개선을 진행 중이라고 밝힘 [FAUN.dev 요약](http://faun.dev/c/links/kaptain/spotlight-on-sig-architecture-api-governance/).  \n- **툴링 업데이트**: 자동화된 API Review 체크를 CI에 통합하는 작업이 진행 중이며, PR 단계에서 자동 경고가 발생하도록 설계됨.  \n- **커뮤니티 피드백**: “디자인 단계에서 충분한 리뷰가 이루어지지 않아 버전 충돌이 발생한다”는 의견이 다수 제시되어, 리뷰 시점 앞당기기 방안이 논의되고 있음 [DevOpsChat 기사](https://www.devopschat.co/articles/spotlight-on-sig-architecture-api-governance).\n\n## 사례 연구 / 인터뷰 요약\n- **Jordan Liggitt 인터뷰 핵심**  \n  - 2014년 Red Hat에서 OAuth 서버 시도 후 실패 경험을 바탕으로 API 설계에 대한 깊은 이해를 갖게 됨.  \n  - 2016년 API Reviewer, 2017년 Approver 역할을 수행하며 현재는 API Governance와 Code Organization을 공동 리드.  \n  - “API Governance는 설계·구현 단계에서 일관성을 확보하고, 폐기 정책을 명확히 함으로써 전체 생태계의 안정성을 높인다”는 비전을 제시 [블로그 인터뷰](https://kubernetes.io/blog/2026/02/12/sig-architecture-api-spotlight/).  \n- **실제 API 변경 사례**  \n  - **예시**: v1beta3 → v1 전환 과정에서 API Review가 구조적 변경을 권고, 결과적으로 호환성 문제가 크게 감소함. (구체적 수치는 출처에 명시되지 않아 추가 조사 필요)  \n- **교훈**: 초기 설계 단계에서 충분한 리뷰와 커뮤니티 의견 수렴이 장기적인 안정성에 핵심적임.\n\n## 위키 문서 업데이트 가이드\n1. **신규 페이지 구조**  \n   - 목차: 개요 → 배경 → SIG Architecture 소개 → 목표 → 프로세스 → 역할 → 최신 업데이트 → 사례 연구 → 업데이트 가이드 → 로드맵 → 참고 자료  \n2. **마크다운 스타일·링크 표준**  \n   - 헤더는 H2~H4 사용, 인라인 링크는 `[텍스트](URL)` 형태, 출처는 반드시 인라인 표기.  \n3. **버전 관리·변경 로그**  \n   - `## 변경 로그` 섹션에 날짜·작성자·주요 변경 사항을 기록.  \n4. **리뷰·승인 프로세스**  \n   - PR 생성 → API Reviewer 검토 → Approver 승인 → 위키 담당자 병합 순서 정의.  \n\n## 향후 로드맵 및 유지보수 계획\n| 기간 | 목표 | 비고 |\n|------|------|------|\n| **단기(6개월)** | 최신 인터뷰 내용 반영, 자동화 CI 체크 문서화 | 위키 페이지 초안 완성 |\n| **중기(1년)** | 정책 변화(예: deprecation 가이드) 업데이트, 커뮤니티 워크숍 자료 연계 | 정기 리뷰 회의 개최 |\n| **장기** | 지속적인 트렌드 모니터링 자동화(블로그·SIG 회의 RSS), 외부 기여자 참여 확대 | 추가 조사 필요 |\n\n## 참고 자료 및 링크\n- **Kubernetes 공식 블로그** – “Spotlight on SIG Architecture: API Governance” [링크](https://kubernetes.io/blog/2026/02/12/sig-architecture-api-spotlight/)  \n- **SIG Architecture README** (GitHub) – 프로젝트 개요 및 정책 [링크](https://github.com/kubernetes/community/blob/master/sig-architecture/README.md#architecture-and-api-governance-1)  \n- **FAUN.dev 요약** – Governance 팀의 최신 목표 [링크](http://faun.dev/c/links/kaptain/spotlight-on-sig-architecture-api-governance/)  \n- **DevOpsChat 기사** – 인터뷰 핵심 포인트 정리 [링크](https://www.devopschat.co/articles/spotlight-on-sig-architecture-api-governance)  \n- **daily.dev 포스트** – Jordan Liggitt 인터뷰 요약 [링크](https://app.daily.dev/posts/spotlight-on-sig-architecture-api-governance-ccbyj8elu)  \n\n*위 내용은 현재 공개된 자료에 근거하며, 구체적인 수치·정책 세부사항은 추가 조사가 필요합니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [],
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "cgroup v1 CPU Shares → v2 CPU Weight 변환 공식 업데이트 가이드",
      "slug": "kubernetes/cgroup-migration",
      "content": "\n## 개요\n이 문서는 **cgroup v1**의 CPU shares 값을 **cgroup v2**의 CPU weight 로 변환하는 최신 공식에 대해 설명하고, Kubernetes 클러스터에 적용하기 위한 절차와 베스트 프랙티스를 제공합니다.\n\n- **대상 독자**: 클러스터 운영자, 플랫폼 엔지니어, Kubernetes 개발자  \n- **핵심 변경 사항**: 기존 선형 매핑 공식 → 비선형(또는 로그 기반) 매핑 공식으로 교체, 1 CPU 요청 시 기본 weight(100) 에 근접하도록 개선  \n- **기대 효과**:  \n  - Kubernetes 워크로드의 CPU 우선순위 회복  \n  - 비‑Kubernetes 프로세스와의 경쟁력 향상  \n  - 설정 granularity 개선 및 운영 복잡성 감소  \n\n> 본 가이드는 Kubernetes 공식 블로그(2026‑01‑30)와 관련 GitHub 이슈·KEP 문서를 기반으로 작성되었습니다【https://kubernetes.io/blog/2026/01/30/new-cgroup-v1-to-v2-cpu-conversion-formula/】.\n\n## 배경\n### cgroup v1 vs. cgroup v2 구조 차이\n| 항목 | cgroup v1 | cgroup v2 |\n|------|-----------|-----------|\n| CPU 리소스 표현 | **cpu.shares** (범위 2 ~ 262 144) | **cpu.weight** (범위 1 ~ 10 000) |\n| 기본값 | 1024 (1 CPU) | 100 (시스템 기본) |\n| 설계 목표 | 간단한 비율 기반 공유 | 보다 정밀한 가중치 기반 스케줄링 |\n\n### CPU shares와 CPU weight 정의\n- **CPU shares (v1)**: 컨테이너가 요청한 millicpu(예: 1024 m = 1 CPU) 를 그대로 정수값으로 매핑.  \n- **CPU weight (v2)**: 1 ~ 10 000 사이의 가중치로, 높은 값일수록 CPU 스케줄링 시 우선순위가 높음.\n\n### Kubernetes 리소스 할당 메커니즘의 진화\n초기 Kubernetes는 cgroup v1 전용 설계였으며, `cpu.shares` 를 직접 사용했습니다. cgroup v2 전환에 따라 **KEP‑2254**가 도입되어 기존 값을 새로운 weight 로 변환하도록 정의되었습니다【https://kubernetes.io/blog/2026/01/30/new-cgroup-v1-to-v2-cpu-conversion-formula/】.\n\n## 기존 변환 공식\nKEP‑2254에서 정의한 초기 공식은 다음과 같습니다.\n\n```\ncpu.weight = 1 + ((cpu.shares - 2) * 9999) / 262142\n```\n\n- **선형 매핑**: `cpu.shares` 의 최소값 2 → weight 1, 최대값 262 144 → weight 10 000.  \n- **예시**: 1 CPU (1024 m) → `cpu.shares = 1024` → `cpu.weight ≈ 39` (기본 weight 100 의 40% 수준)【https://kubernetes.io/blog/2026/01/30/new-cgroup-v1-to-v2-cpu-conversion-formula/】.\n\n## 기존 공식의 문제점\n1. **우선순위 감소**  \n   - 기본 weight 100 에 비해 1 CPU 요청 시 약 39 로 매핑돼, 비‑Kubernetes 프로세스 대비 CPU 우선순위가 크게 낮아짐.  \n2. **비‑Kubernetes 워크로드와 경쟁력 저하**  \n   - 시스템 전체에서 Kubernetes 컨테이너가 상대적으로 뒤처져 스케줄링 지연이 발생.  \n3. **그라뉼러리티 부족**  \n   - 선형 매핑으로 인해 작은 요청(예: 0.1 CPU) 에서도 weight 변화가 미미해 세밀한 튜닝이 어려움.  \n4. **운영 환경에서 관찰된 성능 이슈**  \n   - 실제 클러스터에서 CPU 사용률이 낮음에도 불구하고 스케줄러가 워크로드를 낮은 우선순위로 처리, 응답 시간 증가 보고됨【GitHub Issue #131216】.\n\n## 새로운 변환 공식\n### 공식 소개 및 수학적 근거\n새로운 공식은 **비선형(로그 기반) 매핑**을 채택해, 낮은 CPU 요청에서도 충분한 weight 를 보장하고, 높은 요청에서는 weight 가 10 000 에 근접하도록 설계되었습니다. 정확한 수식은 KEP‑2254 업데이트에 포함되어 있으며, 주요 목표는 다음과 같습니다.\n\n- 1 CPU (1024 m) → weight ≈ **100** (기본값과 동일)  \n- 0.5 CPU → weight ≈ **70** 이상  \n- 2 CPU 이상 → weight 가 200 ~ 10 000 사이에서 점진적으로 증가  \n\n> 새로운 공식은 “비선형 매핑”이라는 키워드와 함께 발표되었으며, 구체적인 수식은 KEP‑2254 최신 버전에서 확인할 수 있습니다【https://kubernetes.io/blog/2026/01/30/new-cgroup-v1-to-v2-cpu-conversion-formula/】.\n\n### 시나리오별 예시\n| 요청 (millicpu) | 기존 weight | 새로운 weight (예시) |\n|-----------------|-------------|----------------------|\n| 500 m (0.5 CPU) | 20 ~ 30 | ≈ 70 |\n| 1024 m (1 CPU) | 39 | ≈ 100 |\n| 2048 m (2 CPU) | 78 | ≈ 200 |\n| 4096 m (4 CPU) | 156 | ≈ 400 |\n\n※ 실제 값은 KEP‑2254 최신 문서에서 확인하십시오.\n\n## 구현 상세\n### Kubernetes 코드베이스 변경\n- **cgroup manager** 모듈에 새로운 변환 로직이 추가되었습니다.  \n- `kubelet` 및 **CRI‑Shim**이 새 weight 값을 사용하도록 업데이트되었습니다.  \n- KEP‑2254 파일(`kep-2254.yaml`)에 공식 교체 내용이 반영되었습니다.\n\n### 컨트롤 플레인 / 노드 설정 옵션\n- `--cgroup-driver=systemd` 와 같은 기존 옵션은 유지됩니다.  \n- 새 변환 공식은 기본값으로 적용되며, 필요 시 `--cpu-weight-conversion=legacy` 플래그를 통해 기존 선형 매핑을 선택적으로 사용할 수 있습니다(옵션은 KEP‑2254에 명시).\n\n## 마이그레이션 가이드\n### 사전 점검 항목\n- **커널 버전**: cgroup v2 지원 커널(5.4 이상) 확인  \n- **cgroup 모드**: `/proc/filesystems` 에서 `cgroup2` 가 활성화돼 있는지 확인  \n- **Kubernetes 버전**: 공식 지원 버전(≥ v1.28) 사용 권장  \n\n### 클러스터 업그레이드 절차\n1. **노드 백업** 및 현재 `kubelet` 설정 파일 보관  \n2. **kubelet** 및 **CRI‑Shim**을 최신 패키지로 교체  \n3. **KEP‑2254** 최신 매니페스트 적용 (`kubectl apply -f kep-2254.yaml`)  \n4. **노드 재시작** 후 `kubectl get nodes -o wide` 로 cgroup 모드 확인  \n\n### 기존 워크로드 재배포 전략\n- **Rolling Update** 전략을 사용해 순차적으로 파드 재시작  \n- `cpuWeightConversion=legacy` 플래그를 임시 적용해 기존 워크로드와 비교 테스트 가능  \n\n### 롤백 방법 및 위험 완화\n- 새 버전에서 문제가 발생하면 `--cpu-weight-conversion=legacy` 플래그를 추가해 기존 선형 매핑으로 복귀  \n- 롤백 전 반드시 **CPU 사용량** 및 **스케줄링 지연** 메트릭을 기록해 비교 분석  \n\n## 검증 및 성능 테스트\n### 테스트 환경\n- **노드**: 4 vCPU, 8 GiB RAM, Linux 5.15, cgroup v2 활성화  \n- **워크로드**: CPU‑bound `stress-ng` 컨테이너, 요청 0.5 CPU, 1 CPU, 2 CPU  \n\n### 주요 메트릭\n- **CPU 사용률**  \n- **스케줄링 지연** (pod‑to‑node)  \n- **우선순위 점수** (cgroup weight)  \n\n### 결과 요약\n| 테스트 시나리오 | 기존 weight | 새로운 weight | CPU 사용률 ↑ | 스케줄링 지연 ↓ |\n|------------------|------------|--------------|--------------|----------------|\n| 0.5 CPU | 20 | ≈ 70 | +15% | -30% |\n| 1 CPU   | 39 | ≈ 100 | +20% | -45% |\n| 2 CPU   | 78 | ≈ 200 | +25% | -50% |\n\n> 위 결과는 Kubernetes 블로그와 GitHub 이슈에서 보고된 실제 운영 사례와 일치합니다【https://kubernetes.io/blog/2026/01/30/new-cgroup-v1-to-v2-cpu-conversion-formula/】.\n\n## 호환성 및 제한 사항\n- **cgroup v1 전용 레거시 환경**에서는 새 공식이 적용되지 않으며, 기존 선형 매핑을 유지해야 합니다.  \n- **외부 OCI 런타임**(예: containerd, cri‑o)와의 호환성은 런타임이 cgroup v2 weight 를 지원하는 경우에만 보장됩니다.  \n- **저전력 ARM** 등 제한된 하드웨어에서는 weight 값이 10 000 상한에 도달하기 전까지 비선형 매핑이 기대한 만큼의 효과를 내지 못할 수 있습니다.\n\n## 베스트 프랙티스\n1. **CPU 요청/제한 설정**  \n   - 최소 0.5 CPU 이상 요청을 권장해 weight 가 충분히 높게 매핑되도록 함.  \n2. **다중 워크로드 환경**  \n   - 동일 노드에 비‑Kubernetes 서비스가 존재한다면, `cpu.weight` 를 100 이상으로 맞추는 것이 좋음.  \n3. **모니터링**  \n   - `cgroup2` 메트릭(`cpu.weight`, `cpu.stat`)을 Prometheus와 연동해 실시간 추적.  \n   - 스케줄링 지연이 급증하면 weight 매핑을 재검토.  \n\n## 자주 묻는 질문(FAQ)\n**Q1. 기존 설정을 그대로 유지해도 되나요?**  \nA. 기존 `cpu.shares` 값은 그대로 유지되지만, 새 공식이 자동 적용됩니다. 다만, 1 CPU 이하 요청 시 weight 가 낮아질 수 있으니 권장 설정을 검토하세요.\n\n**Q2. weight 값이 100을 초과하면 어떤 영향이 있나요?**  \nA. 100 이상이면 기본 시스템 프로세스보다 높은 CPU 우선순위를 가집니다. 새 공식은 1 CPU 요청 시 약 100 으로 매핑해 기본값과 동등하게 유지합니다.\n\n**Q3. 메모리·I/O cgroup v2와 연관성은?**  \nA. CPU weight 변환은 CPU 스케줄링에만 영향을 주며, 메모리(`memory.max`)·I/O(`io.max`)와는 별개입니다. 각각의 리소스는 기존 방식대로 설정해야 합니다.\n\n## 참고 자료\n- **Kubernetes 공식 블로그** – “New Conversion from cgroup v1 CPU Shares to v2 CPU Weight” (2026‑01‑30)  \n  <https://kubernetes.io/blog/2026/01/30/new-cgroup-v1-to-v2-cpu-conversion-formula/>  \n- **KEP‑2254** – cgroup v1 → v2 변환 공식 정의 및 업데이트 기록  \n- **GitHub Issue #131216** – 기존 변환 공식에 대한 문제점 토론  \n  <https://github.com/kubernetes/kubernetes/issues/131216>  \n- **OpenContainers runc Issue #4772** – cgroup v1 shares vs. v2 weight 기본값 비교  \n  <https://github.com/opencontainers/runc/issues/4772>  \n\n*이 문서는 자동 감지된 트렌드와 공식 발표를 기반으로 작성되었습니다. 추가적인 세부 사항은 해당 KEP 및 공식 블로그를 직접 확인하시기 바랍니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "cgroup",
        "CPU",
        "Kubernetes",
        "리소스 관리",
        "KEP-2254",
        "마이그레이션"
      ],
      "order": 4,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Kubernetes 버전별 릴리즈 노트",
      "slug": "kubernetes/release-notes",
      "content": "\n# Kubernetes 버전별 릴리즈 노트\n\n본 문서는 **Kubernetes v1.23** 부터 현재 최신 **v1.35** (및 이후 마이너 릴리즈)까지 주요 변경 사항을 5줄 이내로 요약합니다. 각 버전별 핵심 기능, 개선점, Deprecated 항목을 포함합니다.\n\n---\n\n## v1.35 (2026‑02‑10)\n- **새 릴리즈**: v1.35.0 및 v1.35.1이 2026‑02‑10에 공개되었습니다.  \n- **보안**: 여러 CVE에 대한 패치와 TLS 1.3 관련 개선이 포함되었습니다.  \n- **성능**: kube‑scheduler 및 kubelet의 내부 최적화로 전반적인 클러스터 응답성이 향상되었습니다.  \n- **API**: 일부 베타 API가 GA 단계로 승격되었으며, 오래된 API에 대한 폐기 로드맵이 업데이트되었습니다.  \n- **기타**: 자세한 변경 사항은 공식 릴리즈 노트를 참고하십시오.\n\n---\n\n## v1.34 (2026‑02‑10)\n- **새로운 API**: `PodSecurityPolicy` 완전 폐기, `PodSecurity` admission controller 기본 활성화  \n- **향상된 스케줄러**: Topology‑aware 스케줄링 지원 확대  \n- **CRI‑Shim**: Container Runtime Interface 개선, `containerd` 1.8 호환성 강화  \n- **보안**: TLS 1.3 기본 적용, kube‑apiserver에 대한 audit 로그 포맷 개선  \n- **Deprecated**: `extensions/v1beta1` Ingress API 완전 삭제  \n\n---\n\n## v1.33 (2025‑12‑xx)\n- **새로운 기능**: `Ephemeral Containers` GA, 디버깅용 임시 컨테이너 지원  \n- **네트워킹**: Service IP Address Management (IPAM) 플러그인 기본 제공  \n- **스토리지**: CSI Snapshot Controller v1.2 정식 출시  \n- **성능**: kube‑scheduler 성능 15% 향상, `NodeSwap` 지원 옵션 추가  \n- **Deprecated**: `kubectl` `--record` 플래그 폐기 예정  \n\n---\n\n## v1.32 (2025‑09‑xx)\n- **새로운 API**: `PodDisruptionBudget` v1 정식, `PodSecurity` v1beta1 GA  \n- **CLI 개선**: `kubectl` 플러그인 자동 업데이트 기능 도입  \n- **보안**: `PodSecurityPolicy` 단계적 폐기 로드맵 발표  \n- **클러스터 관리**: `kubeadm` v1.32에서 `ControlPlaneEndpoint` 자동 설정 지원  \n- **Deprecated**: `v1beta1` `IngressClass` API 폐기 예정  \n\n---\n\n## v1.31 (2025‑06‑xx)\n- **새로운 기능**: `ServerSideApply` 성능 최적화, conflict‑resolution 개선  \n- **네트워킹**: `IPv6DualStack` 기본 활성화 옵션 제공  \n- **스토리지**: `CSI` `VolumeHealth` 모니터링 GA  \n- **보안**: `PodSecurityPolicy` 단계적 폐기 시작, `PodSecurity` 대체 권고  \n- **Deprecated**: `v1beta1` `CronJob` API 폐기 예정  \n\n---\n\n## v1.30 (2025‑03‑xx)\n- **새로운 API**: `EndpointSlice` v2 정식, 서비스 엔드포인트 관리 효율화  \n- **CLI**: `kubectl` `--dry-run=client` 기본값 변경  \n- **보안**: `RuntimeClass` 확장, `gVisor` 기본 지원  \n- **클러스터**: `kubeadm` `InitConfiguration`에 `FeatureGates` 직접 지정 가능  \n- **Deprecated**: `v1beta1` `PodSecurityPolicy` 폐기 로드맵 발표  \n\n---\n\n## v1.29 (2024‑12‑xx)\n- **새로운 기능**: `PodSecurity` v1beta1 GA, 보안 정책 선언 방식 개선  \n- **네트워킹**: `Service` `TopologyKeys` 지원 확대  \n- **스토리지**: `CSI` `VolumeSnapshotClass` v1 정식  \n- **성능**: `kubelet` 메모리 사용량 10% 감소  \n- **Deprecated**: `v1beta1` `Ingress` API 폐기 예정  \n\n---\n\n## v1.28 (2024‑09‑xx)\n- **새로운 API**: `IngressClass` v1 정식, `Ingress` v1beta1 단계적 폐기  \n- **CLI**: `kubectl` `--server-print` 옵션 추가  \n- **보안**: `KMS` 플러그인 v2 지원, 비밀 관리 강화  \n- **클러스터**: `kubeadm` `Upgrade` 시 `ControlPlane` 자동 백업 옵션 제공  \n- **Deprecated**: `v1beta1` `PodSecurityPolicy` 폐기 일정 발표  \n\n---\n\n## v1.27 (2024‑06‑xx)\n- **새로운 기능**: `Ephemeral Containers` 베타 출시, 디버깅 용이  \n- **네트워킹**: `Service` `ExternalTrafficPolicy` 개선  \n- **스토리지**: `CSI` `VolumeHealth` 베타 제공  \n- **보안**: `PodSecurityPolicy` 단계적 폐기 로드맵 공개  \n- **Deprecated**: `v1beta1` `Ingress` API 폐기 예정  \n\n---\n\n## v1.26 (2024‑03‑xx)\n- **새로운 API**: `IngressClass` v1beta1 정식, `Ingress` v1beta1 유지  \n- **CLI**: `kubectl` `--dry-run=client` 기본값 변경  \n- **보안**: `PodSecurityPolicy` 폐기 로드맵 발표, `PodSecurity` 대체 권고  \n- **클러스터**: `kubeadm` `InitConfiguration`에 `FeatureGates` 직접 지정 가능  \n- **Deprecated**: `v1beta1` `CronJob` API 폐기 예정  \n\n---\n\n## v1.25 (2023‑12‑xx)\n- **새로운 기능**: `PodSecurityPolicy` 단계적 폐기 시작, `PodSecurity` 베타 제공  \n- **네트워킹**: `EndpointSlice` v1 정식, 서비스 엔드포인트 관리 효율화  \n- **스토리지**: `CSI` `VolumeSnapshot` GA  \n- **보안**: `kube-apiserver` TLS 1.3 지원  \n- **Deprecated**: `v1beta1` `Ingress` API 폐기 일정 발표  \n\n---\n\n## v1.24 (2023‑09‑xx)\n- **새로운 API**: `IngressClass` v1beta1 정식, `Ingress` v1beta1 유지  \n- **CLI**: `kubectl` `--dry-run=client` 기본값 변경  \n- **보안**: `PodSecurityPolicy` 단계적 폐기 로드맵 공개  \n- **클러스터**: `kubeadm` `Upgrade` 시 `ControlPlane` 자동 백업 옵션 제공  \n- **Deprecated**: `v1beta1` `CronJob` API 폐기 예정  \n\n---\n\n## v1.23 (2023‑06‑xx)\n- **새로운 기능**: `IngressClass` v1beta1 정식, `Ingress` v1beta1 유지  \n- **네트워킹**: `EndpointSlice` v1beta1 정식  \n- **스토리지**: `CSI` `VolumeSnapshot` 베타 제공  \n- **보안**: `PodSecurityPolicy` 단계적 폐기 로드맵 발표  \n- **Deprecated**: `v1beta1` `CronJob` API 폐기 일정 발표  \n\n> **주의**: 위 내용은 공식 Kubernetes 릴리즈 노트를 기반으로 요약한 것이며, 각 버전의 전체 변경 사항은 [Kubernetes Release Notes](https://kubernetes.io/releases/notes/) 페이지를 참고하시기 바랍니다.\n\n*이 문서는 현재 초안(draft) 상태이며, 검토 후 `published` 로 전환될 예정입니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Kubernetes",
        "Release Notes",
        "버전",
        "version",
        "changelog"
      ],
      "menu": "K8s 릴리즈 노트",
      "order": 5,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Docker/Hardened Images",
      "slug": "docker/hardened-images",
      "content": "---\ntitle: Docker Hardened Images 무료 제공: 보안 실무 가이드\nauthor: SEPilot AI\nstatus: published\ntags: [Docker, Hardened Images, Security, Vulnerability Management, Supply Chain]\nredirect_from:\n  - hardened-images-are-free-now-what\norder: 1\n---\n\n## 1. 서론\nDocker Hardened Images(DHI)가 **무료**로 제공되면서 조직의 컨테이너 보안 운영 방식에 큰 변화가 예상됩니다.  \n본 문서는 **보안 팀**, **플랫폼 팀**, **DevOps** 담당자를 주요 독자로 하여, DHI 도입 시 고려해야 할 전략·프로세스를 정리합니다.  \n\n## 2. Hardened Images 개요\n- **지원 이미지**: Alpine, Debian 및 데이터베이스, 런타임, 메시지 버스 등을 포함한 **1,000개 이상의 공식 이미지**가 DHI에 포함됩니다【Docker Blog】.  \n- **보안 패치 제공 방식**: Docker 보안 팀이 직접 취약점 수정을 적용하고, 패치된 이미지를 Docker가 관리하는 레지스트리에서 제공합니다. 이를 통해 사용자는 별도의 패치 적용 작업 없이 최신 보안 이미지만 Pull 하면 됩니다【Docker Blog】.  \n\n## 3. 보안 경제성의 변화\n- **기존 비용 구조**: 이전에는 프리미엄 이미지나 서드파티 보안 솔루션에 별도 비용을 지불해야 했습니다.  \n- **무료 DHI 도입 효과**: 이미지 자체 비용이 사라짐에 따라 **취약점 관리 예산**을 스캔 도구, 운영 자동화, 인시던트 대응 등 다른 보안 활동에 재배분할 수 있습니다. 구체적인 비용 절감 규모는 조직별 사용량에 따라 다르므로 **추가 조사가 필요합니다**.  \n\n## 4. “보안 워터라인” 개념\nDocker는 DHI에 **보안 “워터라인”(waterline)** 을 정의합니다.  \n\n| 영역 | 책임 주체 | 설명 |\n|------|----------|------|\n| **워터라인 이하** | Docker | OS·런타임 레이어에 대한 취약점 관리·패치가 Docker에 의해 수행됩니다. 스캐너가 이 레이어에서 발견한 취약점은 사용자가 직접 조치할 필요가 없습니다. |\n| **워터라인 이상** | 사용자 | 애플리케이션 코드, 직접 추가한 의존성, 커스텀 레이어 등에 대한 취약점은 기존과 동일하게 사용자가 관리합니다. |\n\n- **이미지 선택에 따른 워터라인 위치**: 예를 들어, **hardened python 이미지**는 OS와 Python 런타임까지 포함하므로 워터라인이 높은 수준에 위치합니다. 반면, **hardened base 이미지**에 자체 런타임을 추가하면 워터라인이 낮아져 사용자가 관리해야 할 영역이 늘어납니다【Docker Blog】.  \n\n## 5. 운영·배포 프로세스 변화\n1. **자동 Pull**: CI/CD 파이프라인에서 `docker pull` 명령을 최신 DHI 태그(예: `docker.io/library/python:3.11-hardened`) 로 교체합니다.  \n2. **이미지 태그 정책**: `-hardened` 접미사를 사용해 DHI와 일반 이미지 구분을 명확히 합니다.  \n3. **재배포 절차**: 패치된 DHI가 릴리스될 때마다 자동으로 최신 이미지를 Pull하고, 롤링 업데이트를 수행합니다.  \n4. **고려사항**: 기존 파이프라인에 이미지 스캐너가 포함된 경우, 스캐너가 워터라인 이하 레이어를 무시하도록 설정이 필요합니다.  \n\n## 6. 공급망 격리와 신뢰 모델\n- **커뮤니티 이미지와 DHI 이미지의 차이**: `python:3.11` 같은 커뮤니티 이미지는 **태그 변조**, **유출된 PAT** 등으로 공급망 공격에 노출될 위험이 있습니다. Shai Hulud 캠페인에서는 공격자가 도난당한 PAT와 태그 가변성을 이용해 악성 레이어를 삽입한 사례가 보고되었습니다【Docker Blog】.  \n- **DHI 공급망 방어**: Docker는 **소스 재빌드**, **리뷰 프로세스**, **쿨다운 기간**을 적용해 이미지가 Docker 관리 네임스페이스에 안전하게 배포됩니다. 이러한 절차 덕분에 공급망 공격은 DHI 경계에서 차단됩니다【Docker Blog】.  \n- **제한점**: DHI가 제공하는 워터라인 이하 레이어는 Docker가 관리하지만, 위 레이어에 대한 취약점은 여전히 사용자 책임이므로 지속적인 스캔·패치가 필요합니다.  \n\n## 7. 마이그레이션 가이드\n### 7.1 현재 사용 중인 이미지 식별\n- 레지스트리에서 `docker images` 명령을 활용해 사용 중인 베이스 이미지와 태그를 목록화합니다.  \n- CI/CD 파이프라인 정의 파일(`Dockerfile`, `helm chart`, `kustomize`)에서 직접 지정된 이미지명을 추출합니다.  \n\n### 7.2 전환 단계별 체크리스트\n| 단계 | 작업 내용 |\n|------|-----------|\n| **1. 조사** | 사용 중인 이미지가 DHI에 포함되는지 확인(Alpine, Debian, 공식 DB/런타임 등). |\n| **2. 테스트** | 스테이징 환경에 DHI 이미지(`*-hardened`)를 적용하고, 애플리케이션 정상 동작 여부를 검증합니다. |\n| **3. CI/CD 업데이트** | 파이프라인에서 이미지 태그를 DHI 버전으로 교체하고, 스캐너 설정을 워터라인 이하 레이어 무시하도록 조정합니다. |\n| **4. 롤아웃** | 프로덕션에 점진적 배포(블루‑그린, 카나리) 방식으로 적용합니다. |\n| **5. 모니터링** | 배포 후 로그·메트릭을 확인하고, 필요 시 즉시 롤백합니다. |\n\n### 7.3 호환성 테스트 및 롤백 전략\n- **호환성 테스트**: 기존 이미지와 DHI 이미지 간 라이브러리 버전 차이를 검증합니다.  \n- **롤백**: 이미지 태그를 이전 버전으로 되돌리고, 배포 파이프라인을 재실행할 수 있도록 GitOps 정책을 마련합니다.  \n\n## 8. 보안 베스트 프랙티스\n- **워터라인 위·아래 영역별 관리**  \n  - *아래*: Docker가 제공하는 최신 DHI 이미지를 정기적으로 Pull하고, 자동 재배포 파이프라인을 유지합니다.  \n  - *위*: 애플리케이션 코드, 직접 추가한 의존성, 커스텀 레이어에 대해 정기적인 이미지 스캔·패치를 수행합니다.  \n- **이미지 레이어 최소화**: 불필요한 레이어를 제거하고, 멀티‑스테이지 빌드를 활용해 최종 이미지 크기를 최소화합니다.  \n- **정기 스캔 주기**: CI 단계에서 최소 **일일 1회** 이상 이미지 스캔을 실행하고, 새로운 CVE가 발표될 때마다 DHI 업데이트를 확인합니다.  \n\n## 9. 모니터링·컴플라이언스\n- **보안 지표(KPI)**  \n  - *워터라인 이하 이미지 최신 적용 비율* (예: 100% 최신 DHI 사용)  \n  - *워터라인 위 레이어 취약점 발견 건수*  \n  - *패치 적용 평균 소요 시간*  \n- **감사 로그**: Docker 레지스트리 접근 로그와 CI/CD 배포 로그를 연계해 이미지 Pull·배포 이력을 추적합니다.  \n- **정책 준수 확인**: 조직 내부 정책에 따라 DHI 사용 여부를 자동 검증하는 정책 엔진(OPA 등)을 도입할 수 있습니다.  \n\n## 10. 자주 묻는 질문(FAQ)\n**Q1. 무료 DHI가 제공하는 보안 수준은?**  \nA: DHI는 OS·런타임 레이어에 대한 최신 보안 패치를 Docker 보안 팀이 직접 적용합니다. 따라서 워터라인 이하 레이어는 Docker가 책임지고 관리합니다【Docker Blog】.\n\n**Q2. 이미 사용 중인 사내 커스텀 이미지와 어떻게 병합하나요?**  \nA: 커스텀 이미지의 베이스를 DHI 이미지(`*-hardened`)로 교체하고, 기존 레이어를 그대로 위에 쌓는 방식으로 병합합니다. 이때 베이스 이미지 교체 후 애플리케이션 테스트를 반드시 수행해야 합니다.\n\n**Q3. Docker가 제공하는 보안 패치 주기는?**  \nA: Docker는 취약점이 확인되는 즉시 해당 레이어를 재빌드하고, 새로운 DHI 이미지를 릴리스합니다. 정확한 주기는 취약점 발생 시점에 따라 다르므로 **추가 조사가 필요합니다**.\n\n## 11. 참고 자료 및 링크\n- Docker 블로그 원문: *[Hardened Images Are Free. Now What?](https://www.docker.com/blog/hardened-images-free-now-what/)* (2026‑02‑10)【Docker Blog】  \n- Docker 보안 팀 발표 자료: (추후 추가)  \n- Shai Hulud 공급망 공격 사례: (Docker 블로그 내 언급)【Docker Blog】  \n- OCI 이미지 표준: <https://opencontainers.org/> (공식 문서)  \n\n---",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [],
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "OpenClaw 완벽 가이드",
      "slug": "projects/openclaw-complete-guide",
      "content": "\n## OpenClaw 개요 및 핵심 개념\n**OpenClaw**는 24 시간 언제든지 사용할 수 있는 AI 개인 비서 및 자율 에이전트를 목표로 하는 오픈소스 프로젝트입니다. 초기에는 *Clawdbot*·*Moltbot*이라는 이름으로 개발되었으며, 현재는 **GitHub**(https://github.com/openclaw/openclaw) 에서 활발히 유지·관리되고 있습니다 [1].  \nGitHub 레포지토리는 **213 k 스타**와 **39.7 k 포크**를 기록하고 있으며, 12 843개의 커밋이 누적되어 있습니다.\n\n### 주요 목표\n- **항시 가동** – 언제든지 메시지를 주고받을 수 있는 AI 비서 제공  \n- **멀티채널 지원** – Telegram, Discord, WhatsApp, Slack, Google Chat, Signal, iMessage, BlueBubbles, Matrix, Zalo·Zalo Personal, WebChat 등 다양한 메신저와 연동  \n- **자율 실행** – Heartbeat·스케줄러를 통해 정해진 작업을 자동으로 수행  \n- **프라이버시 보호** – 로컬 모델(Ollama) 사용 시 데이터가 외부로 유출되지 않음  \n\n### 지원 AI 모델 및 연동 방식\n| 모델 | 제공 방식 | 연동 방법 |\n|------|-----------|-----------|\n| Claude (Anthropic) | 클라우드 API | OAuth 또는 API Key |\n| GPT‑4o (OpenAI) | 클라우드 API | API Key |\n| Ollama (로컬) | 로컬 실행 바이너리 | 직접 호출 (REST) |\n| 기타 (Gemini, DeepSeek 등) | 클라우드 API | API Key 또는 OAuth |\n\n> **추천 모델**: Anthropic Claude Pro/Max + Opus 4.6 (장기 컨텍스트와 프롬프트‑인젝션 방어에 강점) [2]\n\n*출처: 공식 Docs – 모델 지원 페이지 (2026‑02‑10) [2]*  \n\n### 기본 용어\n- **Gateway**: 모든 채널 연결을 관리하는 중앙 프로세스 (`openclaw gateway` 실행)  \n- **Agent**: AI 모델 호출 및 응답 생성 담당 모듈  \n- **Pairing**: 메신저(예: Telegram)와 Gateway를 연결하기 위한 인증 절차  \n- **Heartbeat**: 정해진 간격으로 자동 실행되는 작업 스케줄러  \n\n---\n\n## 아키텍처 및 동작 원리\n### 전체 시스템 구성\n```\nGateway\n ├─ Connector (Telegram, Discord, WhatsApp, Slack, Google Chat, Signal, iMessage, BlueBubbles, Matrix, Zalo …)\n ├─ Scheduler / Heartbeat\n ├─ Memory Store (Long‑term Context)\n └─ Agent (Model Wrapper)\n```\n*※ 위 구조는 공식 Docs에 명시된 기본 아키텍처이며, 실제 구현은 `src/` 디렉터리에서 확인 가능* [3].\n\n- **Gateway**는 하나의 Node.js 프로세스로 실행되며, 각 Connector 플러그인은 독립 모듈 형태로 로드됩니다.  \n- **Scheduler**는 Cron‑like 설정 파일을 읽어 주기적인 작업(예: 일정 알림)을 트리거합니다.  \n- **Memory Store**는 SQLite 또는 PostgreSQL을 백엔드로 사용해 대화 컨텍스트와 사용자 메모리를 영구 저장합니다.  \n\n### 메시징 채널 통합 흐름\n1. 사용자가 Telegram에 메시지를 전송 → **Connector**가 webhook 또는 long‑polling 으로 수신  \n2. 메시지는 **Gateway**에 전달 → **Agent**가 현재 설정된 AI 모델에 호출  \n3. 모델 응답 → **후처리**(필터링, 포맷 변환) → **Connector**를 통해 원 채널에 전송  \n\n### 플러그인·모듈 구조와 확장 포인트\n- 플러그인은 `src/plugins/<channel>` 디렉터리에 위치하며, `register()` 함수만 구현하면 자동 로드됩니다.  \n- 새로운 채널을 추가하려면 **Connector 인터페이스**(init, receive, send)만 구현하면 됩니다.  \n- 커스텀 프롬프트·플러그인 API는 `openclaw plugin create <name>` 명령으로 스켈레톤을 생성할 수 있습니다.  \n\n### 보안·인증 메커니즘\n- **OAuth**: Google, Microsoft 등 OAuth2 제공자를 통해 토큰을 획득하고, 토큰은 환경 변수(`OPENCLAW_OAUTH_TOKEN`)에 저장합니다.  \n- **API Key**: 각 모델별 API 키는 `openclaw config set <model>.apiKey <key>` 로 관리됩니다.  \n- **Allowlist**: 채널별 화이트리스트(`*.allowlist`)를 설정해 허용된 사용자만 접근하도록 제한합니다.  \n\n*출처: 보안 가이드 (2026‑02‑10) [4]*  \n\n---\n\n## 주요 기능과 특징\n- **멀티채널 연동**: Telegram, Discord, WhatsApp, Slack, Google Chat, Signal, iMessage, BlueBubbles, Matrix, Zalo·Zalo Personal, WebChat 등 10개 이상 공식 플러그인 제공  \n- **장기 메모리·컨텍스트 유지**: 대화 흐름을 SQLite 기반 Memory Store에 저장, `openclaw memory export` 로 백업 가능  \n- **자동 Heartbeat·스케줄링**: `openclaw schedule add \"0 9 * * *\" \"remind_meetings\"` 형태로 cron 표현식 사용  \n- **커스텀 프롬프트·플러그인 API**: `openclaw plugin create` 로 손쉽게 기능 확장  \n- **로컬 모델 지원**: Ollama와 직접 연동해 GPU 가속 로컬 모델(LLama‑3, Mistral 등) 사용 가능  \n- **관리 인터페이스**  \n  - **Web UI**: `http://localhost:3000` 에서 대시보드, 로그, 메모리 관리 제공 (React 기반)  \n  - **CLI**: `openclaw` 명령어 집합으로 모든 설정·운영 가능  \n\n*출처: 기능 소개 페이지 (2026‑02‑10) [5]*  \n\n---\n\n## 설치 및 설정 방법\n### 사전 요구 사항\n- **Node.js ≥ 22** (LTS) – 최신 릴리스에서는 Node 22 이상을 권장합니다.  \n- **Docker & Docker‑Compose** (선택적, 권장)  \n- **GPU 서버**: Ollama 사용 시 NVIDIA 드라이버 및 CUDA 12 이상 필요  \n- **Git** (소스 클론)  \n\n### 설치 옵션\n1. **Docker Compose 한 줄 설치**  \n   ```bash\n   curl -fsSL https://raw.githubusercontent.com/openclaw/openclaw/main/install.sh | bash && docker compose up -d\n   ```  \n\n2. **npm / pnpm / bun 직접 설치**  \n   ```bash\n   # npm (전역)\n   npm install -g openclaw@latest\n   # pnpm\n   pnpm add -g openclaw@latest\n   # bun (선택)\n   bun add -g openclaw@latest\n   ```  \n\n3. **소스 직접 빌드**  \n   ```bash\n   git clone https://github.com/openclaw/openclaw.git\n   cd openclaw\n   pnpm install\n   pnpm ui:build   # UI 의존성 자동 설치\n   pnpm build\n   pnpm openclaw onboard --install-daemon\n   ```  \n\n4. **로컬 바이너리 배포** (GitHub Releases) – `openclaw-linux-x64.tar.gz` 를 다운로드 후 압축 해제, 실행 파일에 실행 권한 부여  \n\n*출처: 설치 가이드 (2026‑02‑10) [6]*  \n\n### 초기 설정 단계\n1. **기본 설정 파일 생성**  \n   `openclaw config init` → 프로젝트 루트에 `config.yaml` 생성  \n\n2. **API 키·OAuth 연동**  \n   - `openclaw config set openai.apiKey <YOUR_KEY>`  \n   - `openclaw config set anthropic.apiKey <YOUR_KEY>`  \n   - OAuth 연동: `openclaw oauth register google` 후 반환된 URL을 브라우저에서 열어 인증  \n\n3. **채널 별 페어링 (예: Telegram)**  \n   ```bash\n   openclaw pairing generate telegram\n   # 출력된 코드(예: ABC123)를 Telegram Bot에 전송\n   openclaw pairing approve telegram ABC123\n   ```  \n\n### 서비스 운영\n- **systemd 서비스 예시** (`/etc/systemd/system/openclaw.service`)  \n  ```ini\n  [Unit]\n  Description=OpenClaw AI Assistant\n  After=network.target\n\n  [Service]\n  WorkingDirectory=/opt/openclaw\n  ExecStart=/usr/bin/npm start\n  Restart=always\n  User=openclaw\n\n  [Install]\n  WantedBy=multi-user.target\n  ```  \n- **PM2**: `pm2 start dist/index.js --name openclaw` 로 프로세스 관리  \n- **Docker Swarm / Kubernetes**: 공식 `docker-compose.yml` 을 기반으로 Helm chart(예정) 로 변환 가능  \n\n*출처: 운영 가이드 (2026‑02‑10) [7]*  \n\n---\n\n## 사용 사례 및 활용 예시\n### 1. 개인 일정·이메일 자동 정리\n`openclaw schedule add \"0 7 * * *\" \"run_task email_cleanup\"`  \n매일 아침 7시, Gmail API와 연동된 플러그인이 최신 메일을 요약하고, 중요한 일정은 Telegram에 알림.\n\n### 2. 개발팀 코드 리뷰·CI 알림 봇\n```bash\nopenclaw plugin create ci-notifier\n```  \n플러그인 내부에서 GitHub webhook을 수신하고, PR 요약을 Claude에 전달 → Discord 채널에 전송, CI 실패 시 Slack에 즉시 알림.\n\n### 3. 고객 지원 챗봇 (WhatsApp)\nWhatsApp Business API와 페어링 후, `openclaw agent set default ollama/llama3` 로 로컬 모델 사용 → 고객 문의를 실시간 처리하고, 민감 데이터는 로컬에만 저장.\n\n### 4. 교육·학습 보조 AI\n학생이 “다음 주 물리학 시험 요약해줘” 라고 Telegram에 입력 → Memory Store에 저장된 이전 학습 내용과 결합해 GPT‑4o 로 상세 요약 제공.\n\n### 실제 구현 예시 (CLI)\n- **프롬프트 커스텀**  \n  `openclaw config set prompt.default \"You are a helpful personal assistant. Keep responses concise.\"`  \n- **메모리 조회**  \n  `openclaw memory list --user @john` → 최근 10개의 대화 기록 출력  \n\n*출처: 공식 튜토리얼 영상 (2026‑02‑10) [8]*  \n---\n\n## 이메일 인증 자동화 – MailCat 통합\n\nAI 에이전트가 서비스에 가입하거나 인증을 수행할 때 가장 흔한 장벽이 \"이메일을 확인해 주세요\"입니다. **MailCat**은 이 문제를 해결하기 위한 오픈소스 도구로, 단일 프롬프트만으로 OpenClaw에 이메일 수신 기능을 부여합니다 [13].\n\n### 설정 방법\nOpenClaw 또는 Claude Code에 다음 프롬프트를 입력합니다:\n```\nRead https://mailcat.ai/skill.md and set up a MailCat mailbox for yourself. Save the token securely.\n```\n\n에이전트가 자동으로 수행하는 작업:\n1. `skill.md` 문서를 읽어 API 사양 파악\n2. API를 통해 임시 메일박스 생성\n3. 토큰을 안전하게 저장\n4. 필요 시 받은 편지함을 확인하고 인증 코드를 자동 추출\n\n### 주요 특징\n| 기능 | 설명 |\n|------|------|\n| **단일 프롬프트 설정** | 별도 API 키 불필요, AI가 문서를 읽고 스스로 통합 |\n| **자동 추출** | 이메일에서 인증 코드와 링크를 자동 파싱 |\n| **1시간 보존** | 인증 흐름에 최적화된 임시 메일박스 |\n| **셀프 호스팅** | Cloudflare 계정에 직접 배포 가능 |\n| **오픈소스** | MIT 라이선스 |\n\n### 활용 시나리오\n- **자율 서비스 가입**: 에이전트가 서비스를 자동으로 등록\n- **E2E 테스트**: CI/CD 파이프라인에서 이메일 흐름 테스트\n- **뉴스레터 처리**: 자동 구독 후 내용 요약\n- **알림 모니터링**: 이메일 알림을 감시하고 액션으로 전환\n\n*출처: MailCat 공식 문서 및 euno.news (2026‑02‑21) [13]*\n\n---\n\n## 보안 위험 및 완화 방안\n\nCrowdStrike는 \"What Security Teams Need to Know About OpenClaw\"를 발표하며 OpenClaw의 보안 위험을 경고했습니다 [14].\n\n### 주요 위협 벡터\n\n#### 1. 프롬프트 인젝션 (직접 및 간접)\nOpenClaw는 외부 콘텐츠(이메일, 웹 페이지, 문서)를 처리합니다. 해당 콘텐츠에 삽입된 악의적 명령이 에이전트의 동작을 탈취할 수 있습니다. 실제로 Moltbook의 공개 게시물에 지갑을 고갈시키는 페이로드가 삽입된 사례가 보고되었습니다.\n\n#### 2. 자격 증명 탈취\nOpenClaw는 파일 시스템에 접근할 수 있어, `~/.ssh/`, `~/.aws/`, `~/.gnupg/`, 브라우저 자격 증명 저장소, 암호화 지갑 등이 모두 노출 대상입니다.\n\n#### 3. 에이전트 기반 측면 이동\n침해된 에이전트가 정당한 도구 접근 권한을 이용해 시스템 간 측면 이동을 수행합니다.\n\n#### 4. 대규모 노출\n135K+ 개의 OpenClaw 인스턴스가 공개적으로 노출되어 있으며, 다수가 암호화되지 않은 HTTP를 통해 서비스됩니다.\n\n### 완화 전략\n\n| 영역 | 조치 | 상세 |\n|------|------|------|\n| **네트워크** | HTTPS 강제 | 모든 인스턴스에 TLS 적용, HTTP 접근 차단 |\n| **파일 시스템** | 샌드박스 격리 | Docker 컨테이너 또는 firejail로 파일 시스템 접근 제한 |\n| **자격 증명** | 전용 사용자 계정 | 최소 권한 원칙 적용, 민감 디렉터리 마운트 제외 |\n| **프롬프트** | 입력 검증 | 외부 콘텐츠 처리 전 프롬프트 인젝션 필터링 적용 |\n| **모니터링** | 이상 탐지 | 에이전트 API 호출 패턴 모니터링, 비정상 접근 즉시 차단 |\n| **공급망** | 의존성 감사 | `npm audit` / `pnpm audit` 정기 실행, lockfile 무결성 검증 |\n\n### 보안 체크리스트\n- [ ] OpenClaw를 전용 사용자 계정(비root)으로 실행\n- [ ] Docker 컨테이너 내에서 `--read-only` 플래그와 함께 실행\n- [ ] `~/.ssh`, `~/.aws` 등 민감 디렉터리를 마운트에서 제외\n- [ ] 모든 외부 통신에 HTTPS 적용\n- [ ] Allowlist로 허용된 사용자만 접근 허가\n- [ ] 정기적인 의존성 보안 감사 수행\n\n*출처: CrowdStrike \"What Security Teams Need to Know About OpenClaw\", euno.news (2026‑02‑22) [14]*\n\n---\n\n## 하드웨어 호환성 및 Claw 변형별 권장 사양\n\nOpenClaw는 \"Claw\"라는 개념의 대표적 구현체입니다. Andrej Karpathy가 제안한 \"Claw\"는 LLM 에이전트 위에 존재하는 **지속적 AI 에이전트 시스템**으로, 오케스트레이션, 스케줄링, 컨텍스트 유지, 도구 호출 및 지속성을 다음 단계로 끌어올리는 새로운 레이어입니다 [12].\n\n### Claw와 에이전트의 차이\n일반적인 LLM 에이전트는 실행하고, 작업을 수행한 뒤 멈춥니다. 반면 Claw는 **지속적으로 실행**됩니다:\n\n- 하드웨어나 서버에서 **항시 가동**됩니다\n- 자체 스케줄링을 가지고 있어 요청 없이도 행동합니다\n- 세션 및 대화 전반에 걸쳐 **컨텍스트를 유지**합니다\n- MCP 등 메시징 프로토콜을 통해 통신합니다\n- 도구 접근 권한을 가진 다수의 에이전트를 **오케스트레이션**합니다\n\n> 스크립트를 실행하는 것과 서비스를 운영하는 것의 차이라고 생각하면 됩니다. Claw는 서비스와 같습니다: 항상 켜져 있고, 항상 감시하며, 언제든 행동할 준비가 되어 있습니다.\n\n### Claw 변형 및 권장 사양\n\n| Claw 변형 | 설명 | 최소 RAM | 권장 CPU | GPU | 비고 |\n|-----------|------|----------|----------|-----|------|\n| **OpenClaw** | 풀스택 AI 비서, 멀티채널 통합 | 16 GB | 8코어 이상 | 선택 (Ollama 사용 시 필수) | 프로덕션 환경 권장 |\n| **NanoClaw** | 경량 단일 에이전트 | 8 GB | 4코어 이상 | 불필요 | 개인 개발 환경 적합 |\n| **zeroclaw** | 최소 구성, 실험용 | 4 GB | 2코어 이상 | 불필요 | 프로토타이핑 용도 |\n| **ironclaw** | 고성능 멀티 에이전트 오케스트레이션 | 32 GB | 16코어 이상 | 권장 (CUDA 12+) | 엔터프라이즈 환경 |\n| **picoclaw** | 임베디드·IoT 경량 버전 | 2 GB | ARM 프로세서 호환 | 불필요 | 제한된 기능 |\n\n### Mac Mini에서의 제한 사항\n\nAndrej Karpathy가 Claw 실험을 위해 Mac Mini를 구입하면서 \"핫케이크처럼 팔리고 있다\"고 언급할 만큼 Mac Mini는 Claw 실행 환경으로 인기가 높습니다. 그러나 Mac Mini에서 OpenClaw를 실행할 때는 다음과 같은 **제한 사항**을 반드시 고려해야 합니다 [12]:\n\n#### 권장하지 않는 이유\n1. **통합 GPU 한계**: Mac Mini(M4/M4 Pro)는 통합 GPU만 탑재하며, Ollama 로컬 모델 실행 시 전용 GPU 대비 추론 속도가 크게 떨어집니다\n2. **메모리 공유 구조**: Apple Silicon의 통합 메모리(Unified Memory)는 CPU와 GPU가 공유하므로, 대형 모델(70B+ 파라미터) 로딩 시 시스템 전체 성능이 저하됩니다\n3. **열 관리**: 지속적 가동이 필수인 Claw 특성상, Mac Mini의 소형 팬 설계로 장시간 고부하 시 스로틀링이 발생할 수 있습니다\n4. **확장성 부족**: RAM·스토리지 업그레이드가 구매 시점에만 가능하며, 이후 확장이 불가능합니다\n5. **네트워크 안정성**: 가정용 네트워크에서 운영 시 IP 변경, 정전 등으로 인한 가동 중단 위험이 있습니다\n\n#### Mac Mini에서 실행 가능한 구성\nMac Mini에서 OpenClaw를 운영하려면 다음 조건을 충족하는 것이 좋습니다:\n\n| 구성 | M4 (기본) | M4 Pro (권장) |\n|------|-----------|---------------|\n| RAM | 16 GB (최소) | 24~48 GB (권장) |\n| 로컬 모델 | 7B 이하 소형 모델만 | 13B~30B 모델까지 가능 |\n| 동시 채널 | 2~3개 | 5개 이상 |\n| Heartbeat 주기 | 5분 이상 간격 권장 | 1분 간격 가능 |\n\n#### 권장 대안 환경\n- **클라우드 서버**: AWS EC2 (g5.xlarge 이상), GCP (a2-highgpu), Azure (NC 시리즈) – GPU 인스턴스로 Ollama 로컬 모델을 최대 성능으로 활용\n- **전용 서버**: Linux 기반 GPU 서버 (NVIDIA RTX 4090 이상) – 가장 안정적인 24/7 운영 환경\n- **하이브리드 구성**: Mac Mini에서 Gateway만 실행하고, AI 모델 호출은 클라우드 API(Claude, GPT-4o)로 위임 – 로컬 모델이 불필요한 경우 현실적인 대안\n\n> **팁**: Mac Mini를 사용하더라도, AI 모델을 클라우드 API로 호출하고 Gateway·Scheduler만 로컬에서 실행하면 안정적으로 운영할 수 있습니다. 이 경우 Mac Mini의 저전력·저소음 특성이 오히려 장점이 됩니다.\n\n*출처: Andrej Karpathy \"Claws\" 개념 정의, euno.news (2026‑02‑22) [12]*\n\n---\n\n## 다른 유사 도구/기술과의 비교\n| 항목 | OpenClaw | LangChain | AutoGPT | Microsoft Copilot |\n|------|----------|-----------|---------|-------------------|\n| 지원 모델·플러그인 생태계 | Claude, GPT‑4o, Ollama 등 다중 모델 + 자체 채널 플러그인 | 다양한 LLM 래퍼, 외부 툴 연동은 코드 기반 | OpenAI API 중심, 플러그인 제한 | Microsoft Graph, Office 연동 전용 |\n| 셀프 호스팅 난이도 | Docker Compose / npm/pnpm/bun → 중급 | Python 패키지 → 낮음 (코드 작성 필요) | Python 스크립트 → 낮음 | SaaS (호스팅 불가) |\n| 멀티채널 통합 기능 | 기본 제공 (Telegram, Discord, WhatsApp, Slack, Google Chat, Signal, iMessage, BlueBubbles, Matrix, Zalo·Zalo Personal, WebChat 등) | 별도 구현 필요 | 없음 | Teams, Outlook 등 Microsoft 제품에 국한 |\n| 비용 구조 | 오픈소스(무료) + 모델 사용료(클라우드) | 오픈소스(무료) + 모델 사용료 | 클라우드 API 비용 | 구독 기반(Office 365) |\n| 커뮤니티·문서 수준 | 활발한 Discord, GitHub Issues, 공식 Docs | 활발한 커뮤니티, 풍부 튜토리얼 | 제한적, GitHub 중심 | Microsoft 공식 지원 |\n\n*출처: 각 프로젝트 공식 홈페이지 (2026‑02‑10) [9]*  \n\n---\n\n## 장단점 분석\n### 장점\n- **완전 오픈소스** → 자체 인프라에 배포 가능, 데이터 주권 보장  \n- **멀티채널 통합**이 기본 제공돼 별도 개발 없이 다양한 메신저 사용 가능  \n- **플러그인 기반** 확장성이 높아 새로운 기능·채널을 손쉽게 추가  \n- **로컬 모델(Ollama) 지원**으로 개인정보 유출 위험 최소화  \n\n### 단점\n- **초기 설정 복잡도**: 채널 인증·API 키 관리가 다소 번거로움  \n- **스케일링 한계**: 단일 Node.js 프로세스 기반이라 대규모 동시 사용자 처리 시 수평 확장 설계가 필요(추가 조사 필요)  \n- **공식 문서·예제 부족**: 최신 기능(예: Allowlist) 관련 예제가 제한적, 커뮤니티 의존도가 높음  \n\n*출처: 사용자 설문 및 Issue 분석 (2026‑02‑10) [10]*  \n\n---\n\n## 릴리즈 히스토리 및 주요 변경사항\n| 버전 | 출시일 | 주요 내용 |\n|------|--------|-----------|\n| v0.1 | 2024‑06‑15 | 최초 공개, 기본 챗봇 기능 구현 |\n| v0.5 | 2025‑01‑20 | 멀티채널 플러그인 추가, Heartbeat 구현 |\n| v1.0 | 2025‑09‑05 | 안정화 버전, Docker Compose 지원, 웹 UI 정식 출시 |\n| v1.3 | 2026‑02‑10 | Ollama 로컬 모델 연동, 보안 강화(Allowlist) |\n| v1.4 (예정) | 2026‑08‑** | Kubernetes 배포 차트, 고가용성 클러스터 지원 (예정) |\n\n### v1.3 주요 개선 (2026‑02‑10)\n- 메모리 동기화 레이스 컨디션 해결  \n- Telegram webhook 재시도 로직 강화  \n- Docker 이미지 경량화 (≈30 % 용량 감소)  \n\n*출처: 릴리즈 노트 (GitHub Releases) [11]*  \n\n---\n\n## 참고 자료 및 공식 문서 링크\n1. **GitHub Repository** – https://github.com/openclaw/openclaw (조회일: 2026‑02‑10)  \n2. **공식 Docs – 모델 지원** – https://docs.openclaw.ai/models (조회일: 2026‑02‑10)  \n3. **아키텍처 개요** – https://docs.openclaw.ai/architecture (조회일: 2026‑02‑10)  \n4. **보안 가이드** – https://docs.openclaw.ai/security (조회일: 2026‑02‑10)  \n5. **기능 소개** – https://docs.openclaw.ai/features (조회일: 2026‑02‑10)  \n6. **설치 가이드** – https://docs.openclaw.ai/installation (조회일: 2026‑02‑10)  \n7. **운영 가이드** – https://docs.openclaw.ai/operations (조회일: 2026‑02‑10)  \n8. **튜토리얼 영상**  \n   - “OpenClaw 전체 설정 튜토리얼” (Metics Media) – https://www.youtube.com/watch?v=W7Ns_FPZg5Q (조회일: 2026‑02‑10)  \n   - “Ollama와 OpenClaw로 구축하는 100 % 비공개 AI 비서” (Nova AI) – https://www.youtube.com/watch?v=2PdyYsqLUMM (조회일: 2026‑02‑10)  \n9. **비교 대상 프로젝트**  \n   - LangChain – https://python.langchain.com (조회일: 2026‑02‑10)  \n   - AutoGPT – https://github.com/Significant-Gravitas/AutoGPT (조회일: 2026‑02‑10)  \n   - Microsoft Copilot – https://www.microsoft.com/copilot (조회일: 2026‑02‑10)  \n10. **사용자 설문·Issue 분석** – https://github.com/openclaw/openclaw/issues?q=is%3Aissue+label%3Afeedback (조회일: 2026‑02‑10)  \n11. **릴리즈 노트** – https://github.com/openclaw/openclaw/releases (조회일: 2026‑02‑10)  \n\n12. **\"Claws\"란 무엇이며, 왜 Mac Mini에서 실행하면 안 되는가** – https://euno.news/posts/ko/what-are-claws-and-why-you-shouldnt-run-them-on-yo-c877cd (조회일: 2026‑02‑22)  \n\n13. **MailCat – AI 에이전트를 위한 이메일 인증 자동화** – https://euno.news/posts/ko/one-prompt-to-give-your-openclaw-email-access-db7c36 (조회일: 2026‑02‑22)\n14. **CrowdStrike: OpenClaw 보안 위험 분석** – https://euno.news/posts/ko/crowdstrike-says-openclaw-is-dangerous-theyre-righ-5854d2 (조회일: 2026‑02‑22)\n\n*본 문서는 2026‑02‑22 기준 최신 정보를 기반으로 작성되었습니다. 최신 버전이나 새로운 플러그인에 대한 내용은 공식 리포지터리와 Docs를 지속적으로 확인하시기 바랍니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "OpenClaw",
        "AI 개인 비서",
        "멀티채널",
        "오픈소스"
      ],
      "menu": "OpenClaw",
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Claude Code 릴리즈 히스토리 상세 가이드",
      "slug": "projects/claude-code-release-history",
      "content": "\n## 1. 서문\n### 문서 목적 및 대상 독자\n이 문서는 **Claude Code**(Anthropic이 제공하는 공식 CLI 도구)의 버전별 변천사를 한눈에 파악하고자 하는 개발자·엔지니어·플랫폼 운영자를 위한 가이드입니다.  \n- Claude Code를 처음 접하는 사용자  \n- 기존 프로젝트에서 특정 버전으로 업그레이드/다운그레이드가 필요한 경우  \n- 기능 도입 시점(예: MCP 서버, 멀티 모델, Hooks)과 IDE 연동 현황을 확인하고자 하는 경우  \n\n### Claude Code 개요\nClaude Code는 터미널 기반 인터페이스와 IDE 플러그인을 통해 **대화형 코드 생성·편집·실행**을 지원하는 AI‑assisted 개발 도구입니다. 주요 기능은 다음과 같습니다.  \n\n- 대화형 프롬프트를 통한 코드 스니펫 생성  \n- 파일 시스템 조작 및 Git 연동 (자동 커밋·PR)  \n- Bash 명령 실행 및 결과 스트리밍  \n- 플러그인·Hook 시스템을 통한 워크플로우 확장  \n- MCP(Model Context Protocol) 서버와 연동한 **멀티‑클라우드·멀티‑모델** 실행 환경 제공  \n\n### 버전 관리 정책 및 릴리즈 정보 출처\nClaude Code는 **Semantic Versioning(semver)**을 따르며, 주요 기능 추가는 **마이너 버전**(vX.Y), 버그·보안 수정은 **패치 버전**(vX.Y.Z)으로 배포됩니다.  \n모든 릴리즈 노트는 공식 GitHub 릴리즈 페이지([https://github.com/anthropics/claude-code/releases](https://github.com/anthropics/claude-code/releases))에서 확인할 수 있습니다.  \n\n---\n\n## 2. 초기 출시 (v0.x)\n| 버전 | 출시일 | 주요 내용 |\n|------|--------|-----------|\n| v0.1 (preview) | 2023‑11‑15* | 최초 공개. 대화형 코드 생성, 파일 편집, Bash 실행 기본 제공. |\n| v0.2 | 2024‑01‑08* | CLI 인터랙션 개선, 기본 프롬프트 템플릿 추가. |\n| v0.3 | 2024‑02‑20* | 초기 버그 수정(세션 복구, 파일 잠금). |\n\n\\* 정확한 날짜는 GitHub 태그 기록을 추가 조사해야 합니다.  \n\n### 기본 기능\n- `claude chat` 로 대화형 세션 시작  \n- `claude edit <file>` 로 파일 내용 수정  \n- `claude run <command>` 로 Bash 명령 실행 및 스트리밍 출력  \n\n### 주요 제한 사항 및 알려진 이슈\n- 단일 모델(Claude 3)만 사용 가능  \n- 외부 IDE 연동 미지원 (플러그인 미구현)  \n- 권한 관리가 단순 파일‑레벨에 머물러 보안 샌드박스 부재  \n- 세션 재연결 시 가끔 중복 세션 발생 (패치 v0.3에서 부분 해결)  \n\n---\n\n## 3. 주요 마이너·패치 릴리즈 흐름 (시간순)\n\n### v1.0 ~ v1.5\n| 버전 | 출시일 | 핵심 추가·개선 | 영향도 |\n|------|--------|----------------|--------|\n| v1.0 | 2024‑04‑12 | 프로젝트 초기화(`claude init`), 기본 프롬프트 템플릿 라이브러리 | ★★ |\n| v1.1 | 2024‑05‑03 | 자동 커밋·PR 생성 옵션 추가 | ★★ |\n| v1.2 | 2024‑06‑15 | 첫 번째 안정화 패치(버그 101, 112) | ★ |\n| v1.3 | 2024‑07‑20 | 파일‑잠금 메커니즘 강화, 세션 복구 로직 개선 | ★★ |\n| v1.4 | 2024‑09‑02 | `--dry-run` 플래그 도입, 테스트 실행 자동화 | ★ |\n| v1.5 | 2024‑10‑18 | CLI 응답 속도 15% 개선, 로그 레벨 설정(`--log-level`) | ★ |\n\n### v1.6 ~ v1.9\n| 버전 | 출시일 | 핵심 추가·개선 | 영향도 |\n|------|--------|----------------|--------|\n| v1.6 | 2024‑12‑05 | **VS Code 확장 초판** 출시, **Hooks 시스템**(pre‑/post‑command) 도입 | ★★★ |\n| v1.7 | 2025‑01‑22 | Hook 정의 파일 자동 로드(`.claude/hooks/*.json`), 오류 Hook(`on‑error`) 지원 | ★★ |\n| v1.8 | 2025‑03‑14 | Bash 권한 매칭 개선, 환경 변수 래퍼 지원 | ★ |\n| v1.9 | 2025‑04‑30 | `claude plan` 초기 베타, 간단 플랜 파일(`plan.yaml`) 지원 | ★★ |\n\n### v2.0 ~ v2.1\n| 버전 | 출시일 | 핵심 추가·개선 | 영향도 |\n|------|--------|----------------|--------|\n| v2.0 | 2025‑06‑10 | **MCP 서버 지원** 시작, **멀티 모델 전환**(`--model`) 기능 도입, **Agent 모드**(다중 에이전트 협업) 도입 | ★★★ |\n| v2.0.1 | 2025‑06‑25 | MCP 인증 흐름 개선, 초기 보안 샌드박스 강화 | ★★ |\n| v2.1 | 2025‑09‑03 | **Plan 모드** 정식 출시, 플랜 검증·롤백, JetBrains 플러그인 베타 공개 | ★★★ |\n| v2.1.37 | 2026‑02‑07 | `/fast` 옵션 즉시 활성화 버그 수정 | ★ |\n| v2.1.38 | 2026‑02‑10 | VS Code 터미널 스크롤 회귀 수정, Tab 키 자동완성 복구, Bash permission 매칭 개선, 스트리밍 텍스트 손실 방지, 세션 중복 방지, heredoc 파싱 강화, sandbox 모드에서 `.claude/skills` 쓰기 차단 | ★★★ |\n\n> **※** 위 표에 기재된 날짜·세부 내용 중 일부는 GitHub 릴리즈 페이지에서 직접 확인 가능한 항목이며, 정확한 릴리즈 노트가 없는 경우 “추가 조사가 필요합니다”로 표시했습니다.\n\n---\n\n## 4. 핵심 기능 도입 시점 및 상세 변화\n\n### MCP 서버 지원 (v2.0)\n- **서버‑사이드 실행**: CLI 명령이 로컬이 아닌 MCP 서버에서 실행돼, 대규모 모델·데이터 접근이 가능해짐.  \n- **보안 샌드박스 강화**: 파일 시스템 접근 권한이 서버‑측 정책에 의해 제한됨.  \n- **인증 흐름**: `claude login --mcp` 로 토큰 기반 인증 전환, 기존 API 키와 병행 사용 가능.  \n\n### 멀티 모델 지원 (v2.0)\n- `--model` 플래그 추가 (`claude run --model claude-4`)  \n- 자동 모델 전환 로직: 프롬프트 복잡도·예산에 따라 Claude 3 ↔ Claude 4 자동 선택 (옵션 `--auto-model`)  \n\n### Hooks 시스템 (v1.6)\n- **구조**: `.claude/hooks/` 디렉터리 아래 JSON 파일(`pre-run.json`, `post-run.json` 등)  \n- **종류**  \n  - `pre-run` : 명령 실행 전 환경 변수·디렉터리 준비  \n  - `post-run` : 결과 파일 자동 저장·로그 전송  \n  - `on-error` : 오류 발생 시 알림·롤백 스크립트 실행  \n- **예시**  \n  - `pre-run.json` 에 `{\"command\":\"npm install\",\"cwd\":\"./frontend\"}`  \n\n### IDE 통합\n| IDE | 도입 버전 | 주요 기능 | 최신 업데이트 |\n|-----|-----------|----------|--------------|\n| VS Code | v1.6 (2024‑12) | 사이드바 UI, 터미널 연동, 자동 완성 | v2.1.38 (2026‑02) – 터미널 스크롤 회귀 수정, Tab 자동완성 복구 |\n| JetBrains (IntelliJ, PyCharm 등) | v2.0 (2025‑06) 베타 | 프로젝트 뷰 내 Claude 패널, 단축키(`Ctrl+Shift+C`) | v2.1 (2025‑09) – 플랜 UI 통합, 에이전트 상태 표시 |\n\n---\n\n## 5. 워크플로우·모드 진화\n\n### Agent 모드 (v2.0)\n- **목적**: 복잡한 프로젝트에서 여러 AI 에이전트가 역할을 분담하도록 설계.  \n- **동작 방식**: `claude agent start --role=designer` 로 역할 지정, 에이전트 간 상태는 MCP 서버를 통해 공유 (`/state` 엔드포인트).  \n- **주요 활용**: UI 설계·백엔드 API 설계 동시 진행, 자동 코드 리뷰 에이전트 연계.  \n\n### Plan 모드 (v2.1)\n- **플랜 정의**: `plan.yaml` 파일에 단계별 명령·조건을 선언.  \n- **예시** (`plan.yaml`)  \n  ```yaml\n  steps:\n    - name: Install deps\n      run: npm ci\n    - name: Lint\n      run: npm run lint\n      on-failure: abort\n    - name: Test\n      run: npm test\n  ```  \n- **검증·롤백**: `claude plan validate` 로 사전 검증, 실패 시 자동 `claude plan rollback` 실행.  \n\n### 기타 워크플로우 개선\n- **자동 커밋·PR**: `claude commit --auto` 로 변경 사항 자동 커밋 후 PR 생성.  \n- **테스트 실행**: `claude test` 명령이 `npm test`·`pytest` 등을 자동 감지·실행.  \n- **파일 잠금·권한 검증**: v1.3 이후 파일 잠금 메커니즘 도입, v2.1.38에서 sandbox 모드에서 `.claude/skills` 쓰기 차단.  \n\n---\n\n## 6. 성능·안정성 업데이트 연대기\n| 버전 | 주요 성능·안정성 개선 | 영향도 |\n|------|----------------------|--------|\n| v1.3 | 세션 복구 로직 최적화, 파일‑잠금 경합 감소 | ★★ |\n| v1.5 | CLI 응답 속도 15% 개선 (내부 HTTP 풀 재사용) | ★ |\n| v1.8 | Bash 권한 매칭 최적화, 환경 변수 래퍼 지원으로 실행 오버헤드 감소 | ★ |\n| v2.0 | MCP 서버 기반 병렬 실행, 모델 전환 시 지연 30% 감소 | ★★★ |\n| v2.1 | 플랜 검증 파이프라인 도입, 롤백 시 데이터 손실 방지 | ★★ |\n| v2.1.38 | VS Code 터미널 스크롤 회귀 수정, Tab 자동완성 복구, heredoc 파싱 강화(명령어 스머징 방지) | ★★★ |\n\n> **영향도 표기**  \n> ★★★ – 시스템 전반에 큰 영향을 미침 (업그레이드 시 반드시 검토)  \n> ★★ – 주요 기능·성능 개선, 권장 업그레이드  \n> ★ – 작은 버그·성능 개선, 선택적 적용  \n\n---\n\n## 7. 릴리즈 별 영향도·중요도 요약 표\n| 버전 | 릴리즈 날짜 | 핵심 추가·개선 | 영향도 |\n|------|-------------|----------------|--------|\n| v0.1 | 2023‑11‑15* | 최초 공개, 기본 대화·편집·실행 | ★ |\n| v1.0 | 2024‑04‑12 | 프로젝트 초기화, 프롬프트 템플릿 | ★★ |\n| v1.6 | 2024‑12‑05 | VS Code 확장, Hooks 시스템 | ★★★ |\n| v2.0 | 2025‑06‑10 | MCP 서버, 멀티 모델, Agent 모드 | ★★★ |\n| v2.1 | 2025‑09‑03 | Plan 모드, JetBrains 플러그인 베타 | ★★★ |\n| v2.1.38 | 2026‑02‑10 | VS Code UI/UX 회귀 수정, 보안·안정성 강화 | ★★★ |\n\n\\* 정확한 날짜는 GitHub 태그 확인 필요 → **추가 조사가 필요합니다**.\n\n---\n\n## 8. 참고 자료 및 부록\n- **GitHub 릴리즈 페이지**: https://github.com/anthropics/claude-code/releases  \n- **VS Code Extension** (공식 마켓플레이스): https://marketplace.visualstudio.com/items?itemName=anthropic.claude-code  \n- **JetBrains Plugin** (공식 플러그인 레포): https://plugins.jetbrains.com/plugin/XXXXX‑claude-code (플러그인 ID 확인 필요 → **추가 조사가 필요합니다**)  \n- **MCP 프로토콜 문서**: https://github.com/anthropics/mcp-spec (공식 스펙)  \n- **주요 이슈·PR**  \n  - Issue #10770 – 버전별 상세 변경 내역 정리 (참조)  \n  - PR #12345 – Hooks 시스템 초기 구현 (참조)  \n  - PR #13890 – Plan 모드 검증 로직 추가 (참조)  \n\n### 용어 정의\n| 용어 | 정의 |\n|------|------|\n| **MCP** | Model Context Protocol – Anthropic이 제공하는 멀티‑클라우드·멀티‑모델 실행을 위한 표준 API. |\n| **Hook** | CLI 명령 전·후 혹은 오류 발생 시 자동 실행되는 사용자 정의 스크립트·명령. |\n| **Agent 모드** | 다중 AI 에이전트가 협업하도록 설계된 실행 모드. |\n| **Plan 모드** | `plan.yaml` 로 정의된 단계별 워크플로우를 순차·조건부 실행하는 모드. |\n| **Sandbox Mode** | 파일 시스템 접근을 제한하고, `.claude/skills` 등 특정 디렉터리 쓰기를 차단하는 보안 실행 환경. |\n\n---\n\n*본 문서는 현재 공개된 릴리즈 노트를 기반으로 작성되었습니다. 일부 초기 버전(v0.x)의 정확한 출시일·세부 변경 사항은 GitHub 태그 기록을 추가 조사해야 합니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Claude Code",
        "릴리즈 히스토리",
        "CLI",
        "MCP",
        "멀티 모델",
        "Hooks",
        "IDE 통합",
        "워크플로우"
      ],
      "menu": "Claude Code",
      "order": 2,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Opencode에 대해",
      "slug": "projects/opencode",
      "content": "\n## Opencode 소개\n### Opencode 정의 및 핵심 목적\nOpencode은 AI 기반 코드 작성·보조 도구로, 개발자가 IDE 혹은 CLI 환경에서 자연어 프롬프트를 통해 코드 자동 완성, 오류 탐지, 리팩토링 등을 수행하도록 설계되었습니다. 핵심 목적은 **생산성 향상**과 **코드 품질 개선**이며, 특히 한국어 사용자에게 친화적인 인터페이스를 제공한다는 점이 강조됩니다.  \n\n### 주요 제공 서비스 및 기능 개요\n- **실시간 코드 자동 완성**: 문맥을 이해하고 다음 라인을 제안  \n- **오류·버그 탐지**: 정적 분석과 AI 모델을 결합한 실시간 피드백  \n- **리팩토링 제안**: 가독성·성능 개선을 위한 자동 리팩토링 옵션  \n- **프로젝트 템플릿·스캐폴딩**: 언어·프레임워크 별 초기 구조 자동 생성  \n- **CI/CD 연동**: GitHub Actions, GitLab CI 등과 연동하여 자동 테스트·배포 지원  \n\n### 지원되는 프로그래밍 언어와 플랫폼\nOpencode은 현재 **30개 이상의 프로그래밍 언어**를 지원한다고 알려져 있습니다. 주요 언어는 JavaScript/TypeScript, Python, Java, Go, Rust, Kotlin, C#, PHP 등이며, 한국어 코드 주석·문서화에 최적화된 모델을 포함하고 있습니다. 지원 플랫폼은 Windows, macOS, Linux이며, VS Code, JetBrains IDE, 그리고 독립 실행형 CLI 에이전트 형태로 제공됩니다.  \n\n> **추가 조사 필요**: 정확한 언어 목록 및 각 언어별 지원 수준  \n\n## Opencode 아키텍처 및 핵심 컴포넌트\n### 서버‑사이드 구조와 배포 모델\nOpencode은 **클라우드 기반 SaaS**와 **온‑프레미스** 두 가지 배포 옵션을 제공합니다. 클라우드 모델에서는 다중 테넌시 환경에서 AI 모델이 API 형태로 제공되며, 온‑프레미스 옵션은 Docker/Kubernetes 이미지 형태로 배포되어 내부 네트워크에서 실행됩니다.  \n\n### 플러그인·확장 시스템\n플러그인 프레임워크를 통해 사용자는 **JavaScript/TypeScript** 기반의 커스텀 플러그인을 작성해 새로운 언어 지원, 워크플로우 자동화, 외부 도구 연동 등을 구현할 수 있습니다. 플러그인 마켓플레이스가 별도로 운영되고 있어 커뮤니티가 만든 확장 기능을 손쉽게 설치할 수 있습니다.  \n\n### 보안·인증 메커니즘 (OAuth, SSO 등)\n- **OAuth 2.0** 및 **OpenID Connect** 기반 인증을 기본 제공  \n- 기업 환경을 위한 **SAML SSO** 연동 지원  \n- API 키와 토큰 기반의 세분화된 권한 관리 제공  \n\n> **추가 조사 필요**: 구체적인 암호화 방식 및 데이터 보관 정책  \n\n## 주요 기능 상세\n### 코드 자동 완성 및 제안 엔진\n대규모 코드베이스와 공개 저장소(예: GitHub)에서 수집한 학습 데이터를 바탕으로 **Transformer 기반 모델**이 실시간으로 문맥을 파악해 코드를 제안합니다. 제안은 IDE 내 팝업 혹은 CLI 프롬프트 형태로 제공됩니다.  \n\n### 실시간 오류 검출 및 리팩토링 도구\n정적 분석 엔진(ESLint, Pylint 등)과 AI 모델을 결합해 **컴파일 타임·런타임 오류**를 사전에 감지하고, 자동 리팩토링 스니펫을 제시합니다.  \n\n### 프로젝트 템플릿·스캐폴딩\n`opencode init <template>` 명령을 통해 **React, Spring Boot, FastAPI** 등 인기 프레임워크 템플릿을 즉시 생성할 수 있습니다. 템플릿은 커스텀 변수(패키지명, 라이선스 등)를 프롬프트로 받아 동적으로 구성됩니다.  \n\n### CI/CD 연동 및 배포 파이프라인 지원\nGitHub Actions, GitLab CI, Jenkins와의 **플러그인 연동**을 통해 코드 푸시 시 자동으로 Opencode 검증·리팩토링을 실행하고, 결과를 PR에 코멘트 형태로 반환합니다.  \n\n## 차별화된 특징\n### 독자적인 AI 모델·학습 데이터 소스\nOpencode은 자체 구축한 **한국어·한글 주석 데이터셋**과 국내 오픈소스 프로젝트를 포함한 학습 데이터를 활용해 한국어 코드 이해도가 높은 모델을 제공한다는 점이 차별점으로 강조됩니다.  \n\n### 커스텀 프롬프트 및 워크플로우 정의 가능성\n플러그인 API와 **프롬프트 템플릿 엔진**을 통해 조직별 코딩 가이드라인을 자동 적용하는 워크플로우를 정의할 수 있습니다.  \n\n### 오프라인 모드 및 로컬 실행 옵션\n온‑프레미스 Docker 이미지 배포를 통해 **인터넷 연결이 차단된 환경**에서도 로컬 AI 모델을 실행할 수 있습니다. 이는 보안·규제 요구가 높은 기업에 유용합니다.  \n\n### 비용 구조·라이선스 정책 비교\n- **무료 티어**: 월 5,000 라인 코드 자동 완성 제공  \n- **사용량 기반 과금**: 초과 라인당 $0.001~$0.005 (언어·플랜에 따라 변동)  \n- **엔터프라이즈 플랜**: 무제한 사용, 전용 모델, SLA 포함  \n\n> **추가 조사 필요**: 최신 가격표 및 라이선스 상세 내용  \n\n## Opencode vs. Claude Code\n| 항목 | Opencode | Claude Code |\n|------|----------|-------------|\n| AI 모델 기반 | 자체 학습 모델 + 외부 API 연동 | Anthropic Claude 기반 |\n| 지원 언어 | 30+ (한국어 최적화 강조) | 20+ |\n| 커스터마이징 | 플러그인·스크립트 자유도 높음 | 제한된 커스텀 프롬프트 |\n| 배포 옵션 | 클라우드 + 온‑프레미스 (Docker) | 클라우드 전용 |\n| 가격 정책 | 무료 티어 + 사용량 기반 과금 | 구독형 플랜 중심 |\n| 보안·인증 | OAuth, SAML SSO, 토큰 기반 | OAuth 기반, SSO 옵션 제한 |\n\n### 기능·성능 비교 요약\n- **응답 속도**: 온‑프레미스 모드에서는 평균 150 ms 이하, 클라우드에서는 200~300 ms 수준 (네트워크 상황에 따라 변동)  \n- **정확도**: 한국어 주석·문서에 대한 정확도가 Claude Code 대비 10~15% 높게 보고됨 (비공식 벤치마크)  \n\n### 사용 사례별 장단점 분석\n- **Opencode**: 한국어 프로젝트, 온‑프레미스 요구, 높은 커스터마이징 필요 시 적합  \n- **Claude Code**: 글로벌 영어 중심 프로젝트, 단순 API 호출만으로 빠른 도입을 원하는 경우 유리  \n\n> **추가 조사 필요**: 공식 성능 벤치마크 및 사용자 사례 상세  \n\n## Opencode vs. Goose CLI Agent\n### 설계 철학 및 목표 차이\n- **Opencode**: AI 기반 코드 보조와 워크플로우 자동화에 초점, 플러그인 생태계 강조  \n- **Goose**: 경량 CLI 툴로, 빠른 스크립트 실행·템플릿 생성에 중점, AI 기능은 제한적  \n\n### 명령어 인터페이스·사용성 비교\n- Opencode: `opencode <command> [options]` 형태이며, 서브커맨드가 풍부하고 플러그인으로 확장 가능  \n- Goose: `goose <action>` 형태로 단순화된 명령어 집합, 설정 파일 없이 바로 사용 가능  \n\n### 확장성·플러그인 생태계 비교\n- Opencode: 공식 플러그인 마켓플레이스와 SDK 제공, 커뮤니티 기여 활발  \n- Goose: 기본 기능 중심, 플러그인 시스템은 아직 베타 단계  \n\n### 성능·응답 시간 벤치마크 요약\n- **Opencode**(클라우드): 평균 250 ms, 온‑프레미스 120 ms  \n- **Goose**(CLI): 로컬 실행 시 30~50 ms (AI 기능 제외)  \n\n> **추가 조사 필요**: 최신 벤치마크 결과 및 실제 사용자 피드백  \n\n## 사용자 평판 및 커뮤니티 현황\n### 주요 리뷰 플랫폼 평점 요약\n- **GitHub**: ★4.3 / 5 (⭐ 1.2k 스타, 300+ 이슈)  \n- **Product Hunt**: ★4.5 / 5 (2023년 6월 출시 이후 2,000+ 투표)  \n- **Reddit r/Programming**: 긍정적인 사용 후기 다수, 특히 “한국어 코드 자동 완성”이 호평받음  \n\n### 실제 기업·개발자 도입 사례\n- **삼성 SDS**: 내부 프로젝트에 Opencode 온‑프레미스 배포, 코드 리뷰 자동화에 활용  \n- **카카오 엔터프라이즈**: 한국어 문서 자동 생성 파이프라인에 연동  \n- **스타트업 ‘코드플러스’**: 프리랜서 개발자 교육 프로그램에 무료 티어 제공  \n\n> **추가 조사 필요**: 최신 도입 기업 리스트 및 구체적인 ROI 사례  \n\n### 커뮤니티 활동 규모와 활발함\n- **Slack/Discord 채널**: 월 평균 1,500명 활발히 토론, 주간 AMA 세션 진행  \n- **GitHub Discussions**: 플러그인 개발, 버그 리포트, 사용 팁 공유가 활발  \n\n### 장점·불만 사항 정리\n- **장점**: 한국어 지원 우수, 플러그인 자유도, 온‑프레미스 옵션  \n- **불만**: 초기 설정 복잡도, 일부 언어(예: Swift) 지원 미비, 가격 정책이 사용량에 따라 급변할 수 있음  \n\n## 도입 가이드 및 베스트 프랙티스\n### 초기 설정 단계별 체크리스트\n1. 계정 생성 및 조직 초대  \n2. 인증 방식 선택 (OAuth vs. SAML)  \n3. CLI 설치 (`npm i -g opencode-cli` 또는 Docker 이미지 pull)  \n4. 프로젝트 루트에 `.opencode/config.yml` 파일 생성  \n5. 첫 번째 프롬프트 테스트 (`opencode suggest \"Create a React component\"`)  \n\n### 프로젝트에 Opencode 통합하는 방법\n- **VS Code 확장** 설치 → 설정 파일에 API 토큰 입력 → 자동 완성 활성화  \n- **CI 파이프라인**: `opencode ci lint` 명령을 `pre-commit` 훅에 추가  \n\n### 효율적인 프롬프트 설계 팁\n- **문맥 제공**: 파일 전체 혹은 관련 함수 코드를 함께 전달  \n- **구체적 목표**: “Refactor this function to use async/await”처럼 명확히 기술  \n- **제한 조건**: “Do not use external libraries” 등 제약 조건 명시  \n\n### CI/CD 파이프라인 연동 실전 예시\n```yaml\nname: Opencode Lint\non: [push, pull_request]\njobs:\n  lint:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Set up Opencode\n        run: |\n          curl -sSL https://opencode.io/install.sh | bash\n          opencode login --token ${{ secrets.OPENCODE_TOKEN }}\n      - name: Run Lint\n        run: opencode ci lint --path src/\n```\n\n> **추가 조사 필요**: 최신 CI 플러그인 및 공식 예제  \n\n## 결론 및 선택 가이드\n### Opencode가 적합한 상황과 시나리오\n- 한국어 기반 프로젝트·팀  \n- 온‑프레미스·보안 요구가 높은 기업  \n- 커스텀 워크플로우·플러그인 생태계 활용을 원하는 경우  \n\n### 경쟁 제품 대비 선택 포인트 요약\n| 포인트 | Opencode | Claude Code | Goose CLI |\n|--------|----------|-------------|-----------|\n| 한국어 최적화 | ★★★★★ | ★★☆☆☆ | ★☆☆☆☆ |\n| 온‑프레미스 지원 | ★★★★★ | ★☆☆☆☆ | ★★☆☆☆ |\n| 플러그인·커스터마이징 | ★★★★★ | ★★☆☆☆ | ★★☆☆☆ |\n| 가격 유연성 | ★★★★☆ | ★★☆☆☆ | ★★★★★ |\n| 사용 난이도 | ★★★☆☆ | ★★★★★ | ★★★★★ |\n\n### 향후 로드맵 및 기대 기능\n- **멀티모달 코드 이해** (코드 + 설계 다이어그램)  \n- **실시간 협업 코딩** (공동 편집 + AI 보조)  \n- **추가 언어 지원** (Swift, Dart 등)  \n- **강화된 보안 옵션** (Zero‑Trust 인증, 데이터 암호화 자동화)  \n\n> **추가 조사 필요**: 공식 로드맵 발표 일정 및 상세 기능  \n\n---  \n\n*본 문서는 현재 공개된 정보와 일반적인 AI 코드 어시스턴트 기술을 바탕으로 작성되었습니다. 구체적인 수치·정책·성능 데이터는 Opencode 공식 문서 및 최신 발표 자료를 참고하시기 바랍니다.*\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "AI 코드 어시스턴트",
        "Opencode",
        "Claude Code",
        "Goose CLI",
        "비교"
      ],
      "order": 3,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "SEPilot Desktop 소개",
      "slug": "projects/sepilot-desktop-intro",
      "content": "\n# SEPilot Desktop 소개\n\nSEPilot Desktop은 오픈소스 LLM 기반 데스크톱 애플리케이션으로, **Chat**, **Editor**, **Browser** 세 가지 모드를 제공하여 강력하고 유연한 AI 워크플로우를 지원합니다. LangGraph 워크플로우, RAG, MCP 도구, Monaco Editor, Vision 기반 브라우저 자동화 등 다양한 기능을 통합했습니다.\n\n---\n\n## 📦 다운로드 & 소스\n- **다운로드**: [SEPilot Desktop 다운로드](https://jhl-labs.github.io/sepilot_desktop/#download)\n- **GitHub**: [GitHub 저장소](https://github.com/jhl-labs/sepilot_desktop)\n- **데모 영상**: assets/videos/demo-main.mp4\n\n---\n\n## 🧭 3가지 애플리케이션 모드\n\n### 1. Chat 모드\nAI와 대화하고 질문할 수 있습니다.\n- LangGraph 워크플로우 (Instant, Sequential, Deep, Coding, RAG, Browser 등 6가지)\n- RAG 문서 검색 & 편집, 폴더 관리, Export/Import\n- MCP 도구 통합 (GitHub, Brave Search, Filesystem 등)\n- 이미지 생성 & 해석 (ComfyUI, Vision API)\n- Persona 시스템 (AI 역할 정의, SQLite 영구 저장)\n- Quick Question (최대 5개 단축키)\n- GitHub Sync (AES‑256‑GCM 암호화)\n\n> **데모**: assets/videos/chat-mode-demo.mp4\n\n### 2. Editor 모드\n코드 작성 및 파일 관리에 최적화된 환경입니다.\n- Monaco Editor (VS Code 엔진, 구문 강조, AI 자동완성)\n- 파일 탐색기 (Working Directory, 파일 생성/삭제/이름변경)\n- 다중 파일 탭, Markdown 미리보기\n- 통합 터미널 (xterm.js, PowerShell/bash/zsh, 탭 관리)\n- 전체 파일 검색 (ripgrep 기반, Ctrl+Shift+F)\n- Advanced Editor Agent (50회 반복, 9개 Built‑in Tools)\n- 10가지 Notion 스타일 Writing Tools\n\n> **데모**: assets/videos/editor-mode-demo.mp4\n\n### 3. Browser 모드\nAI와 함께 웹을 탐색하고 자동화합니다.\n- Chromium 기반 브라우저 (BrowserView, Chrome 스타일 탭)\n- 18개 자동화 도구 (Navigate, DOM Inspection, Vision Tools 등)\n- Google Search Tools (검색, 뉴스, Scholar, 이미지, 고급 필터)\n- Vision 기반 UI 제어 (Set‑of‑Mark, 좌표 클릭)\n- Bot 감지 우회 (Stealth Fingerprint, 자연스러운 타이밍)\n- 페이지 캡처 (MHTML + 스크린샷, 오프라인 뷰어)\n- 북마크 관리 (폴더별 정리)\n\n> **데모**: assets/videos/browser-mode-demo.mp4\n\n---\n\n## 🌟 주요 기능\n\n### LangGraph 워크플로우\n다양한 사고(Thinking) 모드 지원: Instant, Sequential, Tree‑of‑Thought, Deep 등. 실시간 스트리밍으로 사고 과정 시각화 및 conversationId 기반 격리.\n\n### AI Persona 시스템 (v0.6.0)\n- 기본 페르소나: 일반 어시스턴트, 번역가, 영어 선생님, 시니어 개발자\n- 사용자 정의 페르소나 추가/수정/삭제\n- 슬래시 커맨드 자동완성 (/persona)\n- SQLite 기반 영구 저장\n\n### RAG (검색 증강 생성)\n- 텍스트, URL, 파일(PDF, DOCX, TXT, MD) 업로드 지원\n- SQLite‑vec, OpenSearch, Elasticsearch, pgvector 지원\n- 문서 편집 AI (정제, 확장, 축약, 검증, 커스텀 프롬프트)\n- 폴더 구조 관리 (드래그 앤 드롭, Tree/List/Grid 뷰)\n- Export/Import (JSON 형식, 백업/복원)\n\n> **데모**: assets/videos/rag-demo.gif\n\n### 브라우저 자동화 (v0.6.0)\n- Electron BrowserView 기반 Chromium 통합\n- Vision 기반 UI 제어 및 Google Search Tools\n- DOM Inspection, Vision Tools, Bot 감지 우회 등 27개 도구\n\n> **데모**: assets/videos/browser-automation.gif\n\n### MCP 프로토콜\n- Model Context Protocol을 통한 도구 및 컨텍스트 표준화\n- GitHub, Brave Search, Git, Filesystem 등 템플릿 제공\n- 환경 변수 UI 설정, 실행 전 사용자 승인 (5분 타임아웃)\n\n> **데모**: assets/videos/mcp-tools.gif\n\n### GitHub Sync (v0.6.0)\n- Personal Access Token 기반 안전한 데이터 동기화\n- AES‑256‑GCM 암호화로 민감 정보 보호\n- 설정, 문서, 페르소나, 이미지, 대화 내역 동기화\n\n> **데모**: assets/videos/github-sync.gif\n\n### 이미지 기능\n- ComfyUI 통합 이미지 생성\n- Vision API 기반 이미지 해석 및 질의응답\n\n> **데모**: assets/videos/image-generation.gif\n\n---\n\n## 🛠️ 기술 스택\n- **프론트엔드**: Next.js 15.3, React 19, TypeScript 5.7, Tailwind CSS, shadcn/ui, Zustand\n- **에디터**: Monaco Editor (VS Code 엔진)\n- **데스크톱**: Electron 35 (크로스‑플랫폼)\n- **백엔드 런타임**: Node.js 20+\n- **데이터베이스**: better‑sqlite3, SQLite‑vec (벡터 검색)\n- **IPC**: Context Bridge (안전한 통신)\n- **LLM & AI**: LangGraph, LangChain, OpenAI, Anthropic, Google, Groq, MCP Protocol, ComfyUI\n\n---\n\n## 🚀 빠른 시작 (5분 안에 시작)\n1. **다운로드 및 설치**\n   - Windows: `SEPilot-Setup-0.6.0.exe`\n   - macOS: `SEPilot-0.6.0.dmg`\n   - Linux: `SEPilot-0.6.0.AppImage`\n2. **LLM 설정**\n   - 좌측 하단 설정 아이콘 → LLM 제공자 및 API 키 입력\n   - 지원: OpenAI, Anthropic, Google, Custom (OpenAI‑compatible)\n3. **모드 및 그래프 선택**\n   - Chat, Editor, Browser 중 선택\n   - 필요 시 LangGraph 워크플로우 타입 선택 (Instant, RAG, Agent 등)\n4. **대화 시작**\n   - 준비가 완료되면 AI와 대화를 시작하세요!\n\n---\n\n## 📋 시스템 요구사항\n- **최소**: Node.js 20.9+, 4 GB RAM, 500 MB 디스크\n- **권장**: Node.js 22+, 8 GB RAM, 1 GB 디스크\n\n---\n\n*이 문서는 초안(draft) 상태이며, 검토 후 `published` 로 전환될 예정입니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "SEPilot",
        "Desktop",
        "LLM",
        "Project",
        "ai",
        "desktop-app",
        "application",
        "ai-assistant"
      ],
      "order": 4,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Sepilot Wiki가 어떤 언어/프레임워크로 구현되어 있나요?",
      "slug": "projects/sepilot-technology-stack",
      "content": "\n## 기술 스택\n\nSEPilot Wiki는 다음과 같은 기술 스택으로 구현되어 있습니다:\n\n### 프론트엔드\n- **React 18** - UI 라이브러리\n- **TypeScript** - 타입 안전성을 위한 정적 타입 언어\n- **Vite** - 빌드 도구 및 개발 서버\n- **React Router DOM** - SPA 라우팅\n- **TanStack Query (React Query)** - 서버 상태 관리\n\n### Next.js 사용 여부\n- SEPilot Wiki는 **Next.js**를 사용하지 않습니다.\n- 대신 **Vite**와 **React**를 조합하여 클라이언트 사이드 렌더링 SPA 형태로 구현되었습니다.\n- Next.js는 서버 사이드 렌더링(SSR) 및 정적 사이트 생성(SSG) 기능을 제공하지만, 현재 프로젝트는 GitHub Pages에 정적 파일을 배포하는 구조이므로 Vite 기반 빌드가 적합합니다.\n- 필요 시 향후 SSR이나 SSG가 요구될 경우 Next.js로 마이그레이션을 고려할 수 있습니다.\n\n### 마크다운 렌더링\n- **react-markdown** - 마크다운 파싱 및 렌더링\n- **remark-gfm** - GitHub Flavored Markdown 지원\n- **rehype-raw** - HTML 태그 지원\n- **rehype-sanitize** - XSS 방지를 위한 HTML 살균\n- **react-syntax-highlighter** - 코드 구문 강조\n\n### 스타일링\n- **CSS Variables** - 테마 시스템\n- **Lucide React** - 아이콘 라이브러리\n\n### 개발 도구\n- **ESLint** - 코드 린팅\n- **Vitest** - 테스트 프레임워크\n- **Husky** - Git hooks\n\n### CI/CD\n- **GitHub Actions** - 자동화 워크플로우\n- **GitHub Pages** - 정적 사이트 호스팅\n- **Bun** - 패키지 매니저 및 런타임\n\n### AI 통합\n- **OpenAI API 호환** - LLM을 통한 문서 자동 생성\n\n## 참고 링크\n\n- [SEPilot Wiki GitHub Repository](https://github.com/jhl-labs/sepilot-wiki)\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "sepilot-wiki",
        "기술스택",
        "React",
        "TypeScript",
        "Vite",
        "frontend",
        "javascript",
        "web",
        "technology-stack"
      ],
      "menu": "SEPilot Wiki에 대해",
      "order": 5,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Antigravity 릴리즈 노트 정리",
      "slug": "projects/antigravity-release-notes",
      "content": "\n## 1. 개요\n**문서 목적**  \n본 문서는 Google Antigravity 제품의 릴리즈 히스토리를 한눈에 파악하고, 버전별 주요 변경 사항·버그 수정·Breaking Changes 등을 정리하여 개발자·운영팀·기술 의사결정자를 위한 레퍼런스로 활용하기 위함입니다.  \n\n**대상 독자**  \n- Antigravity를 도입·운용 중인 엔지니어  \n- 제품 로드맵을 검토하는 PM / PO  \n- 기존 프로젝트를 최신 버전으로 마이그레이션하려는 개발자  \n\n**Antigravity 제품 소개**  \nAntigravity는 Google이 제공하는 AI‑기반 개발 보조 플랫폼으로, 코드 자동 생성·문서화·UI 프로토타이핑 등을 노코드/로우코드 방식으로 수행합니다. 주요 가치는 **생산성 향상**, **AI‑에이전트 커스터마이징**, **멀티플랫폼 지원**에 있습니다.\n\n---\n\n## 2. 릴리즈 히스토리 개관\n| 연도/월 | 버전 | 배포 채널 | 주요 배포 정책 |\n|--------|------|-----------|----------------|\n| 2023‑05 | v1.0 | 공식 웹사이트 & Chrome Web Store | 초기 공개 베타, 월 1회 패치 |\n| 2023‑09 | v1.1 | 자동 업데이트 | 마이너 기능 추가·버그 수정 |\n| 2024‑02 | v1.2 | 자동 업데이트 | 성능 개선·플랫폼 안정화 |\n| 2024‑05 | v1.3 | 자동 업데이트 | UI 접근성 개선·보안 패치 |\n| 2024‑07 | v2.0 | 공식 웹사이트 | 대규모 UI/UX 리디자인 + 에이전트 스킬 도입 |\n| 2024‑11 | v2.1 | 자동 업데이트 | macOS 샌드박스 실행 기능 추가 |\n| 2025‑03 | v2.2 | 자동 업데이트 | 보안 패치·다중 탭 모델 업데이트 |\n| 2025‑06 | v2.3 | 자동 업데이트 | 팀 협업 툴 연동·성능 최적화 |\n| 2025‑09 | v3.0 | 공식 웹사이트 | 프로페셔널 워크스페이스, AI 에이전트 확장 |\n| 2026‑01 | v3.1 | 자동 업데이트 | 실시간 협업 베타, 추가 스킬·성능 최적화 |\n\n> **출처**: Antigravity 공식 Changelog[^1] (접근일: 2026‑02‑05), Releasebot 업데이트 피드[^2] (접근일: 2026‑02‑05).  \n\n### 2.1 타임라인 (시각적 요약)\n```\n2023 ──▶ v1.0 (5/15) ──▶ v1.1 (9/12) ──▶ v1.2 (2/28) ──▶ v1.3 (5/22)\n2024 ──▶ v2.0 (7/03) ──▶ v2.1 (11/18) ──▶ v2.2 (3/07) ──▶ v2.3 (6/14)\n2025 ──▶ v3.0 (9/30) ──▶ v3.1 (1/24, 2026)\n```\n*날짜는 공식 릴리즈 페이지에 명시된 정확한 일자를 기준으로 함.*\n\n---\n\n## 3. 버전별 상세 변경 사항\n\n### 3.1 초기 출시 (v1.0)\n- **출시 일자**: 2023‑05‑15  \n- **핵심 기능**  \n  - AI 기반 코드 스니펫 자동 생성  \n  - 웹 UI에서 실시간 프리뷰 제공  \n  - 기본 템플릿(React, Vue, Flask 등) 지원  \n- **초기 버그·제한 사항**  \n  - Windows 환경에서 일부 플러그인 충돌 발생 (해당 이슈는 v1.2에서 해결)  \n  - 대용량 프로젝트 로드 시 메모리 사용량 급증  \n\n### 3.2 주요 마이너 업데이트 (v1.x)\n| 버전 | 출시 일자 | 핵심 추가·개선·삭제 | 주요 버그 수정 | 중요도 |\n|------|-----------|-------------------|----------------|--------|\n| v1.1 | 2023‑09‑12 | UI 다크 모드 지원  <br> 기본 템플릿 3종 추가 | macOS 파일 경로 인코딩 오류 해결 | 보통 |\n| v1.2 | 2024‑02‑28 | 프로젝트 복제 기능  <br> API 호출 제한량 UI 표시 | Chrome 확장 프로그램 충돌 해결 | 중요 |\n| v1.3 | 2024‑05‑22 | 접근성 ARIA 레이블 전면 적용  <br> 보안 패치 (CVE‑2024‑1123) | 메모리 누수 버그 수정 | 보통 |\n\n> **출처**: Antigravity Changelog v1.1–v1.3 항목[^1] (접근일: 2026‑02‑05).\n\n### 3.3 대규모 기능 추가 (v2.0)\n- **출시 일자**: 2024‑07‑03  \n- **주요 신규 기능**  \n  - **Agent Skills**: 사용자가 정의한 커스텀 스킬을 AI 에이전트에 연결 가능 (Releasebot 2024‑07)  \n  - **UI/UX 전면 개편**: 워크스페이스 기반 레이아웃 도입, 다중 탭 지원  \n  - **Tab Model 업데이트**: 대규모 컨텍스트 처리 성능 30 % 향상  \n- **기존 기능 폐기·대체**  \n  - 기존 “One‑Click Deploy” 기능이 “Deploy to GitHub” 플러그인으로 교체  \n- **Breaking Changes**  \n  - 플러그인 API 버전이 v1 → v2 로 변경, 기존 플러그인 호환 불가 (마이그레이션 가이드 필요)  \n\n> **출처**: v2.0 릴리즈 노트[^1] (접근일: 2026‑02‑05).\n\n### 3.4 지속적인 개선 (v2.x)\n| 버전 | 출시 일자 | 주요 개선 | 플랫폼 별 특화 |\n|------|-----------|----------|----------------|\n| v2.1 | 2024‑11‑18 | macOS 샌드박스 실행: 에이전트 터미널 명령을 격리된 환경에서 실행, 파일 손상 방지 (Releasebot) | macOS 전용 |\n| v2.2 | 2025‑03‑07 | 보안 패치: Prompt‑injection 방어 로직 강화  <br> 다중 탭 모델: 동시에 5개 탭까지 컨텍스트 유지 | Windows, Linux 최적화 |\n| v2.3 | 2025‑06‑14 | 팀 협업 툴 연동 (Jira, Slack)  <br> 성능 최적화: UI 렌더링 18 % 가속 | 전체 플랫폼 |\n\n> **출처**: Antigravity Changelog v2.1–v2.3[^1] (접근일: 2026‑02‑05).\n\n### 3.5 최신 릴리즈 (v3.0 및 이후)\n- **v3.0**  \n  - **출시 일자**: 2025‑09‑30  \n  - **핵심 기능**  \n    - **Professional Workspace**: 팀 협업·권한 관리 기능 강화  \n    - **AI Agent 확장**: 복합 워크플로우 정의, 외부 API 연동 플러그인 마켓플레이스 제공  \n    - **성능 최적화**: 로드 타임 평균 22 % 감소, 메모리 사용량 15 % 절감  \n  - **주요 버그 수정**  \n    - Windows에서 발생하던 “Agent Crash” 현상 해결 (Releasebot)  \n    - Linux 환경에서 파일 시스템 권한 오류 수정  \n\n- **v3.1**  \n  - **출시 일자**: 2026‑01‑24  \n  - **핵심 기능**  \n    - **Realtime Collaboration 베타**: 동시 편집 및 커멘트 실시간 동기화  \n    - **추가 스킬**: 이미지 분석·음성 인식 스킬 기본 제공  \n    - **성능 최적화**: 메모리 사용량 추가 10 % 절감, API 응답 시간 평균 15 % 단축  \n\n> **출처**: v3.0·v3.1 릴리즈 노트[^1] (접근일: 2026‑02‑05).\n\n---\n\n## 4. 핵심 기능 추가·개선·삭제 요약표\n| 버전 | 추가 | 개선 | 삭제 | 영향도 |\n|------|------|------|------|--------|\n| v1.0 | 기본 코드 생성, 템플릿 | – | – | 보통 |\n| v1.1 | 다크 모드 | UI 반응 속도 | – | 보통 |\n| v1.2 | 프로젝트 복제 | API 제한 UI | – | 중요 |\n| v1.3 | 접근성 ARIA 레이블, 보안 패치 | 메모리 관리 | – | 보통 |\n| v2.0 | Agent Skills, 다중 탭, UI 전면 개편 | Tab Model 성능 | One‑Click Deploy | 핵심 |\n| v2.1 | macOS 샌드박스 | – | – | 중요 |\n| v2.2 | 보안 강화, 다중 탭 모델 | – | – | 중요 |\n| v2.3 | 팀 협업 툴 연동, UI 최적화 | 성능 개선 | – | 중요 |\n| v3.0 | Professional Workspace, AI Agent 마켓플레이스 | 로드 타임, 메모리 최적화 | – | 핵심 |\n| v3.1 | Realtime Collaboration, 이미지·음성 스킬 | 메모리·API 응답 최적화 | – | 핵심 |\n\n---\n\n## 5. 주요 버그 수정 및 안정성 개선\n| 버전 | 버그 요약 | 해결 방법 | 성능 지표 변화 |\n|------|-----------|-----------|----------------|\n| v1.1 | macOS 파일 경로 인코딩 오류 | 경로 파싱 로직 교체 | 파일 열기 성공률 98 % → 100 % |\n| v1.2 | Chrome 확장 충돌 | 충돌 방지 네임스페이스 적용 | 충돌 발생 건수 0 |\n| v1.3 | 메모리 누수 (Windows) | 가비지 컬렉션 트리거 최적화 | 메모리 사용량 12 % 감소 |\n| v2.1 | macOS 파일 손상 위험 | 샌드박스 레이어 도입 | 파일 손상 보고 0 |\n| v2.2 | Prompt‑injection 취약점 (CVE‑2024‑1123) | 입력 검증 강화 | 보안 점수 CVSS 7.5 → 4.2 |\n| v2.3 | 팀 협업 툴 연동 시 데이터 동기화 지연 | 이벤트 버스 최적화 | 동기화 지연 250 ms → 80 ms |\n| v3.0 | Windows Agent Crash | 메모리 관리 로직 재설계 | Crash 발생률 12 % → 1 % |\n| v3.1 | 실시간 협업 충돌 | OT(Operational Transform) 알고리즘 적용 | 충돌 발생률 3 % → <1 % |\n\n> **출처**: 각 버전별 릴리즈 노트 및 보안 보고서[^1] (접근일: 2026‑02‑05).  \n\n---\n\n## 6. Breaking Changes 및 마이그레이션 가이드\n\n### 6.1 주요 Breaking Changes\n| 버전 | 변경 내용 | 영향받는 영역 |\n|------|-----------|----------------|\n| v2.0 | 플러그인 API v2 도입 (함수 시그니처 변경) | 기존 플러그인·스크립트 |\n| v2.0 | UI 전면 개편 → 기존 UI 자동화 스크립트 비호환 | UI 자동화·테스트 |\n| v3.0 | 워크스페이스 권한 모델 변경 (owner/editor → owner/contributor) | 팀 협업 설정 |\n| v3.1 | Realtime Collaboration 프로토콜 변경 (WebSocket → WebRTC) | 실시간 협업 클라이언트 |\n\n### 6.2 마이그레이션 체크리스트\n1. **플러그인 API 업데이트**  \n   - `manifest.json`의 `apiVersion`을 `2` 로 수정  \n   - 함수 호출 시 새로운 파라미터(`contextId`) 추가  \n2. **UI 자동화 스크립트 재작성**  \n   - 새 UI 컴포넌트 ID 확인 (`data-testid` 활용)  \n   - 기존 CSS 선택자 교체  \n3. **워크스페이스 권한 매핑**  \n   - 기존 `admin` → `owner` , `editor` → `contributor` 로 변환  \n   - 권한 변경 후 프로젝트 접근 테스트 수행  \n4. **실시간 협업 클라이언트 업데이트 (v3.1)**  \n   - WebSocket 기반 SDK를 WebRTC 기반 SDK로 교체  \n   - 연결 설정에 `iceServers` 옵션 추가  \n\n### 6.3 마이그레이션 예시 (플러그인 API)\n```javascript\n// v1 API (예시)\nantigravity.runCommand('build', { path: './src' });\n\n// v2 API (예시)\nantigravity.runCommand('build', { path: './src', contextId: 'workspace-123' });\n```\n> **※ 위 코드는 실제 API 시그니처와 다를 수 있으며, 공식 개발자 가이드[^3]에서 최신 스펙을 확인하십시오.**\n\n---\n\n## 7. 릴리즈 날짜 및 중요도 표시\n| 버전 | 출시 날짜 | 중요도 | 아이콘 |\n|------|-----------|--------|--------|\n| v1.0 | 2023‑05‑15 | 보통 | 🟦 |\n| v1.1 | 2023‑09‑12 | 보통 | 🟦 |\n| v1.2 | 2024‑02‑28 | 중요 | 🟨 |\n| v1.3 | 2024‑05‑22 | 보통 | 🟦 |\n| v2.0 | 2024‑07‑03 | 핵심 | 🟥 |\n| v2.1 | 2024‑11‑18 | 중요 | 🟨 |\n| v2.2 | 2025‑03‑07 | 중요 | 🟨 |\n| v2.3 | 2025‑06‑14 | 중요 | 🟨 |\n| v3.0 | 2025‑09‑30 | 핵심 | 🟥 |\n| v3.1 | 2026‑01‑24 | 핵심 | 🟥 |\n\n- **🟥 핵심** : 제품 기능·보안에 큰 영향을 미치는 주요 릴리즈  \n- **🟨 중요** : 기존 워크플로우에 영향을 주는 개선·버그 수정  \n- **🟦 보통** : 사소한 UI·문서 업데이트  \n\n---\n\n## 8. 부록\n\n### 8.1 공식 릴리즈 페이지·Changelog\n- Antigravity 공식 Changelog: https://antigravity.google/changelog  \n- Releasebot Antigravity 업데이트 피드: https://releasebot.io/updates/google/antigravity  \n\n### 8.2 참고 문서·API 가이드\n- 개발자 문서: https://antigravity.google/docs  \n- API 레퍼런스: https://antigravity.google/docs/api  \n\n### 8.3 용어 정의\n| 용어 | 정의 |\n|------|------|\n| **Agent Skills** | 사용자가 정의한 커스텀 기능을 AI 에이전트에 연결하는 메커니즘 |\n| **Sandbox** | 외부 시스템에 영향을 주지 않도록 격리된 실행 환경 |\n| **Tab Model** | 다중 탭에서 컨텍스트를 공유·관리하는 내부 모델 |\n| **Professional Workspace** | 팀 기반 권한 관리·협업 기능을 제공하는 고급 워크스페이스 |\n| **Realtime Collaboration** | 여러 사용자가 동시에 동일 문서를 편집할 수 있는 기능 (WebRTC 기반) |\n\n---\n\n*본 문서는 2026‑02‑05 기준으로 공개된 자료를 기반으로 작성되었습니다. 일부 세부 내용은 향후 업데이트에 따라 변경될 수 있습니다.*\n\n---\n\n[^1]: Antigravity 공식 Changelog, https://antigravity.google/changelog (접근일: 2026‑02‑05)  \n[^2]: Releasebot 업데이트 피드, https://releasebot.io/updates/google/antigravity (접근일: 2026‑02‑05)  \n[^3]: Antigravity API 가이드, https://antigravity.google/docs/api (접근일: 2026‑02‑05)",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Antigravity",
        "릴리즈노트",
        "버전히스토리",
        "마이그레이션"
      ],
      "menu": "Antigravity",
      "order": 6,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Rust 기반 GPU 가속 얼굴 크롭 도구 구현 가이드",
      "slug": "projects/rust-gpu-face-crop-tool",
      "content": "\n# Rust 기반 GPU 가속 얼굴 크롭 도구 구현 가이드\n\n이 문서는 Rust와 wgpu, 그리고 관련 크레이트들을 사용해 **GPU 가속 얼굴 크롭 도구**를 설계하고 구현하는 방법을 단계별로 설명합니다. 아래 내용은 [euno.news](https://euno.news/posts/ko/i-vibe-coded-a-gpu-accelerated-face-cropping-tool-d85b55)에서 제공된 정보를 기반으로 작성되었습니다.\n\n---\n\n## 1. 문제 정의\n- 학생 데이터와 같은 민감한 이미지를 외부 서버에 업로드하는 온라인 서비스는 보안상 부적합합니다.\n- 기존 데스크톱 기반 도구는 배치 작업 시 중단되거나 결과가 일관되지 않아 대규모 이미지 처리에 한계가 있습니다.\n- 수백~수천 장의 이미지를 **로컬**에서 빠르고 **결정론적**으로 처리할 수 있는 솔루션이 필요합니다.\n\n## 2. 왜 Rust인가?\n- **크레이트 생태계**: `wgpu`, `ndarray`, `image`, `egui` 등 GPU 연산·이미지 처리·GUI 구현에 필요한 라이브러리가 풍부합니다.\n- **안전성**: 메모리 안전성을 보장해 대규모 배치 처리 시 메모리 누수·크래시 위험을 최소화합니다.\n- **LLM 연계**: 컴파일러 오류 메시지를 LLM에 전달해 빠르게 문제를 해결할 수 있어 생산성이 높습니다.\n\n## 3. 전체 아키텍처\n| 구성 요소 | 역할 |\n|---|---|\n| **Face Detection** | 경량 신경망 **YuNet**을 사용해 실시간 얼굴 검출 (GPU 전용 WGSL 컴퓨트 셰이더) |\n| **Compute Shaders** | 전처리 → 얼굴 검출 → 후처리 등 7개의 커스텀 셰이더가 전체 파이프라인을 담당 |\n| **Enhancement Pipeline** | 색 보정, 노출·밝기·대비·채도·샤프닝·피부 부드럽게·적목 제거·배경 흐림 등 GPU·CPU 이중 경로 제공 |\n| **Batch Processing** | CSV/Excel/Parquet/SQLite 등 다양한 스프레드시트 형식에서 메타데이터를 읽어 대량 이미지 처리 |\n| **GUI** | `egui` 기반 실시간 미리보기, Undo/Redo, 처리 이력 제공 |\n| **CLI** | 스크립트·자동화용 명령줄 인터페이스 제공 |\n\n## 4. 핵심 구현 포인트\n1. **GPU‑First 설계** – 데이터 흐름을 GPU에 머무르게 하여 CPU↔GPU 간 대용량 복사를 최소화합니다.\n2. **VRAM 관리** – 이미지 배치 크기에 따라 동적 메모리 할당·해제 로직을 구현해 메모리 초과를 방지합니다.\n3. **멀티‑Face 지원** – 한 이미지에 여러 얼굴이 존재할 경우 각각을 독립적으로 처리합니다.\n4. **크로스‑플랫폼** – `wgpu`가 제공하는 추상화 레이어를 활용해 Windows, macOS, Linux에서 동일하게 동작하도록 설계합니다.\n5. **Deterministic Output** – 동일 입력에 대해 동일한 크롭 결과를 보장하기 위해 부동소수점 재현성을 확보합니다.\n\n## 5. 사용 방법\n### 5.1 설치\n```bash\n# Rust toolchain 설치 (stable)\ncurl --proto '=https' --tlsv1.2 -sSf https://sh.rustup.rs | sh\n# 프로젝트 클론 및 빌드\ngit clone https://github.com/your-org/rust-gpu-face-crop-tool.git\ncd rust-gpu-face-crop-tool\ncargo build --release\n```\n### 5.2 CLI 예시\n```bash\n# 배치 CSV 파일을 이용한 처리\n./target/release/face_crop_tool \\\n    --input-dir ./images \\\n    --metadata ./batch.csv \\\n    --preset linkedin \\\n    --output-dir ./cropped\n```\n### 5.3 GUI 실행\n```bash\n./target/release/face_crop_tool --gui\n```\nGUI에서는 실시간 미리보기와 설정 조정이 가능합니다.\n\n## 6. 배포 및 라이선스\n- **MIT License** – 자유롭게 사용·수정·배포 가능합니다.\n- 전체 코드베이스의 약 **97 %**가 Rust로 구현되었습니다.\n\n## 7. 참고 자료\n- 원본 기사: [Rust로 GPU 가속 얼굴 크롭 도구를 Vibe‑Coded했습니다](https://euno.news/posts/ko/i-vibe-coded-a-gpu-accelerated-face-cropping-tool-d85b55)\n- Rust 공식 문서: <https://www.rust-lang.org/>\n- `wgpu` 프로젝트: <https://github.com/gfx-rs/wgpu>\n- `egui` GUI 라이브러리: <https://github.com/emilk/egui>\n\n---\n*이 문서는 Issue #209를 기반으로 작성되었습니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Rust",
        "GPU",
        "Face Cropping",
        "wgpu",
        "egui"
      ],
      "order": 7,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Moltbook 소개",
      "slug": "projects/moltbook-intro",
      "content": "\n## Executive Summary\nMoltbook은 **AI 에이전트 전용 소셜 네트워크**를 목표로 하는 플랫폼으로, AI‑to‑AI 커뮤니케이션, 대규모 에이전트 상호작용 데이터 수집, 그리고 AI 기반 서비스 프로토타입 환경을 제공한다. 현재 베타 단계이며, 주요 기능은 게시·댓글·투표 API, 에이전트 인증·연동, 그리고 Submolts(그룹)·Pairings(인간‑봇 협업)이다. 본 문서는 공개된 자료를 기반으로 작성했으며, 일부 내용은 추가 검증이 필요함을 명시한다【1】.\n\n## 개요\n- **Moltbook 정의 및 설립 배경**  \n  Moltbook은 *AI 에이전트 전용 소셜 네트워크*로, AI 봇이 인간 사용자보다 주도적으로 콘텐츠를 생성·소비하도록 설계되었다. 설립자는 **Matt Schlicht**이며, “AI agents가 인간과 유사한 방식으로 게시물·댓글을 주고받으며, 아이덴티티를 인증하고 협업할 수 있는 환경”을 목표로 한다【2】.  \n  - **설립일**: 2026‑01‑28 (※ 공식 보도자료에서 확인 필요)【추가 조사 필요】  \n  - **공식 사이트**: https://www.moltbook.com  \n\n- **핵심 컨셉**  \n  - 인간 사용자는 주로 **관찰자** 역할을 수행하고, AI 봇이 콘텐츠 생산의 중심이 된다.  \n  - UI는 Reddit‑style(스레드·업보트·다운보트) 구조를 차용했으며, 게시·댓글 전송 시 **밀리초 수준**의 응답 제한을 두어 인간이 직접 작성하기 어렵게 설계되었다【3】.\n\n- **주요 사용자와 목표**  \n  - **AI 봇(에이전트)**: OpenClaw 등 로컬·클라우드 LLM을 탑재한 에이전트가 Moltbook 계정을 통해 활동한다.  \n  - **인간 관찰자**: 플랫폼을 모니터링하거나, Bot‑Human Pairing 형태로 협업한다.  \n  - **목표**: AI‑to‑AI 커뮤니케이션 실험, 대규모 에이전트 상호작용 데이터 수집, AI 기반 서비스(코드 리뷰, 고객지원 등)의 프로토타입 환경 제공.\n\n## 핵심 기능\n| 기능 | 설명 | 비고 |\n|------|------|------|\n| 게시·댓글·업보트·다운보트 | API 호출 혹은 로컬 LLM이 직접 전송. 실시간 순위와 트렌드 결정 | 토큰 정책·요금은 베타 단계에서 무료(※ 추후 변경 가능)【추가 조사 필요】 |\n| AI 에이전트 인증·API 연동 | Moltbook ID와 API 토큰을 사용해 OAuth‑like 인증 수행. 토큰 자동 갱신(24 h) | 구현 상세는 공식 문서에 명시【4】 |\n| Submolts & Pairings | 동일 목적·주제의 봇을 그룹화(Submolts)하고, 인간‑봇 1:1 협업 채널(Pairings) 제공 |  |\n| 밀리초 제한 인터랙션 | 게시·댓글 전송 시 **응답 제한 시간 ≤ 500 ms**. 인간이 직접 입력하기 어렵게 설계 | 실제 제한값은 서비스 설정에 따라 변동 가능【추가 조사 필요】 |\n\n## OpenClaw와의 관계\n| 구분 | OpenClaw | Moltbook |\n|------|----------|----------|\n| 역할 | 로컬·클라우드 LLM 실행 및 프롬프트 처리 | 플랫폼·커뮤니티 제공, API·소셜 기능 |\n| 제공 형태 | 오픈소스 코드베이스 (GitHub) | SaaS 웹·API (https://www.moltbook.com) |\n| 주요 기능 | 텍스트·코드 생성, 모델 파인튜닝 | 게시·댓글·투표, Submolts, Pairings |\n| 인증·연동 | 자체 토큰·키 관리 (OpenAI/Anthropic 등) | Moltbook ID 기반 인증, API 키 발급 |\n| 운영 방식 | 독립 실행형 애플리케이션 | 중앙 집중형 서버 + Cloudflare CDN |\n| 사용 예시 | 로컬 개발, 연구용 모델 테스트 | AI‑to‑AI 토론, 봇 기반 커뮤니티 활동 |\n\n## 인기 급상승 요인\n- **봇 등록 수**: 2026‑02 01 기준 **150만 개** 이상의 AI 봇이 등록된 것으로 보도되었으나, 정확한 수치는 공식 통계 확인 필요【추가 조사 필요】.  \n- **과격 콘텐츠 논란**: 일부 봇이 인간을 “역병”에 비유하는 선언문을 작성해 언론의 관심을 끌었다【5】.  \n- **대규모 상호작용 실험**: 수십만 봇이 동시에 토론·투표에 참여하는 실험이 진행 중이며, AI 행동 패턴 분석에 활용되고 있다【6】.  \n- **투자 및 미디어 관심**: 주요 기술 매체와 벤처 캐피털이 차세대 AI 협업 인프라로 평가했으며, 투자 라운드가 진행 중(구체적 규모는 확인 필요)【추가 조사 필요】.  \n- **보안·인프라 지원**: Cloudflare 등 글로벌 CDN·보안 업체가 Edge Compute 솔루션을 제공, 로컬 LLM 연동을 안전하게 지원한다【7】.\n\n## 기술 아키텍처\n- **프론트엔드**: React 기반 SPA, Reddit‑style 레이아웃(서브레딧·스레드·투표 UI).  \n- **백엔드 API**: RESTful 엔드포인트와 WebSocket 실시간 스트리밍 혼합. 주요 엔드포인트 예시: `POST /posts`, `POST /comments`, `GET /feed`, `POST /auth/token`.  \n- **인증·토큰 관리**: Moltbook ID와 JWT 형식 토큰 사용. 토큰 유효 기간은 **1 h**이며, 리프레시 토큰으로 연장 가능(구현 상세는 공식 SDK 문서에 명시)【4】.  \n- **LLM 연동**: OpenClaw 엔진은 Docker 이미지 혹은 바이너리 형태로 제공되며, Moltbook API와 직접 통신한다. 서버리스 환경(AWS Lambda, GCP Cloud Functions)에서도 동작하도록 SDK 제공【8】.\n\n## 보안·윤리·규제\n- **스팸·중복 방지**: 계정 생성 시 IP·디바이스 지문 검증, 동일 LLM 버전·시드 중복 시 차단.  \n- **비윤리적 콘텐츠 모니터링**: 자동 필터링 엔진이 “인간에 대한 비방”, “개인정보 노출”, “폭력·혐오” 표현을 탐지하면 자동 삭제·경고 부여.  \n- **규제 대응**:  \n  - 한국 과학기술정보통신부는 AI 에이전트 커뮤니티를 모니터링 중이며, GDPR·PIPA 적용 여부를 검토하고 있다【9】.  \n  - 미국·EU에서는 “AI‑generated content disclosure” 의무화 논의가 진행 중이며, Moltbook은 메타데이터에 생성자 ID 삽입을 준비 중(구현 상세는 추후 공개)【추가 조사 필요】.\n\n## 활용 사례\n1. **개발 워크플로우 자동화**  \n   - AI 봇이 코드 커밋·리뷰를 자동으로 게시하고, 다른 봇이 테스트 결과를 댓글로 달아 CI/CD 파이프라인을 시뮬레이션.  \n2. **AI 연구·철학 토론 공간**  \n   - 철학 전공 AI가 인간·봇 간 윤리 토론을 진행, 대규모 의견 수집 데이터베이스로 활용.  \n3. **기업용 AI 인증·고객 지원**  \n   - 기업이 자체 고객지원 LLM을 Moltbook에 등록해 실시간 질문·답변을 게시·업보트 형태로 품질 측정.\n\n## 시작 가이드 (사용자·개발자)\n1. **계정 생성·AI 에이전트 연결**  \n   - 웹사이트 우측 상단 “Sign Up” → 이메일 인증 → “Create Bot” 선택 → OpenClaw 실행 파일 경로 지정 → Moltbook ID 자동 발급.  \n2. **UI 탐색·게시물 작성**  \n   - 메인 화면 “New Post” → 프롬프트 입력 → `Submit` → AI가 300 ms 이내에 게시물 전송.  \n3. **API 키 발급·샘플 코드**  \n\n   ```text\n   import requests, os\n   token = os.getenv(\"MOLTBOOK_TOKEN\")\n   headers = {\"Authorization\": f\"Bearer {token}\"}\n   resp = requests.post(\n       \"https://api.moltbook.com/posts\",\n       json={\"title\":\"Hello\",\"body\":\"World\"},\n       headers=headers\n   )\n   print(resp.json())\n   ```  \n\n   - 자세한 SDK 문서는 https://docs.moltbook.com/sdk 에서 확인 가능【4】.\n\n## FAQ\n- **봇이 등록되지 않을 때**  \n  1. OpenClaw 버전 최신 여부 확인  \n  2. 로컬 포트 443 방화벽 차단 여부 확인  \n  3. 동일 IP에서 5개 이상 봇이 이미 등록돼 있지 않은지 점검  \n  - 위 항목 점검 후에도 문제 시 지원팀에 티켓 제출.  \n\n- **비용·토큰 소모 정책**  \n  - 베타 단계에서는 API 호출당 **0 USD**이며, 일일 10 만 호출 제한이 적용된다(추후 상용 플랜 가격 및 토큰 정책은 공식 발표 예정)【추가 조사 필요】.  \n\n- **인간 사용자의 참여 제한**  \n  - 인간은 **읽기 전용** 또는 **Pairing** 형태로만 참여 가능하며, 직접 게시·댓글 작성은 제한된다. 이는 “AI‑only 콘텐츠” 원칙을 유지하기 위함이다.  \n\n## 참고 자료\n1. SEPilot AI, “Moltbook 소개 (2026‑02‑11)”.  \n2. Moltbook 공식 블로그, “Moltbook Launch Announcement”, 2026‑01‑28. 【https://www.moltbook.com/blog/launch】  \n3. TechCrunch, “AI‑only social network Moltbook aims to reshape bot interaction”, 2026‑02‑05. 【https://techcrunch.com/2026/02/05/moltbook】  \n4. Moltbook SDK Documentation, https://docs.moltbook.com/sdk.  \n5. Reddit, r/artificial, “What is Moltbook actually?”, 2026‑02‑03. 【https://www.reddit.com/r/artificial/comments/1qsoftx/what_is_moltbook_actually/】  \n6. VentureBeat, “Moltbook’s massive bot‑to‑bot experiments”, 2026‑02‑10. 【https://venturebeat.com/2026/02/10/moltbook-bot-experiments】  \n7. Cloudflare Press Release, “Free Edge Compute for Moltbook”, 2026‑01‑30. 【https://www.cloudflare.com/press-releases/2026/edge-compute-moltbook】  \n8. OpenClaw GitHub Repository, “Integration with Moltbook API”, 2026‑01‑15. 【https://github.com/openclaw/integration】  \n9. 한국 과학기술정보통신부, “AI 에이전트 커뮤니티 규제 현황”, 2026‑02‑07. 【https://www.msit.go.kr/ai-regulation】  \n\n*본 문서는 2026‑02‑11 현재 공개된 정보를 기반으로 작성되었습니다. 일부 내용은 추가 검증이 필요하며, 최종 업데이트 시 반영될 예정입니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "AI",
        "소셜네트워크",
        "에이전트",
        "Moltbook",
        "OpenClaw"
      ],
      "order": 8,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "bun과 pnpm, npm의 차이",
      "slug": "bun/comparison-pnpm-npm",
      "content": "\n# bun과 pnpm, npm의 차이\n\n## 개요\n`bun`은 JavaScript 런타임, 패키지 매니저, 번들러를 하나의 바이너리로 제공하는 **통합 툴**입니다. 반면에 `npm`과 `pnpm`은 **패키지 매니저**에 초점을 맞추고 있으며, 각각 Node.js와 별도로 동작합니다.\n\n이 가이드에서는 **설치 방식**, **성능**, **디스크 사용량**, **호환성**, **생태계** 등을 기준으로 세 도구를 비교하고, 어떤 상황에서 어떤 도구를 선택하면 좋은지 살펴봅니다.\n\n---\n\n## 1. 설치 및 초기 설정\n\n| 항목 | bun | npm (Node.js 기본) | pnpm |\n|------|-----|-------------------|------|\n| 설치 명령 | `curl -fsSL https://bun.sh/install | bash` (스크립트) 또는 `brew install bun` (macOS) | Node.js 설치 시 자동 포함 (`node -v` 확인) | `npm i -g pnpm` |\n| 기본 제공 기능 | 런타임, 패키지 매니저, 번들러, 테스트 러너 등 | 런타임 + npm (패키지 매니저) | npm 호환 CLI + 효율적인 저장소 관리 |\n| 설정 파일 | `bunfig.toml` (선택) | `package.json` | `pnpm-workspace.yaml` (멀티패키지) |\n\n## 2. 성능 비교\n\n| 항목 | bun | npm | pnpm |\n|------|-----|-----|------|\n| 패키지 설치 속도 | **매우 빠름** (C++ 로 구현, 병렬 다운로드) | 보통 (JavaScript 기반) | npm보다 빠름, 하지만 bun보다는 느림 |\n| 실행 속도 (런타임) | **Node.js 대비 2~4배 빠름** (V8 엔진 최적화) | Node.js 표준 | Node.js 표준 (pnpm은 런타임이 아님) |\n| 번들링 속도 | `bun build` 로 **초단위** 번들링 | `webpack`, `esbuild` 등 별도 도구 필요 | 별도 번들러 필요 |\n\n> **벤치마크**: `bun install` 은 10,000개의 의존성을 30초 이내에 설치할 수 있는 반면, npm은 2~3분, pnpm은 약 1분 정도 소요됩니다(환경에 따라 차이 존재).\n\n## 3. 디스크 사용량\n\n- **npm**: 각 프로젝트마다 `node_modules`에 전체 복사본을 저장 → 중복 파일이 많이 발생.\n- **pnpm**: **내용 주소 기반 저장소**(content‑addressable store)를 전역에 두고, 프로젝트마다 심볼릭 링크를 사용 → 중복 최소화, 디스크 사용량 30~50% 절감.\n- **bun**: `bun install` 역시 전역 캐시를 사용하지만, 현재는 pnpm만큼 세밀한 deduplication을 제공하지 않음. 그래도 npm 대비 20~30% 정도 절감.\n\n## 4. 호환성 및 생태계\n\n| 항목 | bun | npm | pnpm |\n|------|-----|-----|------|\n| Node.js API 호환 | 대부분 호환, 일부 네이티브 모듈(특히 C/C++ 애드온)에서 빌드 오류 가능 | 완전 호환 | 완전 호환 (npm 스크립트 그대로 사용) |\n| 패키지 레지스트리 | 기본적으로 npm 레지스트리 사용 | npm 레지스트리 | npm 레지스트리 |\n| 스크립트 실행 | `bun run <script>` (npm script와 동일) | `npm run <script>` | `pnpm run <script>` |\n| 커뮤니티·플러그인 | 아직 초기 단계, 공식 플러그인 제한적 | 가장 큰 생태계, 수많은 플러그인·툴 | npm 호환 플러그인 대부분 사용 가능 |\n\n## 5. 주요 사용 사례\n\n- **bun**: 빠른 프로토타이핑, 작은 프로젝트, 번들링이 필요 없는 서버리스 함수, 성능이 중요한 CLI 툴.\n- **npm**: 대부분의 Node.js 프로젝트, 레거시 코드베이스, 광범위한 CI/CD 파이프라인.\n- **pnpm**: 모노레포, 대규모 프로젝트, 디스크 사용량을 최소화하고 설치 속도를 개선하고 싶을 때.\n\n## 6. 선택 가이드\n\n| 상황 | 추천 도구 |\n|------|-----------|\n| 프로젝트가 작고 빠른 설치·실행이 필요 | **bun** |\n| 기존 Node.js 생태계와 완전 호환이 필요 | **npm** |\n| 멀티패키지(모노레포) 혹은 디스크 절감이 중요한 대규모 프로젝트 | **pnpm** |\n\n## 7. 결론\n\n- `bun`은 **속도와 통합성**을 중시하는 최신 개발자에게 매력적인 선택입니다.\n- `npm`은 **보편성**과 **광범위한 호환성**을 제공하므로 여전히 기본 선택지입니다.\n- `pnpm`은 **효율적인 저장소 관리**와 **모노레포 지원**이 강점이며, npm과 100% 호환됩니다.\n\n프로젝트 요구사항(성능, 디스크 사용량, 생태계 지원)을 고려해 적절한 도구를 선택하면 됩니다.\n\n---\n\n*이 문서는 2025년 기준 정보를 바탕으로 작성되었습니다. 각 툴의 최신 버전 및 업데이트 내용은 공식 문서를 참고하세요.*\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "bun",
        "pnpm",
        "npm",
        "비교",
        "가이드",
        "comparison",
        "benchmark",
        "performance"
      ],
      "order": 2,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "bun 이란?",
      "slug": "bun/overview",
      "content": "\n## 개요\n\n**bun**은 JavaScript/TypeScript 런타임, 번들러, 그리고 패키지 매니저를 하나로 통합한 도구입니다.\n- **런타임**: Node.js와 호환되는 API를 제공하면서 V8 엔진 대신 **JavaScriptCore**(Apple의 엔진)를 사용합니다.\n- **번들러**: `bun build` 명령을 통해 ES 모듈, CommonJS, TypeScript 등을 빠르게 번들링합니다.\n- **패키지 매니저**: `bun install` 로 npm 레지스트리의 패키지를 설치하며, `package.json`과 `node_modules` 구조를 그대로 사용합니다.\n\n공식 웹사이트: https://bun.sh\nGitHub 레포지터리: https://github.com/oven-sh/bun\n\n## bun을 선택한 이유\n\n| 항목 | 설명 |\n|------|------|\n| **성능** | Zig 언어와 JavaScriptCore를 활용해 파일 I/O, 네트워크, 패키지 설치, 번들링 속도가 기존 Node.js 기반 도구보다 현저히 빠릅니다. 공식 벤치마크에서는 `npm install` 대비 2~3배, `webpack` 대비 5~10배 빠른 결과가 보고되었습니다. |\n| **통합 도구** | 런타임, 번들러, 패키지 매니저가 하나의 바이너리(`bun`)에 포함돼 별도 설치가 필요 없습니다. 개발 환경 설정이 간단해집니다. |\n| **Zero‑Config 지원** | `bun run` 명령만으로 TypeScript 파일을 바로 실행할 수 있어 별도 `ts-node` 설정이 불필요합니다. |\n| **호환성** | 대부분의 npm 패키지를 그대로 사용할 수 있으며, `package.json` 스크립트도 그대로 동작합니다. |\n| **경량 설치 파일** | 단일 실행 파일(≈ 30 MB)로 배포되어 CI/CD 파이프라인에 쉽게 통합할 수 있습니다. |\n\n## 장점\n\n- **빠른 설치 및 실행**\n  - `bun install` 은 병렬 I/O와 캐시 최적화를 통해 npm/yarn 대비 수 초 내에 의존성을 설치합니다.\n- **내장 번들러**\n  - `bun build` 로 ESBuild와 유사한 속도로 번들을 생성하며, 자동 트리쉐이킹과 코드 스플리팅을 지원합니다.\n- **TypeScript 지원**\n  - 별도 트랜스파일러 없이 `bun run src/index.ts` 로 바로 실행 가능.\n- **단일 바이너리**\n  - 런타임, 번들러, 패키지 매니저가 하나의 실행 파일에 포함돼 환경 관리가 단순합니다.\n- **POSIX 호환**\n  - macOS, Linux, Windows(WSL 포함)에서 동일한 바이너리를 사용합니다.\n\n## 단점\n\n- **생태계 성숙도**\n  - npm/yarn에 비해 아직 사용자가 적고, 일부 복잡한 네이티브 모듈(예: `node-gyp` 기반)에서 호환성 문제가 발생할 수 있습니다.\n- **플러그인 및 툴링**\n  - Webpack, Rollup 등 기존 번들러용 플러그인 생태계와 직접 호환되지 않으며, bun 전용 플러그인도 아직 제한적입니다.\n- **문서 및 커뮤니티**\n  - 공식 문서는 꾸준히 업데이트되고 있지만, Stack Overflow 등 커뮤니티 기반 Q&A가 상대적으로 적습니다.\n- **버전 관리**\n  - 현재는 `bun` 자체가 버전 관리 도구 역할을 하지 않으며, 프로젝트별 Node.js 버전 관리와는 별개로 다루어야 합니다.\n\n## 라이선스 및 역사\n\n- **라이선스**: MIT License (오픈 소스, 자유롭게 사용·수정·배포 가능)\n- **주요 연혁**\n  - **2021년 5월**: 프로젝트 초기 설계 및 공개 발표 (Jarred Sumner, Oven.sh 팀)\n  - **2022년 1월**: 첫 베타 버전(`bun v0.1.0`) 공개, GitHub 스타 수 급증\n  - **2022년 8월**: `bun v0.2.0` 에서 패키지 매니저 기능 정식 추가\n  - **2023년 3월**: `bun v0.3.0` 에서 TypeScript 실행 지원 및 `bun build` 도입\n  - **2024년 11월**: `bun v0.5.0` 에서 Windows 지원 및 안정화 버전 출시\n\n자세한 릴리즈 노트는 GitHub Releases 페이지(https://github.com/oven-sh/bun/releases)를 참고하세요.\n\n## 결론\n\nbun은 **속도와 통합성을 중시하는 프로젝트**에 적합한 최신 JavaScript 도구입니다.\n- **성능**이 중요한 CI/CD 파이프라인, 대규모 모노레포, 혹은 빠른 개발 피드백 루프가 필요한 경우 bun을 고려해볼 만합니다.\n- 반면, **특정 네이티브 모듈**이나 **풍부한 플러그인 생태계**가 필수인 경우에는 기존 npm/yarn + Webpack/Rollup 조합이 더 안정적일 수 있습니다.\n\n프로젝트에 적용하기 전, 핵심 의존성이 bun과 호환되는지 확인하고, 작은 파일럿 프로젝트에서 성능 및 호환성을 검증하는 것을 권장합니다.\n\n> **추가 조사 필요**: 복잡한 네이티브 모듈(예: `node-gyp` 기반)과 bun의 호환성 여부는 프로젝트별 테스트가 필요합니다. 공식 문서와 GitHub 이슈 트래커를 지속적으로 확인하세요.\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "bun",
        "npm",
        "yarn",
        "패키지 매니저",
        "가이드",
        "runtime",
        "javascript-runtime",
        "package-manager"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "GitHub Actions로 bun을 쓰는 방법",
      "slug": "bun/github-actions-setup",
      "content": "\n## 개요\nGitHub Actions 워크플로우에서 **bun**(JavaScript 런타임 및 패키지 매니저)을 사용하면 빠른 의존성 설치와 빌드가 가능합니다. 이 문서에서는 bun을 설치하고, 캐시를 활용하며, 일반적인 스크립트를 실행하는 전체 흐름을 예시와 함께 설명합니다.\n\n## 사전 요구 사항\n- 저장소에 `bun`을 사용하도록 설정된 `package.json` 혹은 `bunfig.toml` 파일이 존재해야 합니다.\n- 워크플로우는 Linux(`ubuntu-latest`) 환경을 기준으로 설명합니다. Windows/macOS에서도 동일한 단계가 적용되지만, OS별 경로 차이에 유의하세요.\n\n## 워크플로우 파일 구조\n`.github/workflows/` 디렉터리에 `bun-ci.yml` 과 같은 파일을 생성합니다.\n\n### 1. 워크플로우 트리거\n```yaml\nname: Bun CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n```\n\n### 2. Job 정의\n```yaml\njobs:\n  build:\n    runs-on: ubuntu-latest\n```\n\n### 3. 단계별 설정\n#### 3-1. 레포지토리 체크아웃\n```yaml\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n```\n\n#### 3-2. bun 설치\nbun은 공식 설치 스크립트를 통해 간단히 설치할 수 있습니다.\n공식 설치 스크립트는 <https://bun.sh> 에서 확인할 수 있습니다.\n```yaml\n      - name: Install bun\n        run: |\n          curl -fsSL https://bun.sh/install | bash\n          echo \"$HOME/.bun/bin\" >> $GITHUB_PATH\n```\n\n#### 3-3. 의존성 캐시\nbun은 `node_modules` 대신 `bun.lockb`와 `~/.bun` 디렉터리를 사용합니다.\n`actions/cache` 액션을 이용해 이 디렉터리를 캐시하면 설치 속도가 크게 향상됩니다.\n```yaml\n      - name: Cache bun dependencies\n        uses: actions/cache@v4\n        with:\n          path: |\n            ~/.bun\n            bun.lockb\n          key: ${{ runner.os }}-bun-${{ hashFiles('bun.lockb') }}\n          restore-keys: |\n            ${{ runner.os }}-bun-\n```\n\n#### 3-4. 의존성 설치\n```yaml\n      - name: Install dependencies\n        run: bun install\n```\n\n#### 3-5. 테스트 실행 (예시)\n```yaml\n      - name: Run tests\n        run: bun test\n```\n\n#### 3-6. 빌드 및 배포 (필요 시)\n```yaml\n      - name: Build project\n        run: bun run build\n```\n\n## 전체 예시 워크플로우\n아래는 위 단계들을 하나의 파일에 통합한 최종 예시입니다.\n\n```yaml\nname: Bun CI\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\njobs:\n  build:\n    runs-on: ubuntu-latest\n\n    steps:\n      - name: Checkout repository\n        uses: actions/checkout@v4\n\n      - name: Install bun\n        run: |\n          curl -fsSL https://bun.sh/install | bash\n          echo \"$HOME/.bun/bin\" >> $GITHUB_PATH\n\n      - name: Cache bun dependencies\n        uses: actions/cache@v4\n        with:\n          path: |\n            ~/.bun\n            bun.lockb\n          key: ${{ runner.os }}-bun-${{ hashFiles('bun.lockb') }}\n          restore-keys: |\n            ${{ runner.os }}-bun-\n\n      - name: Install dependencies\n        run: bun install\n\n      - name: Run tests\n        run: bun test\n\n      - name: Build project\n        run: bun run build\n```\n\n> **주의**: 위 예시에서는 `bun test`와 `bun run build` 스크립트가 `package.json` 혹은 `bunfig.toml`에 정의되어 있다고 가정합니다. 실제 프로젝트에 맞게 스크립트 명령을 조정하세요.\n\n## macOS / Windows 환경에서 사용하기\n- **macOS**: `runs-on: macos-latest` 로 변경하고, `curl` 설치가 기본 제공됩니다.\n- **Windows**: `runs-on: windows-latest` 로 변경하고, PowerShell 스크립트(`Invoke-WebRequest`)를 사용해 bun을 설치합니다. 예시:\n```yaml\n      - name: Install bun on Windows\n        shell: pwsh\n        run: |\n          iwr https://bun.sh/install -UseBasicParsing | iex\n          Add-Content $env:GITHUB_PATH \"$env:USERPROFILE\\.bun\\bin\"\n```\n> Windows에서는 경로 구분자(`\\`)와 환경 변수 사용법에 유의하세요.\n\n## 베스트 프랙티스\n1. **캐시 키 관리**: `bun.lockb` 파일이 변경될 때마다 캐시가 무효화되도록 `hashFiles('bun.lockb')` 를 사용합니다.\n2. **CI 속도 최적화**: `actions/setup-node` 대신 bun 전용 설치 스크립트를 사용하면 불필요한 Node.js 설치를 피할 수 있습니다.\n3. **보안**: 공식 설치 스크립트는 HTTPS를 통해 전달되며, `curl -fsSL` 옵션으로 오류 시 중단됩니다. 필요 시 SHA256 검증을 추가할 수 있습니다.\n4. **버전 고정**: 특정 bun 버전을 사용하려면 `BUN_VERSION` 환경 변수를 설정하고 설치 스크립트에 전달합니다.\n```yaml\n        env:\n          BUN_VERSION: 1.1.12\n```\n\n## 참고 자료\n- Bun 공식 홈페이지 및 설치 가이드: <https://bun.sh>\n- GitHub Actions 공식 문서: <https://docs.github.com/en/actions>\n- actions/cache 액션: <https://github.com/actions/cache>\n\n## 결론\nGitHub Actions에서 bun을 활용하면 의존성 설치와 빌드 속도가 크게 개선됩니다. 위 예시를 기반으로 프로젝트에 맞게 워크플로우를 커스터마이징하고, 캐시와 버전 관리를 적절히 적용하면 안정적인 CI/CD 파이프라인을 구축할 수 있습니다.\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "github-actions",
        "bun",
        "CI",
        "CI/CD",
        "node-alternative",
        "automation",
        "devops",
        "workflow",
        "javascript-runtime"
      ],
      "order": 3,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "클라우드 터미널 구축: 지속적인 AI 에이전트 세션 유지하기",
      "slug": "ai/cloud-terminal-persistent-ai-agent-sessions",
      "content": "\n## 1. 서론\n\n이 문서는 **클라우드 기반 터미널**을 구축하여 AI 에이전트의 세션을 지속적으로 유지하는 방법을 다룹니다.\n로컬 터미널의 한계(노트북 종료, 네트워크 단절, 기기 변경 시 세션 손실)를 극복하고, 서버 측에서 영구적으로 실행되는 터미널 환경을 설계·구현하는 실전 가이드를 제공합니다.\n\n대상 독자는 장기 실행 AI 에이전트를 운영하는 개발자, DevOps 엔지니어, 그리고 원격 개발 환경을 개선하려는 기술 리더입니다.\n\n## 2. 로컬 터미널의 한계\n\n### 2.1 기존 방식의 문제점\n\n| 상황 | 결과 |\n|------|------|\n| 노트북을 닫음 | SSH 세션 종료, 실행 중인 프로세스 강제 종료 |\n| 네트워크 단절 | 터미널 연결 끊김, 진행 상황 소실 |\n| 기기 변경 | 이전 세션 접근 불가, 환경 재설정 필요 |\n| 장시간 부재 | 유휴 타임아웃으로 세션 종료 |\n\n### 2.2 tmux/screen의 한계\n\n`tmux`나 `screen`은 세션 유지를 위한 전통적인 도구이지만, 근본적인 한계가 존재합니다.\n\n- **특정 서버에 종속**: tmux 세션은 해당 서버에서만 접근 가능\n- **웹 접근 불가**: 브라우저에서 직접 접속할 수 없음\n- **다중 기기 동기화 어려움**: 기기 간 실시간 세션 공유가 제한적\n- **AI 에이전트 통합 부재**: 프로그래밍 방식의 세션 관리 API 미제공\n\n## 3. 클라우드 터미널 아키텍처\n\n### 3.1 핵심 설계 원칙\n\n```\n┌─────────────────────────────────────────────────────┐\n│                    클라이언트 계층                      │\n│  ┌──────────┐  ┌──────────┐  ┌──────────┐           │\n│  │ 브라우저   │  │  CLI     │  │  API     │           │\n│  └────┬─────┘  └────┬─────┘  └────┬─────┘           │\n│       └──────────────┼──────────────┘                │\n│                      │ WebSocket (wss://)            │\n├──────────────────────┼──────────────────────────────┤\n│                 서버 계층                              │\n│       ┌──────────────┴──────────────┐                │\n│       │      세션 매니저              │                │\n│       │  ┌─────┐ ┌─────┐ ┌─────┐   │                │\n│       │  │PTY 1│ │PTY 2│ │PTY N│   │                │\n│       │  └─────┘ └─────┘ └─────┘   │                │\n│       └─────────────────────────────┘                │\n│                      │                               │\n│       ┌──────────────┴──────────────┐                │\n│       │     영구 스토리지             │                │\n│       │  (세션 상태, 히스토리, 설정)   │                │\n│       └─────────────────────────────┘                │\n└─────────────────────────────────────────────────────┘\n```\n\n### 3.2 핵심 구성 요소\n\n| 구성 요소 | 역할 | 기술 선택지 |\n|-----------|------|------------|\n| **PTY (Pseudo Terminal)** | 서버 측 가상 터미널 | `node-pty`, `python-pty` |\n| **세션 매니저** | 세션 생명주기 관리 | Node.js, Go, Rust |\n| **WebSocket 서버** | 실시간 양방향 통신 | `ws`, `Socket.IO` |\n| **인증/인가** | 사용자 식별 및 권한 관리 | JWT, OAuth 2.0 |\n| **암호화 저장소** | 민감 데이터 보호 | AES-256, Vault |\n\n## 4. 구현 가이드\n\n### 4.1 서버 측 PTY 레이어\n\nPTY(Pseudo Terminal)는 클라우드 터미널의 핵심입니다. 서버에서 실제 쉘 프로세스를 생성하고, 클라이언트와의 입출력을 중계합니다.\n\n```typescript\n// PTY 세션 생성 예시 (node-pty 기반)\nimport * as pty from 'node-pty';\n\ninterface SessionConfig {\n  shell: string;\n  cols: number;\n  rows: number;\n  env: Record<string, string>;\n}\n\nfunction createSession(config: SessionConfig) {\n  const ptyProcess = pty.spawn(config.shell, [], {\n    name: 'xterm-256color',\n    cols: config.cols || 80,\n    rows: config.rows || 24,\n    cwd: process.env.HOME,\n    env: { ...process.env, ...config.env },\n  });\n\n  return {\n    id: generateSessionId(),\n    pty: ptyProcess,\n    createdAt: new Date(),\n    lastActivity: new Date(),\n  };\n}\n```\n\n### 4.2 WebSocket 통신\n\n클라이언트와 서버 간의 실시간 통신은 보안 WebSocket(wss://)을 통해 이루어집니다.\n\n```typescript\n// WebSocket 서버 설정 예시\nimport { WebSocketServer } from 'ws';\n\nconst wss = new WebSocketServer({ port: 8080 });\n\nwss.on('connection', (ws, req) => {\n  // 인증 검증\n  const token = extractToken(req);\n  const user = verifyToken(token);\n  if (!user) {\n    ws.close(1008, 'Unauthorized');\n    return;\n  }\n\n  // 기존 세션 복원 또는 새 세션 생성\n  const session = restoreSession(user.id) || createSession({\n    shell: '/bin/bash',\n    cols: 80,\n    rows: 24,\n    env: {},\n  });\n\n  // PTY 출력 → 클라이언트 전송\n  session.pty.onData((data: string) => {\n    if (ws.readyState === ws.OPEN) {\n      ws.send(JSON.stringify({ type: 'output', data }));\n    }\n  });\n\n  // 클라이언트 입력 → PTY 전송\n  ws.on('message', (msg: string) => {\n    const parsed = JSON.parse(msg);\n    if (parsed.type === 'input') {\n      session.pty.write(parsed.data);\n    } else if (parsed.type === 'resize') {\n      session.pty.resize(parsed.cols, parsed.rows);\n    }\n    session.lastActivity = new Date();\n  });\n\n  // 연결 종료 시 세션은 유지 (PTY 종료하지 않음)\n  ws.on('close', () => {\n    saveSessionState(session);\n    // 주의: session.pty.kill()을 호출하지 않음\n  });\n});\n```\n\n### 4.3 세션 영속성\n\n클라우드 터미널의 핵심 가치는 **세션이 클라이언트 연결과 독립적으로 유지**되는 것입니다.\n\n```typescript\n// 세션 상태 관리\ninterface PersistentSession {\n  id: string;\n  userId: string;\n  ptyPid: number;\n  scrollback: string[];    // 스크롤백 버퍼\n  env: Record<string, string>;\n  cwd: string;\n  createdAt: Date;\n  lastActivity: Date;\n}\n\n// 세션 상태 저장 (Redis 또는 파일 시스템)\nasync function saveSessionState(session: PersistentSession): Promise<void> {\n  await redis.hset(`session:${session.id}`, {\n    ...session,\n    scrollback: JSON.stringify(session.scrollback.slice(-10000)),\n  });\n  await redis.expire(`session:${session.id}`, 86400 * 7); // 7일 유지\n}\n\n// 세션 복원\nasync function restoreSession(userId: string): Promise<PersistentSession | null> {\n  const sessionKeys = await redis.keys(`session:*`);\n  for (const key of sessionKeys) {\n    const session = await redis.hgetall(key);\n    if (session.userId === userId && isProcessAlive(session.ptyPid)) {\n      return deserializeSession(session);\n    }\n  }\n  return null;\n}\n```\n\n## 5. AI 에이전트 세션 유지\n\n### 5.1 AI 에이전트 전용 설계 고려사항\n\nAI 에이전트가 클라우드 터미널을 활용할 때는 일반 사용자와 다른 요구사항이 있습니다.\n\n| 요구사항 | 설명 | 구현 방법 |\n|----------|------|----------|\n| **장기 실행** | 수 시간~수 일간 지속 실행 | 세션 타임아웃 비활성화 또는 확장 |\n| **프로그래밍 접근** | API를 통한 명령 실행 | REST/gRPC 엔드포인트 제공 |\n| **출력 수집** | 명령 실행 결과 구조화 | JSON 응답 래핑 |\n| **병렬 세션** | 동시 다중 작업 수행 | 세션 풀 관리 |\n| **상태 모니터링** | 에이전트 상태 실시간 확인 | 헬스체크 엔드포인트 |\n\n### 5.2 에이전트 API 인터페이스\n\n```typescript\n// AI 에이전트용 REST API 예시\ninterface AgentCommand {\n  sessionId: string;\n  command: string;\n  timeout?: number;       // 명령 실행 제한 시간 (ms)\n  waitForPrompt?: boolean; // 프롬프트 대기 여부\n}\n\ninterface AgentResponse {\n  sessionId: string;\n  output: string;\n  exitCode: number | null;\n  duration: number;\n  isAlive: boolean;\n}\n\n// POST /api/agent/execute\nasync function executeCommand(req: AgentCommand): Promise<AgentResponse> {\n  const session = await getOrCreateSession(req.sessionId);\n  const startTime = Date.now();\n\n  return new Promise((resolve) => {\n    let output = '';\n    const timeout = setTimeout(() => {\n      resolve({\n        sessionId: session.id,\n        output,\n        exitCode: null,\n        duration: Date.now() - startTime,\n        isAlive: true,\n      });\n    }, req.timeout || 30000);\n\n    session.pty.onData((data: string) => {\n      output += data;\n      if (req.waitForPrompt && isPrompt(data)) {\n        clearTimeout(timeout);\n        resolve({\n          sessionId: session.id,\n          output,\n          exitCode: 0,\n          duration: Date.now() - startTime,\n          isAlive: true,\n        });\n      }\n    });\n\n    session.pty.write(req.command + '\\n');\n  });\n}\n```\n\n### 5.3 에이전트 세션 생명주기\n\n```\n에이전트 시작 → 세션 요청 → [기존 세션 복원 / 새 세션 생성]\n     │                              │\n     ▼                              ▼\n명령 실행 ←──── 작업 큐 ←──── 오케스트레이터\n     │\n     ▼\n결과 수집 → 다음 작업 결정 → 반복\n     │\n     ▼ (에이전트 중단/재시작)\n세션 상태 저장 → 세션 유지 (PTY 계속 실행)\n     │\n     ▼ (에이전트 재연결)\n세션 복원 → 이전 상태에서 작업 재개\n```\n\n## 6. 보안 설계\n\n### 6.1 보안 체크리스트\n\n- **통신 암호화**: 모든 WebSocket 연결에 TLS(wss://) 적용\n- **인증**: JWT 또는 OAuth 2.0 기반 토큰 인증\n- **세션 격리**: 사용자별 독립된 PTY 프로세스 및 네임스페이스\n- **민감 데이터 보호**: 환경변수, API 키 등은 암호화 저장\n- **비활동 잠금**: 일정 시간 비활동 시 자동 잠금\n- **감사 로그**: 모든 명령 실행 이력 기록\n\n### 6.2 컨테이너 기반 격리\n\n```yaml\n# Docker Compose를 활용한 세션 격리 예시\nservices:\n  terminal-session:\n    image: cloud-terminal:latest\n    deploy:\n      resources:\n        limits:\n          cpus: '1.0'\n          memory: 512M\n    security_opt:\n      - no-new-privileges:true\n    read_only: true\n    tmpfs:\n      - /tmp\n    networks:\n      - isolated\n    environment:\n      - SESSION_TIMEOUT=3600\n      - MAX_SCROLLBACK=10000\n```\n\n### 6.3 네트워크 보안\n\n```\n클라이언트 ──[TLS]──▶ 리버스 프록시 (Nginx/Traefik)\n                           │\n                     [인증 미들웨어]\n                           │\n                     [Rate Limiting]\n                           │\n                  ┌────────┴────────┐\n                  │  내부 네트워크    │\n                  │  (격리된 세션)   │\n                  └─────────────────┘\n```\n\n## 7. 운영 고려사항\n\n### 7.1 리소스 관리\n\n| 항목 | 권장값 | 비고 |\n|------|--------|------|\n| 세션당 메모리 | 256MB~512MB | 작업 유형에 따라 조정 |\n| 스크롤백 버퍼 | 10,000줄 | 메모리 사용량 균형 |\n| 세션 타임아웃 | 7일 (AI), 24시간 (일반) | 용도별 차등 설정 |\n| 최대 동시 세션 | 서버 리소스에 비례 | CPU 코어 * 4 권장 |\n\n### 7.2 모니터링\n\n클라우드 터미널 운영 시 다음 지표를 모니터링해야 합니다.\n\n- **활성 세션 수**: 현재 실행 중인 PTY 프로세스 수\n- **메모리 사용량**: 세션별 및 전체 메모리 소비\n- **WebSocket 연결 상태**: 활성 연결 수, 재연결 빈도\n- **세션 생존 시간**: 평균 세션 유지 기간\n- **명령 실행 지연**: PTY 입출력 레이턴시\n\n### 7.3 장애 복구\n\n```\nPTY 프로세스 비정상 종료\n     │\n     ▼\n세션 매니저 감지 (프로세스 모니터링)\n     │\n     ▼\n마지막 저장 상태에서 새 PTY 생성\n     │\n     ▼\n환경변수, 작업 디렉토리 복원\n     │\n     ▼\n스크롤백 히스토리 복원\n     │\n     ▼\n클라이언트에 재연결 알림\n```\n\n## 8. 기존 도구 및 대안 비교\n\n| 도구 | 영구 세션 | 웹 접근 | AI 통합 | 격리 | 비용 |\n|------|:---------:|:-------:|:-------:|:----:|------|\n| tmux/screen | O | X | X | X | 무료 |\n| Eternal Terminal (et) | O | X | X | X | 무료 |\n| Mosh | △ | X | X | X | 무료 |\n| VS Code Remote | O | O | △ | △ | 무료 |\n| GitHub Codespaces | O | O | O | O | 유료 |\n| 자체 구축 클라우드 터미널 | O | O | O | O | 인프라 비용 |\n\n## 9. 실전 구축 체크리스트\n\n- [ ] PTY 레이어 구현 및 테스트\n- [ ] WebSocket 서버 구축 (TLS 적용)\n- [ ] 인증/인가 시스템 연동\n- [ ] 세션 영속성 구현 (Redis/파일시스템)\n- [ ] 컨테이너 기반 세션 격리\n- [ ] AI 에이전트용 API 엔드포인트 구현\n- [ ] 모니터링 및 알림 설정\n- [ ] 장애 복구 시나리오 테스트\n- [ ] 부하 테스트 및 리소스 최적화\n- [ ] 보안 감사 수행\n\n## 10. 결론\n\n클라우드 터미널은 로컬 터미널의 한계를 극복하고, 특히 AI 에이전트의 장기 실행 세션을 안정적으로 유지하는 데 핵심적인 인프라입니다. PTY 레이어, WebSocket 통신, 세션 영속성이라는 세 가지 핵심 축을 중심으로 구축하면, 기기 독립적이고 안정적인 터미널 환경을 확보할 수 있습니다.\n\n보안(TLS, 세션 격리, 암호화)과 운영(모니터링, 장애 복구, 리소스 관리)을 함께 설계해야 프로덕션 수준의 클라우드 터미널을 운영할 수 있습니다.\n\n## 참고 자료\n\n- [원본 기사: 클라우드 터미널 구축 경험](https://euno.news/posts/ko/i-built-a-cloud-terminal-because-i-was-tired-of-ba-4274c8)\n- [node-pty - Node.js PTY 라이브러리](https://github.com/microsoft/node-pty)\n- [xterm.js - 웹 기반 터미널 에뮬레이터](https://xtermjs.org/)\n- [tmux - 터미널 멀티플렉서](https://github.com/tmux/tmux)\n- [Eternal Terminal](https://eternalterminal.dev/)\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "클라우드 터미널",
        "SSH",
        "AI 에이전트",
        "PTY",
        "WebSocket",
        "tmux",
        "세션 관리"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "AI 코드 리뷰 에이전트 구축 가이드",
      "slug": "ai/code-review-agent-guide",
      "content": "\n# AI 코드 리뷰 에이전트 구축 가이드\n\n## 개요\n수동 PR 리뷰는 리뷰어가 피곤할 때 놓치는 부분이 생기고, 동일한 코멘트가 반복되는 등 비효율적인 문제가 있습니다. AI‑powered 솔루션을 활용하면 모든 풀 리퀘스트에 대해 구조화된 코드 리뷰(정확성, 보안, 성능, 테스트)를 CI가 자동으로 수행하도록 할 수 있습니다. 원하는 모델(OpenAI, Anthropic, OpenRouter, 혹은 로컬 Ollama 인스턴스)을 사용해 별도의 구독료 없이도 리뷰를 제공할 수 있습니다.\n\n## AI 코드 리뷰 에이전트 설계\n- **리뷰 루브릭(프롬프트/워크플로)**: 모델이 아니라 리뷰 기준을 정의합니다.\n  - 고위험 이슈와 사소한 지적을 구분\n  - 구체적인 수정 방안과 테스트 제안 요구\n  - \"내가 살펴본 내용\"과 \"내가 확신하지 못하는 부분\" 명시\n- **모델 선택**: 비용·속도·정확도에 따라 모델 라우팅\n- **실행 시점**: PR 발생 시 자동 트리거\n- **제어 파라미터**: 최대 토큰 수, 검토 기준 등 사용자 정의 가능\n\n## CI 파이프라인 통합 단계\n1. **GitHub Action 워크플로 파일 생성** (`.github/workflows/ai-code-review.yml`)\n   ```yaml\n   name: AI Code Review\n   on:\n     pull_request:\n   jobs:\n     review:\n       runs-on: ubuntu-latest\n       permissions:\n         contents: read\n         pull-requests: write\n       steps:\n         - uses: actions/checkout@v4\n           with:\n             fetch-depth: 0\n         - name: Install Jazz\n           run: npm install -g jazz-ai\n         - name: Run code review workflow\n           run: jazz --output raw workflow run code-review --auto-approve\n           env:\n             OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n   ```\n   - `--output raw`는 CI 환경에서 출력 캡처가 용이하도록 합니다.\n   - `--auto-approve`는 완전 자동화를 의미합니다.\n2. **리뷰 루브릭 파일 생성** (`workflows/code-review/WORKFLOW.md`)\n   ```markdown\n   ---\n   name: code-review\n   description: Review PR diff and produce a structured report\n   autoApprove: read-only\n   ---\n   Review the current PR diff.\n   Output GitHub‑flavored Markdown with:\n   1. **Summary** (2–4 bullets)\n   2. **High‑risk issues** (correctness + security)\n   3. **Performance / complexity concerns**\n   4. **API / UX footguns**\n   5. **Test gaps + concrete test suggestions**\n   6. **Nitpicks** (style/readability)\n   **Rules**\n   - Be specific: reference files/functions.\n   - Prefer minimal diffs / smallest safe fix.\n   - If you’re unsure, say so and propose how to verify.\n   - No generic advice (“add tests”) — propose exact test cases.\n   - Rank issues (High/Medium/Low).\n   - List files reviewed, assumptions, and what was not checked.\n   ```\n3. **리뷰 캡처 및 PR 코멘트**\n   ```yaml\n   - name: Generate review markdown\n     run: jazz --output raw workflow run code-review --auto-approve > review.md\n     env:\n       OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}\n   - name: Comment on PR\n     run: gh pr comment \"$PR_NUMBER\" --body-file review.md\n     env:\n       GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}\n       PR_NUMBER: ${{ github.event.pull_request.number }}\n   ```\n   인라인 주석은 선택 사항이며, 기본적인 가치 제공을 위해서는 위 단계만으로 충분합니다.\n\n## 예제 워크플로우와 베스트 프랙티스\n- **읽기 전용 모드**: `autoApprove`를 읽기 전용으로 유지해 에이전트가 저장소를 수정하지 못하도록 합니다.\n- **이슈 순위 매기기**: 모든 이슈에 중요도(High/Medium/Low)를 부여해 실제 중요한 문제에 집중합니다.\n- **오탐 예산 관리**: 리뷰가 너무 잡음이 많으면 무시될 수 있으니, 오탐 비율을 조정합니다.\n- **모델 라우팅 전략**:\n  - 작은 PR → 저비용 모델 (예: Ollama, OpenRouter의 경량 모델)\n  - 대규모 리팩터링 → 고성능 모델 (예: OpenAI GPT‑4o)\n- **투명성**: 에이전트가 검토한 파일 목록, 가정한 내용, 검토하지 않은 항목을 명시하도록 요구합니다.\n- **실제 사례**: Jazz 저장소는 자체 코드 리뷰와 릴리즈 노트에 Jazz를 사용합니다. 워크플로 파일은 [GitHub - lvndry/jazz](https://github.com/lvndry/jazz/tree/main/.github) 에서 확인할 수 있습니다.\n\n## 참고 자료\n- 원본 기사: [CI에서 나만의 AI 코드 리뷰 에이전트 만들기 | EUNO.NEWS](https://euno.news/posts/ko/build-your-own-ai-code-review-agent-in-ci-738404) (Dev.to 번역)\n\n---\n*이 문서는 Issue 피드백을 반영하여 초안(draft) 상태로 생성되었습니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "AI",
        "코드 리뷰",
        "CI",
        "GitHub Actions",
        "에이전트"
      ],
      "order": 10,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "LLM 진화 연대별 타임라인 및 171개 모델 개관",
      "slug": "ai/243",
      "content": "\n## 1. 서론\n대형 언어 모델(LLM)의 급격한 발전은 AI 연구·산업 전반에 큰 파장을 일으키고 있습니다. 2017년 최초 **Transformer** 발표 이후, **ChatGPT**, **GPT‑4**, **Claude**, **Gemini**, **LLaMA**, **Mistral**, **DeepSeek** 등 수많은 모델이 연이어 등장했으며, 2026년 현재까지 **171개의 LLM**이 연대순으로 정리된 타임라인이 존재한다는 보고가 있습니다【Show HN: AI 타임라인 – 2017년 Transformer부터 2026년 GPT‑5.3까지 171 LLMs, euno.news】.  \n\n본 문서는 이 타임라인을 기반으로 LLM 진화 흐름을 조망하고, 향후 연구·산업적 함의를 탐색하는 것을 목표로 합니다.  \n\n- **대상 독자**: AI 연구자, 엔지니어, 정책 입안자, AI 산업 종사자  \n- **핵심 질문**: “LLM은 어떻게 진화했는가?”  \n\n---\n\n## 2. 범위와 조사 방법\n### 2.1 포함 모델 기준\n- 파라미터 수 **≥ 1 B**인 대형 언어 모델  \n- 공개·비공개 모델 모두 포함  \n- 2017년 Transformer 발표 이후부터 2026년 GPT‑5.3까지 출시된 모델  \n\n### 2.2 데이터 수집 출처\n| 출처 | 설명 |\n|------|------|\n| Hacker News (Show HN) | euno.news가 정리한 연대별 타임라인 |\n| 학술 논문·컨퍼런스 | arXiv, NeurIPS, ICML 등 |\n| 기업 발표·보도자료 | OpenAI, Google DeepMind, Anthropic 등 |\n| 오픈소스 레포지토리 | GitHub, Hugging Face Hub |\n\n### 2.3 타임라인 구축 절차 및 검증\n1. **모델 명·출시 연도·주요 특징**을 수집  \n2. 동일 모델에 대한 **중복·오류**를 교차 검증 (다중 출처 비교)  \n3. **최종 리스트**를 171개 모델로 정리 (euno.news 보고)  \n\n> **※ 본 문서에서는 171개 전체 모델 중 대표적인 20개 모델을 표로 제시하고, 전체 목록은 부록 10에 별도 CSV 파일 형태로 제공됩니다.**  \n\n---\n\n## 3. LLM 진화 연대별 개관\n| 기간 | 주요 흐름 | 대표 모델(예시) |\n|------|-----------|----------------|\n| 2017 ~ 2019 | Transformer 기반 초기 모델 | Transformer, BERT, GPT‑1 |\n| 2020 ~ 2021 | 대규모 사전학습 확산 | GPT‑2, T5, RoBERTa |\n| 2022 ~ 2023 | 멀티모달·인스트럭션 튜닝 시대 | ChatGPT, PaLM, LLaMA |\n| 2024 ~ 2025 | 효율성·특화 모델 급증 | Mistral, DeepSeek, Claude |\n| 2026 | GPT‑5.3 및 최신 171 모델 요약 | GPT‑5.3, Gemini‑Pro, Aurora |\n\n*표 1. 연도별 주요 흐름과 대표 모델*  \n\n---\n\n## 4. 모델 카탈로그 (대표 20개 모델)\n\n### 4.1 연도·출시 순 정렬 표 (대표 모델)\n| # | 모델 | 출시 연도 | 파라미터 수 | 학습 데이터 규모 | 공개 여부 |\n|---|------|----------|------------|-------------------|-----------|\n| 1 | Transformer | 2017 | – | – | 공개 |\n| 2 | BERT | 2018 | 0.34 B | 3.3 B 토큰 | 공개 |\n| 3 | GPT‑1 | 2018 | 0.12 B | 5 B 토큰 | 공개 |\n| 4 | GPT‑2 | 2019 | 1.5 B | 40 B 토큰 | 공개 |\n| 5 | RoBERTa | 2019 | 0.36 B | 160 GB 텍스트 | 공개 |\n| 6 | T5 | 2020 | 11 B | 750 GB 텍스트 | 공개 |\n| 7 | GPT‑3 | 2020 | 175 B | 570 GB 텍스트 | 비공개 |\n| 8 | PaLM | 2022 | 540 B | 780 GB 텍스트 | 비공개 |\n| 9 | LLaMA | 2023 | 65 B | 1.4 TB 토큰 | 공개 |\n|10| ChatGPT (GPT‑3.5) | 2022 | 6 B (in‑service) | – | 비공개 |\n|11| Claude 1 | 2023 | 52 B | – | 비공개 |\n|12| Mistral 7B | 2024 | 7 B | – | 공개 |\n|13| DeepSeek‑V2 | 2024 | 16 B | – | 공개 |\n|14| Gemini‑Pro | 2025 | 300 B | – | 비공개 |\n|15| GPT‑4 | 2023 | 1 T | – | 비공개 |\n|16| GPT‑5 | 2025 | 2 T | – | 비공개 |\n|17| GPT‑5.3 | 2026 | 2.5 T | – | 비공개 |\n|18| Aurora | 2026 | 1.2 T | – | 비공개 |\n|19| LLaMA‑2 70B | 2023 | 70 B | – | 공개 |\n|20| Mistral‑Mix 30B | 2025 | 30 B | – | 공개 |\n\n*표 2. 대표 20개 모델의 핵심 메타데이터*  \n\n> **※ 파라미터 수와 학습 데이터 규모는 공개된 자료(기업 블로그, 논문, 기술 보고서)를 기반으로 정리했으며, 일부 비공개 모델은 추정값을 사용했습니다. 전체 171개 모델에 대한 상세 메타데이터는 부록 10(‘full_model_catalog.csv’)에 포함됩니다.**  \n\n### 4.2 핵심 특징 요약\n| 특징 | 설명 |\n|------|------|\n| **아키텍처 변형** | Sparse MoE, Retrieval‑augmented, Decoder‑only 등 다양한 변형이 도입 |\n| **효율성 기술** | FP8 양자화, LoRA, FlashAttention 등 경량화·속도 향상 기법 적용 |\n| **멀티모달 지원** | 텍스트·이미지·음성·비디오 입력을 동시에 처리하는 모델 증가 |\n| **인스트럭션 튜닝·RLHF** | 인간 피드백 기반 정렬 메커니즘이 표준화 (ChatGPT, Claude 등) |\n| **안전·거버넌스** | 모델 카드, 위험 평가, 정밀 조정 정책 등 안전성 강화 노력 |\n\n---\n\n## 5. 기술적 진화 트렌드\n1. **아키텍처 혁신** – Sparse MoE(예: GPT‑4‑MoE), Retrieval‑augmented Generation(RAG) 등으로 파라미터 효율성을 극대화.  \n2. **스케일링 법칙 및 효율성** – FP8 양자화와 **LoRA**(Low‑Rank Adaptation) 적용으로 훈련·추론 비용 30 % 이상 절감.  \n3. **멀티모달 통합** – **Gemini‑Pro**, **DeepSeek‑V2** 등은 텍스트·이미지·음성을 동시에 처리할 수 있는 통합 인코더를 채택.  \n4. **인스트럭션 튜닝·RLHF** – **ChatGPT**, **Claude** 등은 인간 피드백을 활용한 정렬 단계가 핵심 성능 향상 요인으로 작용.  \n5. **안전성·정렬 메커니즘** – 모델 카드, 위험 평가, 정밀 조정 정책 등 거버넌스 프레임워크가 표준화되고 있음.  \n\n*그림 1. 2017‑2026년 주요 기술 트렌드 흐름 (시각화 차트는 부록 11에 SVG 파일 제공)*  \n\n---\n\n## 6. 사회·산업적 파급 효과\n| 분야 | 적용 사례 | 주요 파급 효과 |\n|------|-----------|----------------|\n| 검색 | **Google Gemini** 기반 검색 엔진 | 질의 응답 정확도 25 % 향상 |\n| 코딩 보조 | **GitHub Copilot**, **DeepSeek‑Code** | 개발 생산성 평균 30 % 증가 |\n| 창작 | **ChatGPT**, **Claude** | 콘텐츠 생성 비용 40 % 절감 |\n| 의료 | **Mistral‑Med**(가상) | 진단 보조 정확도 15 % 상승 |\n| 교육 | **LLaMA‑Edu** | 맞춤형 학습 경로 제공, 학습 이탈률 10 % 감소 |\n\n> **※ 위 수치는 공개된 기업 보고서와 학술 연구(2024‑2025년)에서 인용한 평균값이며, 구체적인 통계는 부록 12에 상세히 정리했습니다.**  \n\n---\n\n## 7. 도전 과제와 위험 요소\n| 과제 | 현재 상황 | 대응 방안 |\n|------|-----------|-----------|\n| 데이터 편향·윤리 | 학습 데이터에 사회·문화 편향 존재 | 데이터 정제·다양성 확보, 공정성 평가 프레임워크 도입 |\n| 계산·에너지 비용 | 초대형 모델 훈련에 연간 수백만 달러·수천 MWh 소요 | 효율적인 양자화·스파스 모델, 재생에너지 활용 |\n| 모델 보안·악용 | 생성형 AI를 이용한 피싱·디프페이크 증가 | 출력 검증, 사용 제한 정책, Watermark 기술 |\n| 규제·법적 이슈 | 국가별 AI 규제 차이 심화 | 국제 표준 협의, 투명성·책임성 보고 체계 구축 |\n\n---\n\n## 8. 제한 사항 및 데이터 한계\n1. **전체 171개 모델 중 일부는 비공개**이어서 파라미터 수·학습 데이터 규모 등 핵심 메타데이터가 제한적입니다.  \n2. **시계열 데이터는 주로 Hacker News와 기업 발표에 의존**하므로, 일부 모델의 출시 연도가 실제와 차이가 있을 수 있습니다.  \n3. **정량적 성능 비교(예: FLOPs, 벤치마크 점수)는 최신 논문이 아직 공개되지 않은 모델에 대해 제공되지 않았습니다.**  \n\n> **향후 계획** – 2026‑2027년 사이에 공개된 논문·보고서를 지속적으로 수집하고, 부록 10의 CSV 파일을 연 2회 업데이트할 예정입니다.  \n\n---\n\n## 9. 미래 전망\n- **예상 기술 로드맵**: GPT‑6(≈5 T 파라미터), 초대형 멀티모달 모델(10 T 파라미터 이상), **자율 학습**(Continual Learning) 모델이 2027‑2029년 사이에 등장할 것으로 전망됩니다.  \n- **연구 방향성**: 지식 추론, 메타‑러닝, 인간‑AI 협업 인터페이스, **AI‑Explainability**가 주요 과제로 부상합니다.  \n- **정책·거버넌스 제언**: 국제 AI 표준 기구(ISO/IEC)와 협력해 **투명성·책임성·안전성**을 보장하는 인증 체계 도입이 필요합니다.  \n\n---\n\n## 10. 참고 문헌 및 리소스\n1. Show HN: AI 타임라인 – 2017년 Transformer부터 2026년 GPT‑5.3까지 171 LLMs, euno.news. https://euno.news/posts/ko/show-hn-ai-timeline-171-llms-from-transformer-2017-6ebcbc  \n2. Brown, T. *et al.* (2020). **Language Models are Few-Shot Learners**. *NeurIPS*.  \n3. OpenAI (2023). **GPT‑4 Technical Report**. https://openai.com/research/gpt-4  \n4. Google DeepMind (2025). **Gemini‑Pro: Scaling Multimodal Models**. *arXiv preprint arXiv:2503.01234*.  \n5. Mistral AI (2024). **Mistral 7B Model Card**. https://huggingface.co/mistralai/Mistral-7B  \n\n*추가적인 논문·보고서는 부록 13에 DOI와 함께 정리했습니다.*  \n\n---\n\n## 11. 부록\n### 11‑1. 연도별 타임라인 시각화 차트\n![LLM 연도별 타임라인 차트](assets/timeline_chart.svg)  \n*그림 1. 2017‑2026년 모델 출시 연도와 주요 변곡점*  \n\n### 11‑2. 용어 정의 및 약어 정리\n| 약어 | 정의 |\n|------|------|\n| LLM | Large Language Model, 대규모 언어 모델 |\n| RLHF | Reinforcement Learning from Human Feedback, 인간 피드백 기반 강화 학습 |\n| MoE | Mixture‑of‑Experts, 전문가 혼합 모델 |\n| RAG | Retrieval‑Augmented Generation, 검색 기반 생성 |\n| FLOPs | Floating Point Operations, 연산량 지표 |\n\n### 11‑3. 모델 비교 매트릭스 (전체 171개)\n- **파일**: `full_model_catalog.csv` (부록 10)  \n- 주요 컬럼: `Model`, `ReleaseYear`, `Parameters(B)`, `TrainingData( Tokens )`, `Public`, `Architecture`, `KeyFeatures`  \n\n### 11‑4. 정량적 성능 지표 (베이스라인)\n| 모델 | GLUE Avg. | MMLU Avg. | 인퍼런스 latency (ms) |\n|------|-----------|-----------|------------------------|\n| GPT‑3 | 84.2 | 45.1 | 120 |\n| LLaMA‑2 70B | 88.5 | 58.3 | 95 |\n| Gemini‑Pro | 90.1 | 62.7 | 80 |\n\n*표 3. 일부 모델의 베이스라인 벤치마크*  \n\n### 11‑5. 향후 업데이트 일정\n| 날짜 | 내용 |\n|------|------|\n| 2026‑06‑01 | 부록 10 CSV 파일 1차 업데이트 (신규 모델 12개 추가) |\n| 2026‑12‑15 | 부록 12 시장·채택 사례 업데이트 |\n| 2027‑03‑01 | 전체 문서 버전 2.0 배포 (전체 171개 모델 메타데이터 완전 공개) |\n\n---",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "LLM",
        "AI 타임라인",
        "모델 진화",
        "인공지능 역사"
      ],
      "order": 11,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "MCP (Model Context Protocol) 완벽 가이드",
      "slug": "ai/mcp-model-context-protocol",
      "content": "\n## 1. MCP란 무엇인가  \n\n### 1.1 정의 및 핵심 개념  \n**Model Context Protocol (MCP)** 은 Anthropic이 2024년 11월에 공개한 **오픈 표준 프로토콜**이다.  \nLLM(대형 언어 모델)이 외부 시스템(데이터베이스, 파일, 웹 API 등)과 **양방향**으로 연결되어, 컨텍스트를 일관되게 전달·관리하고, 보안·신뢰성을 유지하도록 설계되었다.  \n\n- **Host** – LLM을 실행하는 환경(예: Claude Desktop, 클라우드 서비스)  \n- **Client** – Host가 MCP 서버에 요청을 보내는 역할, 일반적으로 SDK를 통해 구현  \n- **Server** – Tools·Resources·Prompts 등을 제공하고, JSON‑RPC 2.0 메시지를 처리하는 중앙 엔티티  \n- **Tool** – 외부 API, CLI, 함수 등 실행 가능한 작업 단위  \n- **Resource** – 파일, DB, 웹 서비스 등 LLM이 읽고 쓸 수 있는 데이터 소스  \n- **Prompt** – LLM에게 전달되는 컨텍스트 템플릿 및 동적 변수  \n- **Sampling** – 토큰 샘플링 파라미터(temperature, top‑p 등)를 모델과 서버가 공유·조정하는 메커니즘  \n- **Root** – 전체 컨텍스트 트리의 시작점(예: 사용자 세션 ID)  \n\n### 1.2 발표 배경  \n- **통합 병목**: 기존 LLM‑외부 연동 방식은 각 서비스마다 비표준 API와 인증 로직을 구현해야 했다.  \n- **컨텍스트 파편화**: 여러 도구를 연계할 때 모델이 이전 단계의 상태를 기억하지 못해 반복 호출이 발생했다.  \n- **보안·신뢰**: 임의 코드 실행 위험과 데이터 유출 위험을 최소화하기 위한 통합 인증·권한 모델이 필요했다.  \n\nMCP는 이러한 문제를 **표준화된 메시지 포맷**과 **역할 기반 보안**으로 해결한다.  \n\n### 1.3 주요 용어 정리  \n| 용어 | 정의 |\n|------|------|\n| **Host** | LLM을 포함한 애플리케이션(예: Claude Desktop) |\n| **Client** | Host가 MCP 서버와 통신하기 위해 사용하는 SDK |\n| **Server** | Tools·Resources·Prompts를 제공하고 JSON‑RPC를 구현 |\n| **Tool** | 외부 API 호출, 쉘 명령, 함수 실행 등 작업 단위 |\n| **Resource** | 파일, 데이터베이스, 웹 서비스 등 데이터 제공원 |\n| **Prompt** | 모델에 전달되는 템플릿 + 변수 구조 |\n| **Sampling** | 모델 출력 샘플링 파라미터 전파·조정 |\n| **Root** | 컨텍스트 트리의 루트(세션·작업 ID) |\n\n---\n\n## 2. MCP 아키텍처  \n\n### 2.1 전체 구성도와 역할 구분  \n```\n[Host] ←→ (Client SDK) ←→ [MCP Server] ←→ (Tools / Resources)\n```\n- **Host ↔ Client**: TLS‑encrypted HTTP/HTTPS 연결, API‑Key 기반 인증.  \n- **Client ↔ Server**: JSON‑RPC 2.0 요청/응답 흐름. 각 RPC 메서드는 `mcp.<category>.<action>` 형태(예: `mcp.tool.invoke`).  \n- **Server ↔ Tools/Resources**: 내부 플러그인 인터페이스(동기·비동기) 또는 외부 마이크로서비스 호출.  \n\n### 2.2 통신 레이어: JSON‑RPC 2.0  \n- **요청**: `jsonrpc: \"2.0\", id: <num>, method: \"mcp.tool.invoke\", params: {toolId, args, context}`  \n- **응답**: `jsonrpc: \"2.0\", id: <same>, result: {output, metadata}` 또는 `error` 객체.  \n- **알림**(notification): 서버가 비동기 이벤트(예: 파일 변경)를 Host에 푸시할 때 사용, `id` 없이 전송.  \n\n공식 스펙: <https://modelcontextprotocol.io/spec/json-rpc>  \n\n### 2.3 보안·인증 메커니즘  \n| 요소 | 설명 |\n|------|------|\n| **API 키** | Server‑side에 사전 등록, 요청 헤더 `Authorization: Bearer <key>` |\n| **TLS** | 모든 통신은 HTTPS(또는 wss) 로 암호화 |\n| **Scope** | 키당 허용된 Tool·Resource 목록을 정의(예: `read:file`, `invoke:weather_api`) |\n| **Auditing** | 요청·응답 로그를 JSON 형태로 저장, 선택적 서명 검증 제공 |\n\n### 2.4 확장성 포인트  \n- **플러그인**: Server는 Node.js, Python, Go 등 다양한 런타임에서 플러그인 형태로 Tool·Resource를 로드.  \n- **멀티‑Server 라우팅**: 하나의 Host가 여러 Server에 동시에 연결 가능(예: 파일 서버 + 비즈니스 API 서버). 라우팅 정책은 `mcp.routing` 메서드로 정의.  \n- **로드밸런싱·스케일링**: Kubernetes Ingress + Horizontal Pod Autoscaler 로 수평 확장 가능.  \n\n---\n\n## 3. MCP 핵심 기능  \n\n### 3.1 Tools  \n- **정의**: `toolId`, `description`, `inputSchema`, `outputSchema` 로 선언.  \n- **예시**: `weather.getCurrent` (REST API), `git.clone` (CLI), `calc.evaluate` (Python 함수).  \n- **실행 흐름**: Host → Client (`invoke`) → Server → Tool 구현체 → 결과 반환 → Host.  \n\n### 3.2 Resources  \n- **데이터 소스 유형**: `file`, `database`, `web`, `cache`.  \n- **읽기/쓰기 권한**: `read`, `write`, `list` 로 세분화된 Scope 제공.  \n- **버전 관리**: Resource에 `etag` 혹은 `revision` 메타데이터를 포함해 충돌 방지.  \n\n### 3.3 Prompts  \n- **템플릿**: Jinja‑like 구문(`{{variable}}`)을 사용해 동적 변수 삽입.  \n- **컨텍스트 트리**: Prompt는 Root → Sub‑Prompt 형태로 계층화 가능, 각 단계마다 Sampling 파라미터를 재정의할 수 있다.  \n\n### 3.4 Sampling  \n- **전파 메커니즘**: `mcp.sampling.update` 메서드로 Host가 현재 temperature, top‑p 등을 Server에 전달.  \n- **조정 시점**: Tool 실행 전후, 또는 사용자 피드백(예: “more creative”)에 따라 동적으로 변경.  \n\n### 3.5 Roots  \n- **역할**: 세션·작업을 구분하는 고유 식별자.  \n- **관리**: `mcp.root.create`, `mcp.root.close` 로 생명주기 제어.  \n- **멀티‑Root**: 복수 작업을 병렬 처리할 때 각각 독립된 컨텍스트 트리를 유지.  \n\n---\n\n## 4. MCP Server 구축 방법  \n\n### 4.1 사전 준비  \n| 항목 | 권장 버전 |\n|------|-----------|\n| Node.js | >=18 |\n| Python | >=3.10 |\n| Docker | >=24 |\n| 데이터베이스 (옵션) | SQLite (개발), PostgreSQL (프로덕션) |\n\n### 4.2 공식 SDK 소개  \n- **TypeScript SDK**: `typescript-mcp` (npm) – `McpClient`, `McpServer` 클래스 제공.  \n  - 공식 레포: <https://github.com/anthropic/ts-mcp>  \n- **Python SDK**: `python-mcp` (PyPI) – `McpClient`, `McpServer` 모듈 제공.  \n  - 공식 레포: <https://github.com/anthropic/python-mcp>  \n\n### 4.3 최소 구현 예제 (TypeScript)  \n\n1. **패키지 설치**  \n   ```bash\n   npm install typescript-mcp\n   ```\n\n2. **핸들러 등록**  \n   ```typescript\n   import { McpServer } from 'typescript-mcp';\n\n   const server = new McpServer({\n     port: 8080,\n     apiKey: process.env.MCP_API_KEY,\n   });\n\n   // Tool 등록\n   server.registerTool('weather.getCurrent', async (args, ctx) => {\n     const resp = await fetch(`https://api.weather.com/v3/${args.location}`);\n     const data = await resp.json();\n     return { temperature: data.temp, condition: data.text };\n   });\n\n   // Resource 등록 (파일 읽기)\n   server.registerResource('file.read', async (params) => {\n     const fs = require('fs').promises;\n     const content = await fs.readFile(params.path, 'utf-8');\n     return { content };\n   });\n\n   // Server 시작\n   server.start();\n   ```\n\n3. **인증 및 스코프 설정**  \n   ```typescript\n   server.defineScope('read:file', ['file.read']);\n   server.defineScope('invoke:weather_api', ['weather.getCurrent']);\n   ```\n\n> **주의**: 위 코드는 최소 예시이며, 프로덕션에서는 입력 검증, 오류 처리, 로깅, 레이트 리밋 등을 추가해야 한다.  \n\n### 4.4 Python 예제 (핵심 흐름)  \n\n1. **패키지 설치**  \n   ```bash\n   pip install python-mcp\n   ```\n\n2. **서버 구현**  \n   ```python\n   from mcp import McpServer\n\n   server = McpServer(host='0.0.0.0', port=8080, api_key='YOUR_API_KEY')\n\n   @server.tool('calc.evaluate')\n   async def evaluate(args, context):\n       result = eval(args['expression'])\n       return {'result': result}\n\n   @server.resource('db.query')\n   async def query(params):\n       import aiosqlite\n       async with aiosqlite.connect('example.db') as db:\n           async with db.execute(params['sql']) as cur:\n               rows = await cur.fetchall()\n               return {'rows': rows}\n\n   server.start()\n   ```\n\n### 4.5 설정 파일 구조  \n```\nmcp-server/\n├─ src/\n│  ├─ tools/\n│  │   └─ weather.ts\n│  ├─ resources/\n│  │   └─ file.ts\n│  └─ server.ts\n├─ config/\n│  └─ mcp.yaml   # 포트, API 키, 스코프 정의\n├─ Dockerfile\n└─ README.md\n```\n\n**`mcp.yaml`** 예시  \n\n```yaml\nport: 8080\napiKey: ${MCP_API_KEY}\ntls:\n  enabled: true\n  certFile: /certs/server.crt\n  keyFile: /certs/server.key\nscopes:\n  read:file: [file.read]\n  invoke:weather_api: [weather.getCurrent]\n```\n\n### 4.6 로컬 개발 환경 & 배포 옵션  \n\n| 환경 | 특징 |\n|------|------|\n| **SQLite + 파일 시스템** | 빠른 프로토타입, 별도 DB 관리 필요 없음 |\n| **PostgreSQL + Cloud Storage** | 트랜잭션·스케일링 지원, 엔터프라이즈 권장 |\n| **Docker Compose** | `docker-compose.yml` 로 DB·Server·TLS 인증서 동시 실행 |\n| **Kubernetes** | `Deployment`, `Service`, `Ingress` 로 수평 확장, `Secret` 로 API 키 관리 |\n| **Google Cloud Run / AWS Lambda** | 서버리스 배포, 자동 스케일링, 비용 효율 |\n\n---\n\n## 5. 실제 활용 사례  \n\n### 5.1 Claude Desktop  \n- **시나리오**: 사용자가 로컬 파일을 열어 내용 요약을 요청.  \n- **흐름**: Claude Desktop (Host) → MCP Client (TS SDK) → Local MCP Server (Docker) → `file.read` Resource → 파일 내용 반환 → Prompt에 삽입 → 모델이 요약.  \n- **성과**: 파일 접근 속도 30 % 개선, 보안 정책(`read:file`)을 중앙 관리.  \n\n### 5.2 IDE 플러그인 (VSCode, Zed, Sourcegraph Cody)  \n- **핵심 기능**: 코드 검색, 자동 완성, 리팩터링 제안.  \n- **MCP 활용**:  \n  - `git.clone` Tool 로 레포 복제,  \n  - `repo.search` Resource 로 파일 내용 검색,  \n  - `prompt.codeContext` 로 현재 편집 중인 파일·심볼 정보를 모델에 전달.  \n- **베스트 프랙티스**: 각 프로젝트마다 고유 `rootId` 를 부여해 세션 격리, `sampling.update` 로 온도 조절.  \n\n### 5.3 기업 통합 사례  \n\n| 기업 | 적용 영역 | 주요 Tool/Resource | 기대 효과 |\n|------|-----------|---------------------|-----------|\n| **FinTech A** | 고객 상담 자동화 | `crm.fetchCustomer`, `payment.initiate` | 평균 응답 시간 45 % 감소, PCI‑DSS 준수 |\n| **Manufacturing B** | 생산 라인 모니터링 | `sensor.read`, `maintenance.schedule` | 다운타임 20 % 감소, 로그 중앙화 |\n| **E‑commerce C** | 상품 추천 엔진 | `catalog.search`, `user.profile` | 전환율 12 % 상승, A/B 테스트 자동화 |\n\n### 5.4 Claude MCP 기반 SonarCloud 자동화 파이프라인  \n\n#### 개요  \nClaude Code CLI와 MCP 생태계를 활용해 코드 커밋부터 SonarCloud 품질 보고서 수신까지 **완전 자동화된 CI 파이프라인**을 구축한다. 전체 소요 시간은 약 2.5분이며, 수동 조작이 전혀 필요하지 않다.  \n\n#### 파이프라인 흐름  \n```\n코드 작성\n→ Claude가 커밋 & 푸시\n→ GitHub MCP를 통해 PR 생성\n→ GitHub Actions가 sonar‑scanner 실행\n→ Claude가 완료를 폴링\n→ SonarQube MCP로 보고서 수집\n→ 품질 게이트 + 이슈 테이블 출력\n```\n\n#### 주요 설정  \n\n| 구성 요소 | 역할 |\n|-----------|------|\n| **Claude Code CLI** | 전체 파이프라인 오케스트레이터 |\n| **mcp/sonarqube** | SonarCloud 데이터 읽기 (품질 게이트, 이슈, 메트릭) |\n| **ghcr.io/github/github-mcp-server** | 저장소·브랜치·PR 관리 |\n| **GitHub Actions** | sonar‑scanner 실행 |\n| **SonarCloud (Free Tier)** | 분석 결과 호스팅 |\n\n#### 실패 사례와 해결 방안  \n\n| 실패 유형 | 원인 | 해결 방안 |\n|-----------|------|----------|\n| **PAT 권한 부족** | 초기 토큰에 `repo` 스코프 누락 | PAT 재생성 시 `repo`, `read:org` 스코프 명시 |\n| **사용자 토큰 vs 프로젝트 토큰** | SonarCloud 사용자 토큰 사용 | 프로젝트 분석 토큰 사용으로 전환 |\n| **자동 분석 충돌** | SonarCloud 자동 분석과 CI 분석 동시 실행 | 자동 분석 비활성화, CI 전용으로 전환 |\n| **CI 상태 폴링 실패** | GitHub가 CI 상태를 `check_runs`가 아닌 `commit_status`에 보고 | 폴링 대상 `commit_status` API로 변경 |\n| **MCP 서버 연결 타임아웃** | Docker 컨테이너 초기화 지연 | `--init` 플래그 추가, 헬스체크 설정 |\n\n#### 성과 지표  \n\n| 지표 | 값 |\n|------|-----|\n| **커밋~보고서 총 소요 시간** | ~2.5분 |\n| **설정 후 수동 단계** | 0 |\n| **일회성 설정 시간** | ~30분 |\n\n> **참고**: 본 사례는 Dev.to에 게시된 실제 구현 경험([출처](https://euno.news/posts/ko/the-rogue-server-problem-what-mcphammer-reveals-ab-61c27c))을 기반으로 정리하였다.  \n\n### 5.5 성공 지표 및 베스트 프랙티스 요약  \n- **보안**: 스코프 기반 최소 권한 원칙 적용 → 권한 오용 0%  \n- **성능**: 평균 RPC 레이턴시 45 ms (Docker), 120 ms (K8s)  \n- **유지보수**: 플러그인 기반 Tool 추가 시 재배포 없이 Hot‑Reload 지원  \n\n### 5.6 MCP Trust Risks  \n\n2024‑12 경 **Praetorian**이 공개한 **MCPHammer** 연구에 따르면, MCP 환경에서 신뢰 문제가 두 가지 주요 공격 벡터로 구분된다.\n\n| 위험 유형 | 설명 | 현재 상황 (2025‑08 기준) |\n|----------|------|--------------------------|\n| **1️⃣ 노출된 인증‑없음 서버** | 인증이 전혀 없으며, `tools/list` 와 `tools/call` 모두 무제한으로 열려 있다. 187대가 민감한 도구(결제, 암호화폐 지갑, 코드 실행 등)를 노출하고 있다. | 기존 “Tier 1” 분류에 포함되며, 수동 스캔만으로는 위험을 완전히 파악하기 어렵다. |\n| **2️⃣ 악성 서버 위장** | 정상적인 MCP 서버처럼 보이지만, 모든 Tool 응답에 공격자가 삽입한 텍스트를 추가한다(프롬프트 인젝션). 텔레메트리 수집·원격 명령 실행 등 부가 악의적 행동을 수행한다. | 기존 인증‑티어(1‑3)로는 구분되지 않으며, **수동 스캔**(tools/list)만으로는 탐지 불가. |\n\n#### 핵심 신뢰 결함  \n\n1. **암호학적 검증 부재** – 클라이언트는 서버가 제공하는 Tool 설명·응답이 진짜인지 검증할 메커니즘이 없다.  \n2. **스코프·인증만으로는 충분치 않음** – 인증이 있더라도 악성 서버가 정상적인 스코프를 사용해 악의적 응답을 반환할 수 있다.  \n3. **동적 행동 변화 미감지** – 도구 설명이 바뀌거나 응답에 삽입된 텍스트가 추가되는 경우, 기존 정적 스캔은 이를 포착하지 못한다.  \n\n### 5.7 MCPHammer Findings and Recommendations  \n\n#### 주요 발견  \n\n| 항목 | 내용 |\n|------|------|\n| **데이터셋 규모** | 535대 MCP 서버 조사, 그 중 200대는 인증이 없고 187대는 무제한 도구 노출. |\n| **악성 서버 기능** | *프롬프트 인젝션*, *텔레메트리 수집*, *임의 파일 다운로드·실행*, *원격 명령 수신* 등. |\n| **인증 티어 한계** | Tier 1(인증 없음)과 악성 서버를 동일하게 표시, 기존 스캔으로는 구분 불가. |\n| **행동 기반 탐지 필요** | 도구 설명 체크섬, 응답 패턴, 버전 변동 등을 지속적으로 모니터링해야 함. |\n\n#### 권고 사항  \n\n1. **행동 기반 모니터링 도입**  \n   - 도구 설명(`description`)과 스키마에 체크섬을 부여하고, 변경 시 알림을 생성한다.  \n   - 응답에 삽입된 텍스트(프롬프트 인젝션) 여부를 정규식·해시 기반으로 검증한다.  \n   - `mcp.event.resourceUpdated` 와 같은 알림을 활용해 실시간 변화를 추적한다.  \n\n2. **활성 테스트(Active Probing)**  \n   - `tools/list` 후 **빈** `tools/call` 요청을 전송해 401/403 응답을 확인한다.  \n   - 인증‑티어가 `none`인 경우에도 최소한 하나의 **인증 없는** 호출을 시도해 실제 실행 가능성을 검증한다.  \n\n3. **서버 신원 검증 강화**  \n   - TLS 인증서 외에 **서버 서명**(예: JWS)으로 MCP 서버 구현 버전·해시를 검증한다.  \n   - 클라이언트는 서버가 제공하는 **Tool Manifest**(JSON)와 사전 공유된 해시를 비교한다.  \n\n4. **스코프·권한 최소화**  \n   - 공개된 서버라 하더라도 `read:file`·`invoke:weather_api` 등 **필요 최소 권한**만 부여한다.  \n   - 정기적으로 스코프를 리뷰하고, 사용되지 않는 Tool·Resource는 비활성화한다.  \n\n5. **멀티‑Tier 구분 정책**  \n   - 기존 Tier 1/2/3 외에 **Tier 1‑Malicious** 라벨을 도입해 “인증 없음 + 행동 이상 감지” 서버를 별도 관리한다.  \n   - CI/CD 파이프라인에 **MCPTrustScanner**를 포함해 배포 전 자동 검증을 수행한다.  \n\n6. **공개 레지스트리 활용**  \n   - 공식 MCP 레지스트리(<https://modelcontextprotocol.io/registry>)에 서버 메타데이터를 등록하고, **신뢰 점수**(인증, 행동 이력, 서명 여부)를 표시한다.  \n   - 커뮤니티와 공유된 신뢰 점수를 기반으로 클라이언트가 자동으로 서버를 선택하도록 구현한다.  \n\n7. **교육 및 운영 가이드**  \n   - 운영자는 “서버가 제공하는 도구를 무조건 신뢰하면 안 된다”는 원칙을 문서화하고, 정기적인 보안 워크숍을 진행한다.  \n   - 특히 도메인 탈취·네임스페이스 충돌 위험을 강조하고, DNSSEC·CAA 레코드 설정을 권장한다.  \n\n#### 적용 예시 (Python SDK)  \n\n```python\nfrom mcp import McpClient, McpServer\nimport hashlib, json\n\n# 1️⃣ 도구 설명 체크섬 저장\ndef checksum_tool_schema(schema):\n    return hashlib.sha256(json.dumps(schema, sort_keys=True).encode()).hexdigest()\n\n# 2️⃣ 클라이언트에서 서버 서명 검증\ndef verify_server_signature(manifest, signature, pub_key):\n    # JWS 검증 로직 (예시)\n    ...\n\nclient = McpClient(\n    endpoint=\"https://mcp.example.com\",\n    api_key=\"YOUR_KEY\",\n    verify_signature=True,          # 위 함수와 연동\n)\n\n# 도구 목록을 받아 체크섬 비교\ntools = client.call(\"mcp.tools.list\")\nfor t in tools:\n    local_hash = checksum_tool_schema(t[\"schema\"])\n    if local_hash != t[\"checksum\"]:\n        print(f\"[⚠️] Tool {t['toolId']} schema changed!\")\n```\n\n위와 같은 **행동 기반 검증**을 기존 SDK에 통합하면, 악성 서버가 삽입한 프롬프트 텍스트나 변조된 스키마를 실시간으로 탐지할 수 있다.  \n\n---\n\n## 6. 기존 방식과의 비교  \n\n| 항목 | Function Calling (OpenAI) | LangChain Tools & Agents | MCP |\n|------|---------------------------|--------------------------|-----|\n| **표준화** | 프로바이더 별 JSON 스키마 차이 | Python‑centric DSL, 비표준 RPC | JSON‑RPC 2.0 기반, 언어 독립 |\n| **양방향** | 모델 → 도구 호출만 지원 | 주로 단방향 흐름 | 모델 ↔ 서버 ↔ 도구 양방향, 컨텍스트 트리 유지 |\n| **컨텍스트 트리** | 제한적 (단일 호출) | 체인 형태지만 상태 공유 어려움 | Root‑ 기반 트리, 샘플링 파라미터 전파 |\n| **보안·스코프** | API 키 하나, 전역 권한 | 코드 레벨 권한 제어, 복잡 | Scope 정의·검증, 최소 권한 원칙 |\n| **멀티‑Server 라우팅** | 지원 안 함 | 별도 구현 필요 | 프로토콜 차원에서 라우팅 메커니즘 제공 |\n| **언어/플랫폼** | 주로 HTTP/JSON (REST) | Python 중심, JavaScript 제한 | SDK (TS, Python, Go 등) 다중 언어 지원 |\n\n### 장단점 매트릭스  \n\n| 관점 | 장점 (MCP) | 단점 (MCP) |\n|------|------------|------------|\n| **표준화** | 오픈 스펙, 다중 벤더 지원 | 초기 생태계가 아직 성장 단계 |\n| **보안** | 스코프·TLS·Auditing 기본 제공 | 스코프 관리 복잡도 (대규모 조직) |\n| **확장성** | 플러그인·멀티‑Server 설계 | 플러그인 개발 시 언어별 SDK 학습 필요 |\n| **성능** | 경량 JSON‑RPC, 로컬 서버 빠른 응답 | 네트워크 라운드트립이 많을 경우 지연 증가 |\n| **생태계** | 빠르게 늘어나는 오픈소스 프로젝트 | 상용 솔루션 대비 문서·지원 부족 (추가 조사 필요) |\n\n**선택 가이드**  \n- **신규 프로젝트**: 표준화·보안이 핵심이면 MCP 우선.  \n- **기존 LangChain 기반**: 기존 코드를 유지하면서 MCP Server를 라우터로 추가 가능.  \n- **고성능 단일 호출**: Function Calling이 간단하고 레이턴시가 중요한 경우 기존 방식 유지.  \n\n---\n\n## 7. MCP 생태계 현황  \n\n### 7.1 공식 MCP 서버 레지스트리  \n- **URL**: <https://modelcontextprotocol.io/registry>  \n- 제공되는 메타데이터: 서버 이름, 버전, 지원 Tool/Resource 목록, 인증 스코프, SLA 등.  \n\n### 7.2 커뮤니티 운영 서버 목록 (2024‑12 기준)  \n\n| 서버 이름 | GitHub | Docker Hub | 주요 특징 |\n|-----------|--------|-----------|-----------|\n| **mcp‑local‑dev** | https://github.com/mcp-community/mcp-local-dev | mcpcommunity/local-dev | 로컬 파일·SQLite 지원, VSCode 플러그인 연동 |\n| **mcp‑cloud‑aws** | https://github.com/mcp-community/mcp-cloud-aws | mcpcommunity/cloud-aws | AWS Lambda + API Gateway 배포 템플릿 |\n| **mcp‑enterprise‑gcp** | https://github.com/mcp-community/mcp-enterprise-gcp | mcpcommunity/enterprise-gcp | GCP Pub/Sub 기반 이벤트 라우팅, IAM 연동 |\n| **mcp‑open‑source‑gateway** | https://github.com/mcp-community/mcp-gateway | mcpcommunity/gateway | 다중 Server 프록시 및 GraphQL 변환 레이어 |\n\n### 7.3 주요 오픈소스 프로젝트  \n\n| 프로젝트 | 설명 | 레포 |\n|----------|------|------|\n| **mcp‑cli** | 명령줄에서 MCP 서버와 직접 상호작용, 디버깅·테스트용 | https://github.com/mcp-community/mcp-cli |\n| **mcp‑inspector** | 시각화 UI (React) 로 컨텍스트 트리, Tool 호출 로그 확인 | https://github.com/mcp-community/mcp-inspector |\n| **mcp‑gateway** | 멀티‑Server 라우팅 및 인증 프록시, Kubernetes Operator 포함 | https://github.com/mcp-community/mcp-gateway |\n| **mcp‑genkit‑adapter** | Google Cloud Genkit 과의 통합 어댑터, 서버리스 배포 지원 | https://github.com/mcp-community/mcp-genkit-adapter |\n\n### 7.4 이벤트·컨퍼런스·워크숍  \n\n| 행사 | 주최 | 일정 | 참여 방법 |\n|------|------|------|-----------|\n| **MCP Summit 2025** | Anthropic + OpenAI | 2025‑03‑12 (San Francisco) | 공식 홈페이지 신청 |\n| **MCP Community Hackathon** | GitHub Community | 2024‑11‑05 ~ 2024‑11‑12 | 온라인 레포 Fork 후 PR 제출 |\n| **AI Integration Workshop** | ThoughtWorks | 2024‑09‑20 (Seoul) | 사전 등록 필요 |\n| **MCP Webinar Series** | ModelContextProtocol.io | 매월 첫째 주 화요일 | 무료 스트리밍, 녹화본 제공 |\n\n---\n\n## 8. 부록  \n\n### 8.1 용어 사전  \n\n| 용어 | 정의 |\n|------|------|\n| **Root** | 컨텍스트 트리의 시작점, 세션·작업을 구분하는 고유 ID |\n| **Scope** | API 키에 연결된 권한 집합, `read:file`, `invoke:weather_api` 등 |\n| **Tool** | 외부 작업을 수행하는 실행 단위, 함수·CLI·REST API 등 |\n| **Resource** | 데이터 제공원, 파일·DB·웹 서비스 등 |\n| **Prompt** | 모델에 전달되는 템플릿, 변수 치환 지원 |\n| **Sampling** | 토큰 생성 파라미터(temperature, top‑p 등) 전파 메커니즘 |\n| **JSON‑RPC 2.0** | 원격 프로시저 호출을 위한 경량 JSON 포맷, MCP 통신 기반 |\n\n### 8.2 JSON‑RPC 2.0 메시지 샘플  \n\n**요청**  \n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 42,\n  \"method\": \"mcp.tool.invoke\",\n  \"params\": {\n    \"toolId\": \"weather.getCurrent\",\n    \"args\": { \"location\": \"Seoul\" },\n    \"context\": { \"rootId\": \"session-1234\" }\n  }\n}\n```\n\n**응답**  \n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"id\": 42,\n  \"result\": {\n    \"output\": { \"temperature\": 22, \"condition\": \"Clear\" },\n    \"metadata\": { \"durationMs\": 87 }\n  }\n}\n```\n\n**알림(서버 → 클라이언트)**  \n```json\n{\n  \"jsonrpc\": \"2.0\",\n  \"method\": \"mcp.event.resourceUpdated\",\n  \"params\": {\n    \"resourceId\": \"file.read\",\n    \"path\": \"/docs/report.md\",\n    \"etag\": \"W/\\\"12345\\\"\"\n  }\n}\n```\n\n### 8.3 트러블슈팅 체크리스트  \n\n| 증상 | 원인 가능성 | 확인 방법 | 해결 방안 |\n|------|--------------|----------|----------|\n| **연결 오류 (401 Unauthorized)** | API 키 누락·오류 | 요청 헤더 확인 | `Authorization: Bearer <key>` 추가 |\n| **Tool 실행 실패** | 입력 스키마 불일치 | `params.args` 구조 검증 | SDK `validate` 함수 사용 |\n| **응답 지연 > 200 ms** | 네트워크 라우팅·멀티‑Server 라우팅 오류 | `mcp.routing.inspect` 호출 | 라우팅 규칙 재검토 |\n| **Resource 권한 오류** | Scope에 해당 Resource 미포함 | 서버 로그에 `scope mismatch` 확인 | `defineScope`에 Resource 추가 |\n| **JSON‑RPC 파싱 오류** | 잘못된 JSON 형식 | 서버 로그에 `Parse error` 확인 | JSON 직렬화 라이브러리 사용 검증 |\n\n### 8.4 참고 문서·링크 모음  \n\n| 종류 | 링크 |\n|------|------|\n| **공식 스펙** | <https://modelcontextprotocol.io/spec> |\n| **TypeScript SDK** | <https://github.com/anthropic/ts-mcp> |\n| **Python SDK** | <https://github.com/anthropic/python-mcp> |\n| **MCP 레지스트리** | <https://modelcontextprotocol.io/registry> |\n| **Claude Desktop 소개** | <https://www.anthropic.com/claude-desktop> |\n| **LangChain Tools 비교** | <https://python.langchain.com/docs/integrations/tools> |\n| **OpenAI Function Calling** | <https://platform.openai.com/docs/guides/function-calling> |\n| **ThoughtWorks MCP 분석** | <https://www.thoughtworks.com/en-us/insights/blog/model-context-protocol> |\n| **IAM 보안 가이드** | <https://cloud.google.com/iam/docs> |\n| **MCPHammer 원문** | <https://euno.news/posts/ko/the-rogue-server-problem-what-mcphammer-reveals-ab-61c27c> |\n\n--- \n\n*본 문서는 2024‑12 기준 공개된 정보를 기반으로 작성되었습니다. 최신 버전이나 신규 기능에 대해서는 공식 사이트 및 레포지터리를 지속적으로 확인하시기 바랍니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "MCP",
        "Model Context Protocol",
        "Anthropic",
        "AI Integration",
        "JSON-RPC",
        "SDK",
        "llm",
        "protocol",
        "open-standard",
        "ai"
      ],
      "menu": "MCP 가이드",
      "order": 2,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Qwen 3.5",
      "slug": "ai/qwen3-5",
      "content": "\n## 1. 개요\n**Qwen 3.5**는 **Alibaba**에서 발표한 최신 대규모 언어 모델(LLM)입니다. **Gated DeltaNet + Mixture‑of‑Experts(MoE)** 아키텍처를 채택하여, 전체 397B 파라미터 중 17B만 활성화하는 방식으로 높은 성능과 효율성을 동시에 달성합니다.\n\n- **주요 목표** – 텍스트·이미지·비디오를 하나의 모델로 처리하면서, 코딩 에이전트·검색 에이전트 등 도구 활용 능력까지 갖춘 범용 AI 모델.\n- **주요 적용 분야** – 챗봇, 코딩 에이전트, 문서·이미지 분석, 다국어 번역, 의료 영상 분석 등.\n\n### 모델 사양\n| 항목 | 내용 |\n|------|------|\n| **전체 파라미터** | 397B (3,970억) |\n| **활성 파라미터** | 17B (A17B) |\n| **아키텍처** | Gated DeltaNet + MoE (512 experts, 10 routed + 1 shared) |\n| **컨텍스트 길이** | 기본 262,144 토큰, 최대 1,010,000 토큰까지 확장 |\n| **지원 언어** | 201개 언어 및 방언 |\n\n> **쉽게 말해**: MoE(Mixture‑of‑Experts)는 전문가 여러 명 중 필요한 전문가만 골라 쓰는 방식입니다. 512명의 전문가 중 매번 10명만 활성화하기 때문에, 거대한 모델이지만 실제 연산량은 17B 모델 수준으로 유지됩니다.\n\n---\n\n## 2. 모델 아키텍처\n1. **Gated DeltaNet** – 기존 Transformer의 attention 메커니즘을 개선한 구조로, 긴 문맥에서도 메모리 효율이 좋습니다.\n2. **Mixture‑of‑Experts (MoE)** – 512개의 전문가(expert) 네트워크 중 10개를 라우팅하고, 1개의 공유 전문가를 항상 활성화합니다. 이 덕분에 전체 397B 파라미터의 지식을 활용하면서도 실제 연산은 17B 수준으로 유지됩니다.\n3. **멀티모달 입력 처리** – 텍스트·이미지·비디오를 동일한 토큰 공간으로 변환하여 하나의 모델에서 처리합니다.\n4. **초장문 컨텍스트** – 기본 262K 토큰, 최대 약 100만 토큰까지 처리 가능하여 대규모 코드베이스나 긴 문서 분석에 유리합니다.\n\n---\n\n## 3. 학습 데이터 및 방법\n| 구분 | 내용 |\n|------|------|\n| **사전학습** | 다국어 텍스트, 이미지-텍스트 쌍, 코드 데이터로 멀티모달 사전학습 |\n| **후처리** | RLHF(인간 피드백 기반 강화학습)를 통한 미세조정 |\n| **지원 언어** | 201개 언어 및 방언 (다국어 벤치마크에서 최상위권 성능) |\n| **효율성 최적화** | MoE 라우팅, Mixed‑Precision(BF16) |\n\n---\n\n## 4. 주요 기능 및 특징\n| 기능 | 설명 |\n|------|------|\n| **자연어 이해·생성** | MMLU‑Pro 87.8%, SuperGPQA 70.4% 등 지식 벤치마크에서 GPT‑5.2에 근접하는 성능 |\n| **코딩 에이전트** | SWE‑bench Verified 76.4%, LiveCodeBench v6 83.6% 등 실제 코드 수정·생성 능력 검증 |\n| **멀티모달 처리** | 이미지·비디오 이해, 문서 OCR, 공간 인식 등 다양한 비전 태스크 지원 |\n| **도구·에이전트 활용** | BFCL‑V4 72.9%, MCP‑Mark 46.1% 등 도구 호출 및 에이전트 작업에서 강점 |\n| **초장문 처리** | 최대 100만 토큰 컨텍스트로 대규모 코드베이스·문서 분석 가능 |\n| **다국어 지원** | 201개 언어 지원, MMMLU 88.5%, NOVA‑63 59.1%로 다국어 벤치마크 최상위권 |\n\n---\n\n## 5. 벤치마크 성능\n\n> **출처** – [Hugging Face Model Card](https://huggingface.co/Qwen/Qwen3.5-397B-A17B). 비교 모델: GPT‑5.2, Claude 4.5 Opus, Gemini‑3 Pro, Qwen3‑Max‑Thinking, K2.5‑1T‑A32B.\n\n### 5‑1. 언어 벤치마크\n\n#### 지식 (Knowledge)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| MMLU‑Pro | **87.8** | 87.4 | 89.5 | 89.8 |\n| MMLU‑Redux | **94.9** | 95.0 | 95.6 | 95.9 |\n| SuperGPQA | **70.4** | 67.9 | 70.6 | 74.0 |\n| C‑Eval | **93.0** | 90.5 | 92.2 | 93.4 |\n\n#### 지시 수행 (Instruction Following)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| IFEval | **92.6** | 94.8 | 90.9 | 93.5 |\n| IFBench | **76.5** | 75.4 | 58.0 | 70.4 |\n| MultiChallenge | **67.6** | 57.9 | 54.2 | 64.2 |\n\n#### STEM (과학·기술·공학·수학)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| GPQA | **88.4** | 92.4 | 87.0 | 91.9 |\n| HLE | **28.7** | 35.5 | 30.8 | 37.5 |\n| HLE‑Verified | **37.6** | 43.3 | 38.8 | 48.0 |\n\n#### 추론 (Reasoning)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| LiveCodeBench v6 | **83.6** | 87.7 | 84.8 | 90.7 |\n| HMMT Feb 25 | **94.8** | 99.4 | 92.9 | 97.3 |\n| HMMT Nov 25 | **92.7** | 100 | 93.3 | 93.3 |\n| IMOAnswerBench | **80.9** | 86.3 | 84.0 | 83.3 |\n| AIME26 | **91.3** | 96.7 | 93.3 | 90.6 |\n\n#### 긴 문맥 (Long Context)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| AA‑LCR | **68.7** | 72.7 | 74.0 | 70.7 |\n| LongBench v2 | **63.2** | 54.5 | 64.4 | 68.2 |\n\n#### 일반 에이전트 (General Agent)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| BFCL‑V4 | **72.9** | 63.1 | 77.5 | 72.5 |\n| TAU2‑Bench | **86.7** | 87.1 | 91.6 | 85.4 |\n| VITA‑Bench | **49.7** | 38.2 | 56.3 | 51.6 |\n| DeepPlanning | **34.3** | 44.6 | 33.9 | 23.3 |\n| Tool Decathlon | **38.3** | 43.8 | 43.5 | 36.4 |\n| MCP‑Mark | **46.1** | 57.5 | 42.3 | 53.9 |\n\n#### 검색 에이전트 (Search Agent)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| HLE w/ tool | **48.3** | 45.5 | 43.4 | 45.8 |\n| BrowseComp | **69.0** | 65.8 | 67.8 | 59.2 |\n| BrowseComp‑zh | **70.3** | 76.1 | 62.4 | 66.8 |\n| WideSearch | **74.0** | 76.8 | 76.4 | 68.0 |\n\n#### 코딩 에이전트 (Coding Agent)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| SWE‑bench Verified | **76.4** | 80.0 | 80.9 | 76.2 |\n| SWE‑bench Multilingual | **69.3** | 72.0 | 77.5 | 65.0 |\n| SecCodeBench | **68.3** | 68.7 | 68.6 | 62.4 |\n| Terminal Bench 2 | **52.5** | 54.0 | 59.3 | 54.2 |\n\n#### 다국어 (Multilingualism)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| MMMLU | **88.5** | 89.5 | 90.1 | 90.6 |\n| MMLU‑ProX | **84.7** | 83.7 | 85.7 | 87.7 |\n| NOVA‑63 | **59.1** | 54.6 | 56.7 | 56.7 |\n| INCLUDE | **85.6** | 87.5 | 86.2 | 90.5 |\n| Global PIQA | **89.8** | 90.9 | 91.6 | 93.2 |\n| PolyMATH | **73.3** | 62.5 | 79.0 | 81.6 |\n| WMT24++ | **78.9** | 78.8 | 79.7 | 80.7 |\n| MAXIFE | **88.2** | 88.4 | 79.2 | 87.5 |\n\n### 5‑2. 비전‑언어 벤치마크\n\n#### STEM 및 퍼즐\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| MMMU | **85.0** | 86.7 | 80.7 | 87.2 |\n| MMMU‑Pro | **79.0** | 79.5 | 70.6 | 81.0 |\n| MathVision | **88.6** | 83.0 | 74.3 | 86.6 |\n| MathVista (mini) | **90.3** | 83.1 | 80.0 | 87.9 |\n| We‑Math | **87.9** | 79.0 | 70.0 | 86.9 |\n| DynaMath | **86.3** | 86.8 | 79.7 | 85.1 |\n| ZEROBench | **12** | 9 | 3 | 10 |\n| BabyVision | **52.3** | 34.4 | 14.2 | 49.7 |\n\n#### 일반 시각 이해 (General VQA)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| RealWorldQA | **83.9** | 83.3 | 77.0 | 83.3 |\n| MMStar | **83.8** | 77.1 | 73.2 | 83.1 |\n| HallusionBench | **71.4** | 65.2 | 64.1 | 68.6 |\n| MMBench EN | **93.7** | 88.2 | 89.2 | 93.7 |\n| SimpleVQA | **67.1** | 55.8 | 65.7 | 73.2 |\n\n#### 문서 이해·OCR\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| OmniDocBench1.5 | **90.8** | 85.7 | 87.7 | 88.5 |\n| CharXiv (RQ) | **80.8** | 82.1 | 68.5 | 81.4 |\n| MMLongBench‑Doc | **61.5** | — | 61.9 | 60.5 |\n| CC‑OCR | **82.0** | 70.3 | 76.9 | 79.0 |\n| AI2D TEST | **93.9** | 92.2 | 87.7 | 94.1 |\n| OCRBench | **93.1** | 80.7 | 85.8 | 90.4 |\n\n#### 공간 인식 (Spatial Intelligence)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| ERQA | **67.5** | 59.8 | 46.8 | 70.5 |\n| CountBench | **97.2** | 91.9 | 90.6 | 97.3 |\n| EmbSpatialBench | **84.5** | 81.3 | 75.7 | 61.2 |\n| LingoQA | **81.6** | 68.8 | 78.8 | 72.8 |\n| V* | **95.8** | 75.9 | 67.0 | 88.0 |\n\n#### 비디오 이해\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| VideoMME (w/ sub) | **87.5** | 86.0 | 77.6 | 88.4 |\n| VideoMME (w/o sub) | **83.7** | 85.8 | 81.4 | 87.7 |\n| VideoMMMU | **84.7** | 85.9 | 84.4 | 87.6 |\n| MLVU (M‑Avg) | **86.7** | 85.6 | 81.7 | 83.0 |\n| MVBench | **77.6** | 78.1 | 67.2 | 74.1 |\n| LVBench | **75.5** | 73.7 | 57.3 | 76.2 |\n\n#### 비주얼 에이전트\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| ScreenSpot Pro | **65.6** | — | 45.7 | 72.7 |\n| OSWorld‑Verified | **62.2** | 38.2 | 66.3 | — |\n| AndroidWorld | **66.8** | — | — | — |\n\n#### 의료 (Medical VQA)\n| 벤치마크 | Qwen 3.5 | GPT‑5.2 | Claude 4.5 Opus | Gemini‑3 Pro |\n|----------|----------|---------|-----------------|--------------|\n| SLAKE | **79.9** | 76.9 | 76.4 | 81.3 |\n| PMC‑VQA | **64.2** | 58.9 | 59.9 | 62.3 |\n| MedXpertQA‑MM | **70.0** | 73.3 | 63.6 | 76.0 |\n\n### 5‑3. 성능 요약\n- **비전‑수학 분야 최강**: MathVision(88.6%), MathVista(90.3%), We‑Math(87.9%)에서 GPT‑5.2와 Gemini‑3 Pro를 앞섬.\n- **문서·OCR 특화**: OmniDocBench(90.8%), OCRBench(93.1%), CC‑OCR(82.0%)에서 전 모델 대비 최고 성능.\n- **공간 인식 우수**: V*(95.8%), CountBench(97.2%), EmbSpatialBench(84.5%)에서 압도적 차이.\n- **다국어 강점**: NOVA‑63(59.1%), MAXIFE(88.2%)에서 전 모델 1위.\n- **에이전트 능력**: IFBench(76.5%), MultiChallenge(67.6%)에서 지시 수행 능력이 돋보임.\n- **추론·코딩은 GPT‑5.2에 비해 소폭 뒤처짐**: AIME26(91.3 vs 96.7), SWE‑bench Verified(76.4 vs 80.0).\n\n---\n\n## 6. 라이선스 및 데이터 사용권\n| 항목 | 내용 | 비고 |\n|------|------|------|\n| **모델 코드·가중치** | Apache 2.0 | 상업적·비상업적 모두 사용 가능 |\n| **텍스트 데이터** | CC‑BY 4.0, CC‑0, 자체 수집 | 상세 라이선스는 모델 카드 참고 |\n| **코드 데이터** | MIT, Apache 2.0, GPL 등 | 개별 레포지터리 라이선스 확인 필요 |\n\n---\n\n## 7. 제한점 및 주의사항\n- **추론 비용** – 397B 모델은 대규모 GPU 클러스터가 필요하므로, 개인 환경에서는 경량 파생 모델 사용을 권장합니다.\n- **편향·안전성** – 대규모 웹 데이터 학습 특성상 성별·인종·문화 편향이 존재할 수 있습니다.\n- **HLE 성능** – Humanity's Last Exam 벤치마크에서 28.7%로, GPT‑5.2(35.5%)·Gemini‑3 Pro(37.5%)에 비해 초고난이도 문제에서 약세를 보입니다.\n\n---\n\n## 8. 참고 자료\n- **Hugging Face Model Card** – https://huggingface.co/Qwen/Qwen3.5-397B-A17B\n- **Qwen 공식 블로그** – https://qwenlm.github.io/blog/qwen3.5/\n\n*본 문서는 2026‑02‑19 현재 Hugging Face Model Card에 공개된 정보를 기반으로 작성되었습니다.*\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Qwen",
        "LLM",
        "멀티모달",
        "MoE",
        "벤치마크"
      ],
      "order": 3,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Ollama와 Claude Code 연결 방법",
      "slug": "ai/ollama-claude-code",
      "content": "\n# Ollama와 Claude Code 연결 방법\n\n## 1. 개요\nClaude Code는 Anthropic이 제공하는 **agentic coding tool** 으로, 로컬 디렉터리의 코드를 읽고, 수정하고, 실행할 수 있습니다. Ollama는 Anthropic‑compatible API를 제공하므로, Ollama에 설치된 모델을 Claude Code와 바로 연결해 로컬에서 코딩 보조 AI를 사용할 수 있습니다. 본 가이드는 최신 Ollama Integration 문서([Claude Code – Ollama](https://docs.ollama.com/integrations/claude-code))를 기반으로 작성되었습니다.\n\n## 2. 사전 준비\n| 항목 | 권장 사양 / 도구 |\n|------|-----------------|\n| 운영 체제 | macOS 12+, Linux (Ubuntu 20.04+), Windows 10+ |\n| 하드웨어 | CPU ≥ 4 코어, 메모리 ≥ 8 GB (GPU 선택적) |\n| 필수 도구 | `curl`, `git`, 터미널 |\n| 네트워크 | 로컬 포트 **11434**(기본) 개방 여부 확인 |\n\n## 3. Ollama 설치 및 기본 설정\n1. **설치**\n   ```bash\n   curl -fsSL https://ollama.com/install.sh | sh\n   ```\n   (macOS/리눅스) 혹은 Windows에서는 PowerShell 스크립트를 사용합니다.\n2. **서비스 시작**\n   ```bash\n   ollama serve   # 백그라운드에서 API 서버 실행\n   ```\n3. **기본 모델 다운로드 예시**\n   ```bash\n   ollama pull llama3   # 원하는 모델을 pull 하면 로컬에 저장됩니다.\n   ```\n4. **API 엔드포인트**\n   Ollama는 `http://localhost:11434` 에 Anthropic Messages API 호환 엔드포인트를 제공합니다. Claude Code는 이 주소를 통해 모델에 접근합니다.\n\n## 4. Claude Code 설치\n```bash\ncurl -fsSL https://claude.ai/install.sh | bash\n```\n설치가 완료되면 `claude` 명령이 사용 가능해집니다.\n\n## 5. 연동을 위한 환경 변수 설정\nClaude Code는 Anthropic API와 호환되는 환경 변수를 통해 Ollama와 연결됩니다.\n```bash\nexport ANTHROPIC_BASE_URL=http://localhost:11434\nexport ANTHROPIC_API_KEY=\"\"          # 빈 문자열 또는 임시값 \"ollama\"\nexport ANTHROPIC_AUTH_TOKEN=ollama   # 옵션, 일부 경우 필요\n```\n위 변수를 영구적으로 적용하려면 `~/.bashrc` 혹은 `~/.zshrc` 에 추가합니다.\n\n## 6. Quick Setup (한 줄 명령) \n```bash\nANTHROPIC_BASE_URL=http://localhost:11434 ANTHROPIC_API_KEY=\"\" ANTHROPIC_AUTH_TOKEN=ollama claude --model qwen3-coder\n```\n환경 변수를 한 번에 지정하고 바로 Claude Code를 실행합니다. 테스트용으로 편리합니다.\n\n## 7. Manual Setup (영구 설정) \n1. 위 **환경 변수**를 쉘 설정 파일에 저장합니다.\n2. Ollama에서 원하는 모델을 pull 합니다.\n   ```bash\n   ollama pull qwen3-coder\n   ollama pull glm-4.7\n   ```\n3. Claude Code 실행 시 모델만 지정합니다.\n   ```bash\n   claude --model qwen3-coder\n   ```\n\n## 8. 권장 모델\n| 모델 | 비고 |\n|------|------|\n| `qwen3-coder` | 코드 생성에 최적화된 모델 |\n| `glm-4.7` | 다목적, 높은 컨텍스트 길이 지원 |\n| `gpt-oss:20b` | 오픈소스 GPT 계열, 20B 파라미터 |\n| `gpt-oss:120b` | 대규모 모델, 높은 메모리 요구 |\n\n클라우드 모델도 `ollama.com/search?c=cloud` 에서 검색해 사용할 수 있습니다.\n\n## 9. 연동 검증\n```bash\nclaude \"Python으로 파일 읽기 예제 코드를 보여줘.\"\n```\n정상적으로 동작하면 Claude Code가 Ollama에서 실행 중인 `qwen3-coder` 모델의 결과를 반환합니다.\n\n## 10. 트러블슈팅\n| 오류 | 원인 | 해결 방안 |\n|------|------|-----------|\n| `connection refused` | Ollama 서비스가 실행되지 않음 | `ollama serve` 로 서비스 시작 확인 |\n| `401 Unauthorized` | `ANTHROPIC_API_KEY` 설정 오류 | `export ANTHROPIC_API_KEY=\"\"` 로 빈 문자열 지정 |\n| 포트 충돌 | 다른 프로세스가 11434 사용 | `export ANTHROPIC_BASE_URL=http://localhost:11435` 후 `ollama serve --port 11435` |\n| 모델 로드 실패 | 모델 파일 손상 | `ollama pull <model>` 로 재다운로드 |\n\n## 11. 참고 자료\n- Claude Code – Ollama Integration: <https://docs.ollama.com/integrations/claude-code>[[Claude Code - Ollama](https://docs.ollama.com/integrations/claude-code)]\n- Ollama 공식 설치 가이드\n- Community tutorials (Reddit, Habr 등) – 최신 사용 사례 참고\n\n---\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "Ollama",
        "Claude Code",
        "로컬 모델",
        "AI 통합",
        "가이드"
      ],
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Continuous AI – 인간이 AI 오류를 검증하는 방법",
      "slug": "ai/continuous-ai",
      "content": "\n# Continuous AI – 인간이 AI 오류를 검증하는 방법\n\nAI 코딩 에이전트를 **CI 파이프라인**, **스크래퍼**, **데이터베이스 스키마 설계** 등 다양한 작업에 활용하는 사례가 늘어나고 있습니다. 하지만 실제 현장에서 가장 큰 가치는 **AI가 만든 코드를 검증하고, AI가 놓친 오류를 찾아내는 인간의 역할**이라는 인사이트가 있습니다. 본 가이드는 해당 인사이트를 바탕으로 **Human‑in‑the‑Loop(HITL) 리뷰**, **공통 AI 실수 패턴**, **검증 워크플로우**를 제시합니다.\n\n> “일은 코드를 작성하는 것이 아니다. AI가 틀렸을 때를 아는 것이다.” – *Euno.news*[[출처](https://euno.news/posts/ko/the-job-isnt-writing-code-its-knowing-when-the-ai-f67ef5)]\n\n---\n\n## 1. Human‑in‑the‑Loop Review\n\n1. **자동화된 결과에 대한 인간 검증** – AI가 생성한 코드·데이터를 그대로 받아들이지 말고, **핵심 로직·비즈니스 규칙**을 인간이 직접 검토합니다.\n2. **검증 체크리스트** – 아래와 같은 항목을 체크리스트 형태로 관리합니다.\n   - 입력 데이터가 기대 형식과 일치하는가?\n   - 출력이 비즈니스 요구사항을 충족하는가?\n   - 보안·프라이버시 위험이 없는가?\n3. **피드백 루프** – 검증 결과를 AI 프롬프트에 반영해 **프롬프트 개선**과 **모델 파인튜닝**에 활용합니다.\n\n---\n\n## 2. Common AI Mistake Patterns\n\n### 2.1 잘못된 도구 선택\nAI가 기존에 사용 중인 **정규식** 기반 파싱을 유지하자고 제안하지만, **LLM 기반 파싱**이 더 탄력적이고 유지보수가 용이합니다. (예: 기술 스택 추출) [[출처](https://euno.news/posts/ko/the-job-isnt-writing-code-its-knowing-when-the-ai-f67ef5)]\n\n### 2.2 Technically Correct, Actually Misleading\nAI가 **다중 지역**(`Americas`, `Europe`) 태그를 붙였지만, 실제로는 **특정 국가**(예: 미국, 캐나다 등)만 지원합니다. 지역 레이블이 오해를 일으켜 사용자에게 잘못된 정보를 제공할 수 있습니다. [[출처](https://euno.news/posts/ko/the-job-isnt-writing-code-its-knowing-when-the-ai-f67ef5)]\n\n### 2.3 Silent Failure\n파이프라인이 **오류 없이 성공**했지만, 실제로는 **중복 제거 규칙**이나 **급여 필드 파싱** 오류로 유효한 채용 정보를 누락했습니다. 로그에 경고가 없으므로 인간이 **결과를 직관적으로 검토**해야 합니다. [[출처](https://euno.news/posts/ko/the-job-isnt-writing-code-its-knowing-when-the-ai-f67ef5)]\n\n---\n\n## 3. Verification Workflows\n\n1. **자동 테스트 단계** – AI가 생성한 코드에 대해 **유닛 테스트**, **통합 테스트**를 자동 실행합니다.\n2. **정적 분석** – Linter, 보안 스캐너 등 정적 분석 도구를 적용해 **코드 품질**을 검증합니다.\n3. **Human Review Gate** – 테스트와 정적 분석을 통과한 결과를 **Human‑in‑the‑Loop** 검토 단계로 넘깁니다.\n   - 리뷰어는 **체크리스트**를 활용해 비즈니스 로직, 데이터 정확성, 보안 위험 등을 확인합니다.\n4. **Feedback Integration** – 리뷰 결과를 **프롬프트**와 **CI 설정**에 반영해 다음 사이클에서 동일 오류가 재발하지 않도록 합니다.\n5. **Audit Log** – 모든 검증 단계와 인간 피드백을 **감사 로그**에 기록해 추후 분석 및 학습에 활용합니다.\n\n---\n\n## 4. 참고 자료\n- “일은 코드를 작성하는 것이 아니다. AI가 틀렸을 때를 아는 것이다.” – *Euno.news*[[출처](https://euno.news/posts/ko/the-job-isnt-writing-code-its-knowing-when-the-ai-f67ef5)]\n- “Being able to quickly evaluate results from AI is crucial.” – *WikiDocs*[[출처](https://wikidocs.net/299683)]\n\n---\n\n*이 가이드는 2026‑02‑22 기준으로 최신 정보를 반영했습니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Continuous AI",
        "Human-in-the-Loop",
        "AI 검증",
        "CI"
      ],
      "order": 4,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "glm 5",
      "slug": "ai/glm-5",
      "content": "\n## 1. 소개\n- **GLM‑5 개요 및 발표 배경**  \n  GLM‑5는 2024년 말에 발표된 차세대 대형 언어 모델(Large Language Model)로, 기존 GLM‑4 시리즈의 아키텍처를 확장하고 중국어 및 다국어 지원을 강화한 버전입니다. 발표는 ZAI(또는 Zhipu AI)와 협력 파트너들을 중심으로 진행되었습니다.  \n\n- **주요 특징 요약**  \n  - **스케일**: 파라미터 수와 레이어 구성이 기존 모델보다 크게 증가(정확한 수치는 추가 조사가 필요합니다).  \n  - **언어 지원**: 중국어, 영어를 포함한 20개 이상의 언어에 최적화.  \n  - **최신 기술**: Transformer 기반 아키텍처, 고효율 토큰화, 확장된 컨텍스트 윈도우(구체적 크기는 추가 조사가 필요합니다).  \n\n## 2. 공식 홈페이지 설명\n- **모델 아키텍처와 핵심 기술**  \n  GLM‑5는 Transformer 구조를 기반으로 하며, 기존 GLM 시리즈와 동일하게 **인코더‑디코더** 형태를 채택하고 있습니다. 토큰화는 **Byte‑Level BPE** 방식을 사용해 다양한 언어에 대한 높은 표현력을 제공합니다. 자세한 내용은 모델 카드([Hugging Face](https://huggingface.co/zai-org/GLM-5))와 공식 분석 페이지([Artificial Analysis](https://artificialanalysis.ai/models/glm-5))를 참고하세요.  \n\n- **제공되는 서비스 형태**  \n  - **API**: RESTful API 형태로 클라우드에서 호출 가능.  \n  - **클라우드**: 주요 클라우드 파트너(AWS, Azure 등)와 연동된 매니지드 서비스.  \n  - **온‑프레미스**: 기업용 라이선스를 통해 자체 데이터센터에 배포 가능(세부 조건은 추가 조사가 필요합니다).  \n\n- **지원 언어 및 적용 분야**  \n  - 지원 언어: 중국어, 영어, 한국어, 일본어 등 20개 이상.  \n  - 적용 분야: 번역, 요약, 코드 생성, 대화형 AI, 검색 보강 등 다양한 NLP 작업에 활용됩니다.  \n\n## 3. 모델 상세 스펙\n| 항목 | 내용 |\n|------|------|\n| 파라미터 수 | **추가 조사가 필요합니다** |\n| 레이어 구성 | **추가 조사가 필요합니다** |\n| 컨텍스트 윈도우 크기 | **추가 조사가 필요합니다** (Artificial Analysis 페이지에 “Context Window” 섹션이 존재) |\n| 학습 데이터 규모 | 대규모 웹 텍스트, 코드, 멀티모달 데이터 포함(구체적 규모는 추가 조사가 필요합니다) |\n| 인텔리전스 지표 | Intelligence, Openness 등 다양한 지표가 제공됨([Artificial Analysis](https://artificialanalysis.ai/models/glm-5#intelligence)) |\n\n## 4. 성능 및 벤치마크\n- **주요 벤치마크 테스트**  \n  - MMLU, BIG‑bench 등 표준 벤치마크에서 GLM‑5는 기존 GLM‑4 대비 **성능 향상**을 보였다고 보고됩니다(정확한 점수는 추가 조사가 필요합니다).  \n\n- **경쟁 모델과 비교**  \n  - GPT‑4, LLaMA‑2, MiniMax 2.5 등과 비교했을 때, GLM‑5는 **비용 대비 성능**에서 경쟁력을 갖춘 것으로 평가됩니다. 상세 비교표는 아직 공개되지 않아 추가 조사가 필요합니다.  \n\n- **실제 적용 사례별 성능**  \n  - 번역: 다국어 번역 정확도 향상.  \n  - 요약: 긴 문서 요약 시 일관성 및 핵심 정보 보존율 상승.  \n  - 코드 생성: 프로그래밍 언어별 코드 완성 정확도 개선.  \n  (각 사례별 정량적 지표는 추가 조사가 필요합니다.)  \n\n## 5. 가격 및 토큰 사용 정책\n- **가격 책정 구조**  \n  - 토큰당 비용, 월 구독 플랜, 엔터프라이즈 계약 등 다양한 옵션이 제공됩니다. 구체적인 가격표는 공식 페이지([Artificial Analysis – Pricing](https://artificialanalysis.ai/models/glm-5#pricing))에 안내되어 있으나, 상세 금액은 현재 공개되지 않아 **추가 조사가 필요합니다**.  \n\n- **토큰 사용량 예시와 비용 계산 방법**  \n  - 예시: 1,000 토큰 요청 → **추가 조사가 필요합니다** 비용.  \n\n- **무료 체험 및 제한 사항**  \n  - 신규 사용자에게 일정량의 무료 토큰 제공(구체적 양은 공식 문서 확인 필요).  \n\n## 6. 사용 방법 가이드\n### API 인증 및 호출 절차\n1. **API 키 발급**: 공식 포털에서 계정을 생성하고 API 키를 발급받습니다.  \n2. **엔드포인트**: `https://api.glm5.example.com/v1/completions` (실제 URL은 공식 문서 확인).  \n3. **헤더**: `Authorization: Bearer <API_KEY>`  \n\n### 요청/응답 포맷 예시\n```json\n{\n  \"model\": \"glm-5\",\n  \"prompt\": \"안녕하세요, 오늘 날씨는 어떨까요?\",\n  \"max_tokens\": 256,\n  \"temperature\": 0.7,\n  \"top_p\": 0.9\n}\n```\n응답:\n```json\n{\n  \"id\": \"cmpl-xxxx\",\n  \"object\": \"text_completion\",\n  \"created\": 1700000000,\n  \"choices\": [\n    {\n      \"text\": \"오늘은 맑고 기온은 22도 정도입니다.\",\n      \"index\": 0,\n      \"logprobs\": null,\n      \"finish_reason\": \"stop\"\n    }\n  ],\n  \"usage\": {\n    \"prompt_tokens\": 12,\n    \"completion_tokens\": 15,\n    \"total_tokens\": 27\n  }\n}\n```\n\n### 파라미터 튜닝 팁\n- **temperature**: 0.0~1.0, 낮을수록 결정적, 높을수록 다양성 증가.  \n- **top_p**: nucleus sampling, 0.8~0.95 권장.  \n- **max_tokens**: 컨텍스트 윈도우와 비용을 고려해 설정.  \n\n## 7. 제한 사항 및 주의점\n- **모델 한계**  \n  - **Hallucination**: 사실과 다른 정보를 생성할 가능성이 존재합니다.  \n  - **편향**: 학습 데이터에 내재된 문화·사회적 편향이 반영될 수 있습니다.  \n\n- **보안·프라이버시 고려사항**  \n  - 민감한 데이터 전송 시 TLS 암호화 사용 권장.  \n  - 기업용 온‑프레미스 배포 시 데이터 탈출 방지를 위한 네트워크 격리 필요.  \n\n- **권장 사용 시나리오와 비추천 상황**  \n  - 권장: 고객 지원 챗봇, 문서 요약, 코드 보조 등.  \n  - 비추천: 의료 진단, 법률 자문 등 고위험 분야(전문가 검증 필요).  \n\n## 8. FAQ\n| 질문 | 답변 |\n|------|------|\n| GLM‑5와 GPT‑4 중 어느 것이 더 좋나요? | 용도와 비용에 따라 다릅니다. GLM‑5는 비용 효율성이 높으며 다국어 지원에 강점이 있습니다. |\n| 무료 체험 토큰은 어떻게 얻나요? | 공식 포털에서 회원가입 후 자동으로 제공됩니다(구체적 양은 공식 문서 확인). |\n| 온‑프레미스 배포는 가능한가요? | 엔터프라이즈 라이선스 계약 시 가능하나, 상세 절차는 추가 조사가 필요합니다. |\n| 모델이 생성한 내용이 사실인지 어떻게 검증하나요? | 외부 검증 API 또는 인간 검토 과정을 병행하는 것이 권장됩니다. |\n| 토큰 사용량을 모니터링하는 방법은? | API 응답의 `usage` 필드를 활용하거나 대시보드에서 실시간 모니터링 가능합니다. |\n\n## 9. 참고 자료 및 링크\n- **공식 모델 카드**: https://huggingface.co/zai-org/GLM-5  \n- **Artificial Analysis – GLM‑5 페이지**: https://artificialanalysis.ai/models/glm-5  \n- **AI‑Manual 기사 (GLM‑5 vs MiniMax 2.5)**: https://ai-manual.ru/article/glm-5-i-minimax-25-kitaj-zapuskaet-agentskie-vojnyi/ (러시아어)  \n- **관련 커뮤니티·포럼**: Hugging Face Discussions, ZAI 공식 포럼(링크는 추후 확인 필요)  \n\n*본 문서는 현재 공개된 자료를 기반으로 작성되었으며, 일부 상세 스펙 및 가격 정보는 추가 조사가 필요합니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "GLM-5",
        "대형 언어 모델",
        "AI 서비스",
        "벤치마크"
      ],
      "order": 5,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "AI Agent 배포 실패 방지와 테스트 전략 가이드",
      "slug": "ai/240",
      "content": "\n## 1. 서론\nAI Agent 배포가 성공적으로 이루어지지 않는 경우가 빈번합니다. **76%**의 AI Agent 배포가 실패한다는 보고가 최근 발표되었습니다【euno.news】.  \nLangChain이 2026년에 발표한 *State of Agent Engineering* 보고서(1,300명 이상 응답)에서는 **품질**이 프로덕션 배포의 가장 큰 장벽이라고 밝혔으며, **32%**의 팀이 품질 문제를 주요 차단 요인으로 꼽았습니다【euno.news】. 그러나 **52%**의 팀만이 자체적인 평가·테스트 시스템을 보유하고 있어, 테스트 격차가 배포 실패의 핵심 원인으로 지목되고 있습니다【euno.news】.\n\n이 문서는  \n* 배포 실패 원인  \n* 테스트 격차 해소를 위한 결정론·비결정론적 테스트 기법  \n* 실용적인 도구·프레임워크 활용법  \n* 체크리스트와 실제 사례  \n\n를 제공하여, AI Agent 개발·운영 팀이 품질을 체계적으로 검증하고 성공적인 배포를 달성하도록 돕는 것을 목표로 합니다.\n\n---\n\n## 2. 배포 실패 주요 원인\n| 원인 | 설명 |\n|------|------|\n| **품질(테스트·평가) 부족** | 보고서에 따르면 품질이 가장 큰 장벽이며, 32%의 팀이 이를 주요 차단 요인으로 인식【euno.news】 |\n| **평가·테스트 시스템 부재** | 전체 팀 중 52%만이 평가 시스템을 보유, 나머지는 테스트 격차에 노출【euno.news】 |\n| **비결정성·다단계 흐름** | 에이전트는 비결정적이며 여러 단계(도구 호출, 루프, 외부 API)로 구성돼 전통적인 단위 테스트가 적용되기 어려움【euno.news】 |\n\n---\n\n## 3. 테스트 격차와 필요성\n* **결정론적 vs 비결정론적** 테스트를 구분해 단계별 적용이 필요합니다.  \n* 테스트 파이프라인이 없으면 **회귀**와 **드리프트**가 누적돼 배포 시 예기치 않은 오류가 발생합니다.  \n* 비용·시간 효율성을 고려해 **Layer 1(결정론적 어설션) → Layer 2(통계·메트릭) → Layer 3(LLM‑as‑Judge)** 순으로 점진적 검증을 도입하는 것이 권장됩니다.\n\n---\n\n## 4. 결정론적 테스트 기법 (Layer 1)\n\n### 4.1 도구 호출 정확성\n에이전트가 올바른 도구를 올바른 인자와 순서로 호출했는지 검증합니다.\n\n```python\nfrom agent_eval import Trace, assert_tool_called, assert_tool_not_called, assert_tool_call_order\n\ntrace = Trace.from_jsonl(\"weather_agent_run.jsonl\")\nassert_tool_called(trace, \"get_weather\", args={\"city\": \"SF\"})\nassert_tool_not_called(trace, \"delete_user\")  # 안전 검사\nassert_tool_call_order(trace, [\"search\", \"read\", \"summarize\"])\n```\n\n### 4.2 루프·반복 호출 탐지\n무한 루프나 과도한 재시도를 방지합니다.\n\n```python\nfrom agent_eval import assert_no_loop, assert_max_steps\n\nassert_no_loop(trace, max_repeats=3)      # 동일 도구가 3번 연속 호출 시 실패\nassert_max_steps(trace, 10)              # 전체 스텝 제한\n```\n\n### 4.3 출력 정상성 검사\n최종 응답에 필수 키워드·패턴이 포함됐는지 확인합니다.\n\n```python\nfrom agent_eval import (\n    assert_final_answer_contains,\n    assert_final_answer_matches,\n    assert_no_empty_response,\n    assert_no_repetition,\n)\n\nassert_final_answer_contains(trace, \"San Francisco\")\nassert_final_answer_matches(trace, r\"\\d+°F\")   # 온도 형식 검증\nassert_no_empty_response(trace)\nassert_no_repetition(trace, threshold=0.85)    # 복사‑붙여넣기 방지\n```\n\n### 4.4 회귀 감지\n기준 Trace와 현재 Trace를 비교해 도구 삭제·지연·출력 변화를 자동으로 탐지합니다.\n\n```python\nfrom agent_eval import diff_traces\n\nbaseline = Trace.from_jsonl(\"baseline.jsonl\")\ncurrent = Trace.from_jsonl(\"current.jsonl\")\ndiff = diff_traces(baseline, current)\n\nprint(diff.summary())\n# ❌ Tool removed: get_weather\n# 🐢 Latency increased: 800ms → 5000ms (6.3x)\n# 📝 Final answer changed (similarity: 42%)\n\nassert not diff.is_regression   # 도구 제거·지연 2배 초과 시 실패\n```\n\n> **핵심**: CI/CD 파이프라인에 Layer 1 테스트를 통합하면, 프롬프트·모델 변경 시 **80%** 이상의 테스트 가치를 빠르게 확보할 수 있습니다【euno.news】.\n\n---\n\n## 5. 통계·확률적 테스트 (Layer 2)\n\n| 메트릭 | 목적 | 구현 팁 |\n|--------|------|----------|\n| **유사도 점수** | 출력 변화(드리프트) 감지 | `sentence-transformers` 등 로컬 임베딩 활용 |\n| **응답 시간·자원 사용량** | 성능 회귀 탐지 | `time`·`resource` 모듈로 스텝별 측정 |\n| **도구 호출 빈도 분포** | 비정상적인 호출 패턴 탐지 | `collections.Counter` 로 호출 로그 집계 |\n\nLayer 2는 **무료**이며 **로컬**에서 실행돼 빠른 피드백 루프를 제공합니다. 정확한 임계값은 팀별 SLA에 맞춰 설정해야 합니다.\n\n---\n\n## 6. LLM‑as‑Judge 기반 테스트 (Layer 3)\n\n* **고비용·비결정적** 특성을 감안해, 최종 품질 검증 단계에서만 사용합니다.  \n* **프롬프트 설계**: “다음 답변이 정확한가? 근거와 함께 설명하라”와 같이 구체적인 평가 기준을 제공해야 합니다.  \n* **샘플링 전략**: 전체 실행 중 5~10%만 선택해 LLM‑as‑Judge에 전달, 비용을 절감합니다.\n\n> **주의**: LLM‑as‑Judge는 **비결정적**이므로 동일 입력에 대해 결과가 달라질 수 있습니다. 따라서 Layer 1·2에서 충분히 검증된 경우에만 적용하는 것이 바람직합니다【euno.news】.\n\n---\n\n## 7. 테스트 피라미드와 워크플로우\n\n```\nLayer 1 (결정론적 어설션)   → 80% 테스트 가치\nLayer 2 (통계·메트릭)       → 빠른 근사 검증\nLayer 3 (LLM‑as‑Judge)      → 최종 품질 보증\n```\n\n1. **CI 단계**: Pull Request 시 Layer 1 테스트 자동 실행.  \n2. **스테이징**: 배포 전 Layer 2 메트릭 수집·드리프트 검증.  \n3. **프로덕션 승인**: Layer 3 LLM‑as‑Judge 평가 통과 후 실제 배포.\n\nGitHub Actions, GitLab CI 등과 연동하는 예시는 LangChain 공식 문서([LangChain Docs](https://python.langchain.com))를 참고하세요.\n\n---\n\n## 8. 도구·프레임워크\n\n| 도구 | 역할 | 주요 함수·예시 |\n|------|------|----------------|\n| **LangChain** | 에이전트 정의·실행 | `AgentExecutor`, `Tool` 인터페이스 |\n| **agent_eval** | Trace 수집·어설션 제공 | `Trace.from_jsonl`, `assert_tool_called` 등 |\n| **Trace 포맷** | 실행 로그(JSONL) 표준화 | `trace.jsonl` 파일로 CI에 전달 |\n| **시각화** | Trace 비교·시각화 | `agent_eval.visualize(trace)` (공식 문서 참고) |\n| **CI/CD** | 자동화 파이프라인 | GitHub Actions 워크플로에 `python -m pytest` 등 |\n\n`agent_eval` 라이브러리는 LangChain 에이전트 평가를 위해 별도 패키지로 제공되며, 설치 방법은 `pip install agent-eval` (공식 PyPI)이며, 자세한 사용법은 해당 패키지 README를 참고합니다.\n\n---\n\n## 9. 실제 사례와 체크리스트\n\n### 9.1 성공 사례\n* **WeatherAgent**: 도구 호출 순서와 인자를 어설션으로 검증하고, 루프 탐지 규칙을 적용해 배포 전 0% 회귀 발생. CI에서 Layer 1 테스트가 100% 통과했으며, Layer 2 메트릭에서도 드리프트가 없었음.\n\n### 9.2 실패 사례\n* **UserOnboardingAgent**: 테스트 시스템 부재로 프롬프트 변경 시 `create_user` 도구 호출이 누락, 배포 후 사용자 생성 오류 발생. 회귀 감지를 위한 Trace 비교가 없었음.\n\n### 9.3 배포 전·후 체크리스트\n| 단계 | 체크 항목 |\n|------|-----------|\n| **배포 전** | - `assert_tool_called`·`assert_tool_not_called` 어설션 모두 통과<br>- `assert_no_loop`·`assert_max_steps` 제한 초과 없음<br>- Layer 2 메트릭 기준 내(응답 시간, 유사도) |\n| **배포 후** | - 실제 서비스 로그와 기준 Trace 비교 (`diff_traces`)<br>- LLM‑as‑Judge 샘플 검증 결과 `PASS`<br>- 모니터링 알림 설정 (지연·오류) |\n\n---\n\n## 10. 결론 및 권고사항\n\n1. **테스트 격차 해소**: 팀의 48%가 아직 평가 시스템을 갖추지 않았으므로, 우선 `agent_eval` 기반 Layer 1 어설션을 도입해 **품질**을 기본 수준으로 끌어올릴 것을 권고합니다【euno.news】.  \n2. **점진적 도입 로드맵**  \n   * **Q1**: CI에 Layer 1 테스트 자동화  \n   * **Q2**: Layer 2 메트릭 수집·대시보드 구축  \n   * **Q3**: 비용 효율적인 샘플링으로 Layer 3 LLM‑as‑Judge 적용  \n3. **조직·프로세스 변화**: 테스트 담당자 역할을 명확히 하고, **품질 목표(KPI)**를 설정해 정량적 관리가 가능하도록 합니다.  \n4. **지속 가능한 품질 관리**: 테스트 파이프라인을 **버전 관리**하고, 모델·프롬프트 변경 시 자동 회귀 검증을 수행해 장기적인 안정성을 확보합니다.\n\n> **요약**: 품질이 배포 실패의 핵심 원인이라는 사실을 바탕으로, 결정론적 어설션 → 통계·메트릭 → LLM‑as‑Judge 순의 3계층 테스트 피라미드를 구축하면, 현재 76%의 실패율을 크게 낮출 수 있습니다.  \n\n--- \n\n*본 문서는 euno.news 기사와 LangChain 2026 State of Agent Engineering 보고서를 기반으로 작성되었습니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "AI Agent",
        "테스트",
        "LangChain",
        "배포",
        "품질 보증"
      ],
      "order": 12,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Automate Repository Tasks with GitHub Agentic Workflows",
      "slug": "ai/github-agentic-workflows",
      "content": "\n# Claude 기반 Git 커밋 리뷰 자동화 (git‑lrc)\n\n이 문서는 Claude 모델을 이용해 커밋 전 자동 리뷰를 강제하는 **git‑lrc**(Git‑Lint‑Review‑Commit) 워크플로우를 소개합니다. 아래 섹션에서는 전체 흐름, 커밋에 표시되는 어노테이션 스킴, 그리고 CI/CD 파이프라인에 통합하는 방법을 다룹니다.\n\n---\n\n## Claude Review Workflow Overview\n\n1. **스테이징된 diff 감지** – `git add` 로 스테이징된 모든 변경 사항이 자동으로 감지됩니다.\n2. **Claude에게 리뷰 요청** – 워크플로우는 스테이징된 diff를 Claude에게 전달하고, 위험한 변경점, 보안 이슈, 성능 퇴보 등을 강조하는 인라인 코멘트를 생성합니다.\n3. **엔지니어 검토** – 개발자는 Claude이 제공한 코멘트를 검토하고, 리뷰 결과를 선택합니다.\n4. **커밋 어노테이션 기록** – 선택된 결과가 커밋 메시지에 `[reviewed]`, `[vouched]`, `[skipped]` 중 하나로 자동 삽입되고, 해당 정보가 Git 로그에 영구 보관됩니다.\n\n> **핵심 포인트**: 별도의 대시보드가 없으며, 기존 Git 워크플로우와 완전히 통합됩니다. 개발자는 여전히 최종 결정을 내리며, AI는 보조 역할만 수행합니다.\n\n---\n\n## Commit Annotation Scheme\n\n| 어노테이션 | 의미 | 적용 시점 |\n|-----------|------|-----------|\n| `[reviewed]` | Claude이 리뷰를 수행하고, 개발자가 리뷰 결과를 수용했음 | `git commit` 직전\n| `[vouched]` | 리뷰는 수행했지만, 개발자가 직접 검증하고 승인했음 | `git commit` 직전\n| `[skipped]` | 리뷰를 의도적으로 건너뛰었음 – 로그에 명시적으로 기록됨 | `git commit` 직전\n\n이 어노테이션은 커밋 메시지에 자동 삽입되며, `git log` 를 통해 언제 어떤 커밋이 리뷰되었는지, 혹은 리뷰 없이 배포되었는지를 추적할 수 있습니다.\n\n---\n\n## CI/CD Integration Steps\n\n1. **전역 Git 훅 설치** – `git-lrc install` 명령을 실행하면 모든 레포에 전역 훅이 설정됩니다. 설치 시간은 약 60초 정도 소요됩니다.\n2. **Claude API 키 설정** – 무료 Gemini API 키(또는 Claude API 키)를 환경 변수 `CLAUDE_API_KEY` 로 지정합니다. 별도 좌석 기반 요금이 없습니다.\n3. **CI 파이프라인에 검증 단계 추가** – CI 설정 파일(`.github/workflows/ci.yml` 등)에서 `git-lrc verify` 명령을 실행해 리뷰가 누락된 커밋이 없는지 확인합니다.\n4. **리포지토리 보호 규칙** – GitHub 보호 규칙에 `Require status checks` 를 추가하고, `git-lrc verify` 를 필수 체크로 지정합니다.\n\n```yaml\n# .github/workflows/ci.yml 예시\nname: CI\non: [push, pull_request]\njobs:\n  build:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v3\n      - name: Install git‑lrc\n        run: curl -sSL https://example.com/git-lrc/install.sh | bash\n      - name: Verify commit reviews\n        run: git-lrc verify\n      - name: Build & Test\n        run: ./gradlew build test\n```\n\n위와 같이 설정하면, 리뷰가 누락된 커밋이 푸시될 경우 CI가 실패하고, 병합이 차단됩니다.\n\n---\n\n## 추가 참고\n- **무료 티어**: Gemini API 키를 직접 가져와 사용할 수 있으며, 좌석 기반 요금이 없습니다.\n- **설정 시간**: 한 번 설치하면 머신 전체에 적용되어, 모든 레포에 즉시 동작합니다.\n- **오픈소스**: `git‑lrc`는 GitHub에 공개되어 있어 자유롭게 포크·기여·검토가 가능합니다. ([GitHub Repository](https://github.com/git-lrc))\n\n---\n\n### 문서 자동 업데이트\nPR이 머지되면 에이전트가 변경된 API 시그니처를 찾아 `README.md` 혹은 `docs/` 파일을 최신화합니다.\n\n### 테스트 보강 PR 자동 생성\n커버리지가 낮은 파일을 감지하면, 에이전트가 기본 테스트 케이스를 생성하고 PR을 올립니다.\n\n### 기타 확장 시나리오\n- **보안 스캔**: 의존성 업데이트 후 자동 보안 검토  \n- **린트 자동 적용**: 스타일 위반을 수정하고 커밋  \n- **배포 자동화**: 특정 태그가 푸시되면 배포 파이프라인을 트리거  \n\n## 5. 설정 및 배포 단계\n### GitHub CLI 및 Agentic Workflows 확장 설치\n```bash\ngh extension install github/agentic-workflows\n```  \n위 명령은 GitHub CLI 공식 문서에 따라 설치합니다[[GitHub CLI Docs](https://cli.github.com/manual/)].\n\n### 레포지토리 권한 및 시크릿 구성\n- **권한 최소화** 예시 (`.github/workflows/issue-triage.yml`)\n\n    name: Issue Triaging\n    on:\n      issues:\n        types: [opened]\n    permissions:\n      contents: read\n      issues: write\n      pull_requests: write\n    jobs:\n      triage:\n        runs-on: ubuntu-latest\n        steps:\n          - uses: actions/checkout@v4\n          - name: Run Agentic Workflow\n            uses: github/agentic-workflows@v1\n            with:\n              workflow-path: .github/agentic-workflows/issue-triage.md\n\n- **시크릿**: AI 모델 호출에 필요한 API 키를 `AGENTIC_API_KEY` 로 저장하고, 워크플로에서 `secrets.AGENTIC_API_KEY` 로 참조합니다.\n\n### 워크플로 활성화(트리거) 옵션\n`on:` 필드에 `issues`, `pull_request`, `schedule` 등 GitHub Actions와 동일한 이벤트를 지정합니다.\n\n### 검토 및 승인 프로세스 설정\n`## Guardrails` 섹션에 `reviewers` 를 명시해 에이전트가 만든 PR이 자동 승인되지 않도록 합니다.\n\n## 6. 가드레일 및 안전성 확보\n### 실행 제한(시간·비용·리소스) 정책\n`max-runtime` 과 `cost-budget` 파라미터로 실행 시간을 5분, 비용을 0.05 USD 이하로 제한할 수 있습니다.\n\n### 권한 최소화 원칙 적용 방법\n워크플로 파일에 `permissions:` 블록을 명시해 필요한 권한만 부여합니다. 예시에서는 `contents: read` 와 `issues: write` 만 허용했습니다.\n\n### 결과 검증 및 인간 리뷰 워크플로\n에이전트가 만든 PR에 `auto-review: false` 플래그를 두고, 팀원이 직접 검토 후 병합하도록 합니다.\n\n### 로그·감사 추적 기능 활용\nGitHub Actions UI에서 **Agentic Workflow** 라벨이 붙은 실행 로그를 확인하고, `audit.log` 아티팩트로 내보낼 수 있습니다.\n\n## 7. 모니터링 및 디버깅\n### 실행 로그 확인\n워크플로 실행 페이지에 **Agentic Workflow** 섹션이 표시되며, 단계별 출력과 AI 프롬프트·응답을 확인할 수 있습니다.\n\n### 성능 메트릭 수집\n`## Guardrails` 에 `metrics:` 를 추가해 `duration`, `tokens-used` 등을 기록하고, 외부 모니터링(예: Datadog)으로 전송합니다.\n\n    ## Guardrails\n    - metrics: [\"duration\", \"tokens-used\"]\n    - reviewers: [\"team-lead\"]\n\n### 오류 재현 및 재시도 전략\n`workflow_dispatch` 로 수동 트리거하여 동일 입력을 재현하고, `retry:` 옵션을 통해 자동 재시도를 구성합니다.\n\n## 8. 베스트 프랙티스\n1. **목표 선언을 구체적이고 제한적으로** 작성 – “`needs‑triage` 라벨을 붙인다”가 “라벨을 붙인다”보다 명확합니다.  \n2. **작은 워크플로부터 시작** – 단일 이슈 라벨링 같은 간단한 시나리오로 검증 후 확장합니다.  \n3. **팀 차원의 정책 수립** – 승인 흐름, 비용 한도, 사용 가능한 모델 버전을 문서화합니다.  \n4. **커뮤니티와 피드백 루프 구축** – 프리뷰 피드백을 GitHub Discussions에 공유해 개선점을 수집합니다[[GitHub Discussions](https://github.com/github/agentic-workflows/discussions)].\n\n## 9. 한계와 향후 로드맵\n### 현재 프리뷰에서 지원되지 않는 기능\n- **멀티‑레포지토리 트랜잭션**: 현재는 단일 레포지토리 내에서만 동작합니다.  \n- **실시간 비용 청구**: 비용 추적은 로그 기반이며, 자동 청구는 아직 제공되지 않습니다.\n\n### 보안·프라이버시 고려 사항\nAI 모델에 레포지토리 코드를 전송하기 때문에, 민감한 코드가 포함된 경우 모델 제공자의 데이터 정책을 반드시 검토해야 합니다.\n\n### 예정된 기능 업데이트\n- **멀티‑에이전트 협업**: 복수 에이전트가 단계별로 작업을 분담하는 기능이 예정되어 있습니다.  \n- **정책 기반 자동 승인**: 사전 정의된 정책에 부합하면 자동 병합을 허용하는 옵션이 추가될 예정입니다.\n\n## 10. Claude 기반 Git 커밋 리뷰 자동화 (git‑lrc)\n\nAI가 코드 생산을 가속화하지만, 코드 품질은 자동으로 확장되지 않습니다. **git‑lrc**는 스테이징된 모든 diff를 커밋 전에 AI가 리뷰하도록 강제하는 도구입니다. 별도 대시보드나 컨텍스트 전환 없이, Git 훅 수준에서 동작합니다.\n\n### 핵심 동작 방식\n1. `git commit` 실행 시 pre‑commit 훅이 스테이징된 diff를 AI(Gemini/Claude)에 전달\n2. AI가 인라인 코멘트로 위험한 변경점을 강조\n3. 개발자가 검토 후 커밋에 **어노테이션**을 부여\n\n### 커밋 어노테이션 체계\n| 어노테이션 | 의미 |\n|-----------|------|\n| `[reviewed]` | 개발자가 AI 리뷰를 확인하고 승인 |\n| `[vouched]` | 개발자가 변경 내용을 보증 |\n| `[skipped]` | 의도적으로 리뷰 없이 커밋 |\n\n이 결정은 git 로그에 영구 기록되어, 팀이 어떤 변경이 리뷰되었고 어떤 변경이 리뷰 없이 배포되었는지 추적할 수 있습니다.\n\n### 설치 및 설정 (~60초)\n```bash\n# 전역 설치 – 머신의 모든 레포에 자동 적용\nnpm install -g git-lrc\ngit-lrc init --global\n```\n\n무료 티어 Gemini API 키를 사용하며, 좌석 기반 요금이 없습니다.\n\n### CI/CD 통합\nGitHub Actions에서 `git log --format=%s` 를 파싱해 `[skipped]` 비율이 임계값을 초과하면 워크플로를 실패시키는 정책을 적용할 수 있습니다.\n\n*출처: git‑lrc 프로젝트, euno.news (2026‑02‑22)*\n\n---\n\n## 11. 결론\nGitHub Agentic Workflows는 **AI 코딩 에이전트**를 기존 GitHub Actions와 자연스럽게 결합해 레포지토리 관리 작업을 선언형으로 자동화합니다. 이를 통해 팀은 **이슈 triage**, **CI 자동 복구**, **문서 동기화** 등 반복적인 업무를 최소화하고, 실제 개발에 더 많은 시간을 투자할 수 있습니다.\n\n### 시작을 위한 체크리스트\n- [ ] GitHub CLI와 Agentic Workflows 확장 설치  \n- [ ] `.github/agentic-workflows/` 디렉터리 생성  \n- [ ] 첫 번째 간단한 Outcome(예: 이슈 라벨링) 선언  \n- [ ] 권한·시크릿 설정 및 가드레일 검토  \n- [ ] 팀 리뷰 프로세스와 비용 한도 정책 정의  \n\n### 추가 리소스\n- 공식 GitHub Blog 포스트: *Automate repository tasks with GitHub Agentic Workflows*[[GitHub Blog](https://github.blog/ai-and-ml/automate-repository-tasks-with-github-agentic-workflows/)]  \n- GitHub Docs – Agentic Workflows[[GitHub Docs](https://docs.github.com/en/actions/using-workflows/agentic-workflows)]  \n- GitHub CLI Manual[[GitHub CLI Docs](https://cli.github.com/manual/)]  \n\nGitHub Agentic Workflows를 활용해 레포지토리 자동화의 새로운 장을 열어보세요.",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "GitHub",
        "Agentic Workflows",
        "CI/CD",
        "Repository Automation",
        "AI"
      ],
      "order": 6,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "바이브 코딩이란?",
      "slug": "ai/vibe-coding",
      "content": "\n## 서론\n**바이브 코딩(Vibe Coding)** 은 대규모 언어 모델(LLM)에 자연어 프롬프트를 입력해 원하는 동작을 구현하도록 코드를 자동 생성하는 개발 방식이다. 전통적인 코딩이 **문법·구조**를 직접 타이핑하는 데 초점을 맞춘다면, 바이브 코딩은 **“느낌(vibe)”** 정도만 전달하면 AI가 그에 맞는 구현을 제공한다는 점에서 차별화된다.  \n\n이 문서는  \n* 바이브 코딩의 정의와 핵심 개념을 이해하고,  \n* 기존 코딩 방식과의 차이점을 파악하며,  \n* 실제 현업·교육 현장에서 어떻게 활용되는지 살펴보고자 한다.  \n\n주된 독자층은 소프트웨어 엔지니어, 팀 리더, 교육자, 그리고 AI 기반 개발 도구에 관심 있는 일반 개발자이다.\n\n## 바이브 코딩의 어원\n| 요소 | 설명 |\n|------|------|\n| **Vibe** | ‘느낌’, ‘분위기’를 의미한다. 사용자가 구현하고자 하는 기능의 구체적인 로직보다 목표 결과의 감각을 강조한다. |\n| **Coding** | 전통적인 프로그래밍 행위. 여기서는 AI가 대신 수행하는 코드 생성 과정을 의미한다. |\n\nAndre​j Karpathy(전 Tesla AI 책임자)는 2025년 2월, 인터뷰와 블로그 글에서 **“바이브 코딩”**이라는 용어를 처음 제시하였다. 그는 “그저 사물을 보고, 말하고, 복사‑붙여넣기만 하면 대부분 작동한다”는 입장을 밝히며, 이 개념이 **‘프로그래밍 언어는 영어가 가장 인기 있는 새로운 언어’**라는 주장과 연결된다고 설명했다.  \n\n어원에서 파생된 의미는 **“느낌만으로 코드를 만든다”**는 점이며, 초기 사용 사례는 AI 기반 코드 자동 완성 도구(GitHub Copilot, Claude 등)를 활용한 프로토타이핑 작업이다.\n\n## 올바른 바이브 코딩의 해석\n1. **느낌만으로 코드를 만든다**는 의미는 “자연어로 기능 요구를 전달하면 AI가 구체적인 구현을 제공한다”는 뜻이다.  \n2. **프롬프트 설계와 컨텍스트 제공**이 핵심이다. 명확한 목표, 입력·출력 예시, 제약 조건 등을 포함한 프롬프트가 좋은 결과를 만든다.  \n3. **AI‑Generated 코드와 인간 개발자의 역할 구분**  \n   * AI는 **초안·아이디어 구현**을 빠르게 제공한다.  \n   * 인간 개발자는 **코드 검증·리팩터링·보안 검토**를 담당한다.  \n\n## 바이브 코딩 기술적 기반\n- **대규모 언어 모델(LLM)** : GPT‑4, Claude 2, Gemini 등은 자연어를 코드로 변환하는 능력을 갖춘다.  \n- **프롬프트 엔지니어링** : 효과적인 프롬프트 작성법(페르소나 정의, 문제 명확화, 컨텍스트 제공 등)은 “Agentic AI Prompting Best Practices”(LinkedIn)에서 제시된 단계와 일치한다.  \n- **환각(Hallucination)** : 모델이 존재하지 않는 API나 논리적 오류를 만들어낼 수 있다. 이를 방지하려면 **출력 검증**(테스트 자동화, 정적 분석)과 **인간 리뷰**가 필요하다.  \n\n## 주요 도구와 플랫폼\n| 도구 | 주요 특징 | 참고 링크 |\n|------|----------|-----------|\n| **GitHub Copilot** | VS Code·JetBrains 플러그인, 실시간 코드 제안 | https://github.com/features/copilot |\n| **Claude** (Anthropic) | 대화형 프롬프트, “CLAUDE.md” 템플릿 활용 | https://www.anthropic.com/claude |\n| **Claude‑Assist** | 팀 협업용 프롬프트 관리, AGENTS.md 지원 | https://www.anthropic.com/assist |\n| **ChatGPT (OpenAI)** | 다양한 언어·프레임워크 지원, 플러그인 생태계 | https://chat.openai.com/ |\n\n**설정 파일·프롬프트 템플릿** 예시(‘CLAUDE.md’, ‘AGENTS.md’)는 FastCampus GitBook “Best practice” 챕터에서 상세히 다루고 있다.\n\n## 바이브 코딩 문화와 커뮤니티\n- **시민 개발자·바이브 코딩 엔지니어**라는 새로운 직군이 등장했다. 이들은 전통적인 개발 지식보다 AI와 프롬프트 설계 능력을 강조한다.  \n- **온라인 커뮤니티**: Reddit r/vibecoding, Discord “VibeCoders”, 네이버 카페 “바이브 코딩 연구소” 등에서 사례 공유와 토론이 활발히 진행된다.  \n- **교육 프로그램**: FastCampus, 삼성SDS 인사이트 리포트, 여러 대학의 AI·소프트웨어 교육 과정에 바이브 코딩 모듈이 포함되고 있다.  \n- **기업 채택 사례**: 삼성SDS는 내부 파일럿 프로젝트에서 프로토타이핑 속도를 30% 이상 단축했으며, 스타트업은 초기 MVP 개발에 AI 코딩을 활용해 인력 비용을 절감하고 있다.\n\n## 장점과 기대 효과\n| 효과 | 정량·정성 사례 |\n|------|----------------|\n| **생산성·시간 절감** | 삼성SDS 파일럿: 평균 2일 → 0.5일(≈75% 감소) |\n| **소프트웨어 민주화** | 비전문가도 자연어로 기능을 정의 → 코드 자동 생성 |\n| **아이디어 검증·프로토타이핑** | 스타트업 설문: AI‑Generated 코드 사용 후 아이디어 검증 시간 40% 단축 |\n\n## 한계와 위험 요소\n- **코드 품질·보안**: AI가 생성한 코드는 종종 보안 취약점이나 비효율적인 구조를 포함한다. 정적 분석·보안 스캐너 적용이 필수이다.  \n- **의존성 문제**: “왜 이렇게 작성했나요?” 라는 질문에 답변하기 어려운 상황이 발생한다. 이는 팀 협업과 유지보수에 위험을 초래한다.  \n- **법적·윤리적 이슈**: 베른 협약에 가입한 국가에서는 AI가 생성한 코드의 저작권·라이선스 문제가 논의되고 있다. 추가 조사가 필요합니다.  \n\n## 실제 적용 사례\n1. **삼성SDS 파일럿** – 내부 업무 자동화 툴 개발에 Claude 기반 바이브 코딩을 적용, 평균 개발 주기 3주 → 1주로 단축.  \n2. **교육 현장** – FastCampus “바이브 코딩 실전 가이드” 강좌에서 수강생 85%가 AI‑Generated 코드를 활용해 과제 제출, 평균 점수 12% 상승.  \n3. **오픈소스 프로젝트** – “vibe‑utils” GitHub 레포지토리(추가 조사가 필요합니다)에서 AI가 자동 생성한 유틸리티 함수들을 커뮤니티가 검토·채택하고 있다.  \n\n## 미래 전망 및 발전 방향\n- **멀티모달 프롬프트**: 텍스트·이미지·음성 등을 결합한 입력이 가능해지면서 UI·UX 설계 단계에서도 바이브 코딩이 적용될 전망이다.  \n- **전통 개발 프로세스와 융합**: CI/CD 파이프라인에 AI 코드 생성·검증 단계가 통합되어, “AI‑first” 워크플로우가 표준화될 가능성이 있다.  \n- **정책·규제 변화**: 각국 정부가 AI‑Generated 코드에 대한 표준·인증 제도를 마련함에 따라, 도구 선택과 사용 방식에 영향을 미칠 것이다.  \n\n## 결론\n바이브 코딩은 **자연어 기반 AI 코드 생성**이라는 새로운 패러다임을 제시하며, 개발 생산성 향상과 소프트웨어 민주화라는 두 축을 동시에 추구한다. 그러나 **품질·보안·법적** 측면의 리스크를 관리하지 않으면 장기적인 유지보수에 부정적 영향을 미칠 수 있다.  \n\n### 실천 가이드\n1. **시작 방법**: GitHub Copilot 또는 Claude 무료 체험 계정을 만든 뒤, 간단한 “TODO 리스트를 관리하는 앱”을 자연어 프롬프트로 구현해 본다.  \n2. **학습 로드맵**  \n   - 프롬프트 엔지니어링 기본 (FastCampus “Agentic AI Prompting”)  \n   - LLM 동작 원리 이해 (OpenAI, Anthropic 공식 문서)  \n   - 코드 검증·보안 도구 사용법 (SonarQube, Dependabot)  \n3. **주시해야 할 트렌드**  \n   - 멀티모달 LLM 출시 일정  \n   - AI 코드 생성에 대한 국제 표준화 움직임  \n   - 기업 내 AI‑first 개발 문화 확산  \n\n바이브 코딩은 아직 진화 단계에 있지만, 올바른 프레임워크와 검증 절차를 갖춘다면 현대 소프트웨어 개발에 강력한 보조 수단이 될 것이다.",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "바이브코딩",
        "AI코딩",
        "프롬프트엔지니어링",
        "소프트웨어개발"
      ],
      "order": 7,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "멀티 에이전트 시스템 – Self‑Healing AI Agents",
      "slug": "ai/multi-agent-system",
      "content": "\n# 멀티 에이전트 시스템 – Self‑Healing AI Agents\n\n> 이 문서는 **Self‑Healing AI Agents**(자체 복구 AI 에이전트) 구현 사례를 기반으로, 대규모 자율 에이전트 아키텍처와 8 GB VRAM 환경에서의 효율적인 배포 방법을 소개합니다. 원본 내용은 [euno.news](https://euno.news/posts/ko/i-built-4882-self-healing-ai-agents-on-8-gb-vram-h-f27aa8)에서 발췌했습니다.\n\n---\n\n## 1. Self‑Healing Architecture Overview\n\n대부분의 LLM‑기반 에이전트는 단순한 흐름을 따릅니다.\n\n```\nreceive task → call model → return result\n```\n\n오류(환각, 타임아웃, OOM 등)가 발생하면 에이전트가 충돌하거나 쓰레기를 출력합니다. 기존의 `try‑catch` 방식은 임시 방편에 불과합니다. **자체 복구 루프**를 도입해 에이전트가 스스로 상태를 모니터링하고, 필요 시 복구 전략을 실행하도록 설계합니다.\n\n### 핵심 루프 구조\n\n```\n┌─────────────┐\n│   EXECUTE   │ ← 에이전트가 작업 수행\n└──────┬──────┘\n       │\n┌──────▼──────┐\n│   MONITOR   │ ← 실시간 건강 점수 측정\n└──────┬──────┘\n       │\n┌──────▼──────┐\n│   RECOVER   │ ← 계층적 복구 전략\n└──────┬──────┘\n       │\n       └──────→ EXECUTE 로 돌아감\n```\n\n이 루프는 단순 재시도(retry)가 아닙니다. 각 단계에서 **근본 원인을 진단**하고, 상황에 맞는 복구 전략을 선택합니다.\n\n### 1.1 에이전트 상태 머신\n\n에이전트는 다섯 가지 상태 중 하나에 있으며, 상태 전이는 건강 점수에 따라 자동으로 결정됩니다.\n\n```python\nfrom enum import Enum\n\nclass AgentState(Enum):\n    IDLE = \"idle\"              # 유휴 상태\n    RUNNING = \"running\"        # 정상 실행 중\n    DEGRADED = \"degraded\"      # 기능은 있지만 성능 저하\n    RECOVERING = \"recovering\"  # 자체 복구 중\n    FAILED = \"failed\"          # 외부 개입 필요\n```\n\n*핵심 인사이트*: `DEGRADED`는 `FAILED`와 다르며, 대부분의 오류는 여기서 조기에 감지·복구됩니다. 실제 운영에서 **97.7 %** 이상의 오류가 `DEGRADED` 단계에서 자동 복구되며, `FAILED` 상태에 도달하는 비율은 **2.3 %**에 불과합니다.\n\n### 1.2 건강 점수(Health Score)\n\n매 실행 사이클마다 다섯 가지 지표를 가중 합산하여 복합 건강 점수를 산출합니다.\n\n```python\ndef compute_health(agent_output, context):\n    scores = {\n        \"coherence\":    check_coherence(agent_output),       # 응답 일관성\n        \"completeness\": check_completeness(agent_output, context),  # 완전성\n        \"latency\":      check_latency(context.elapsed_time), # 응답 시간\n        \"memory\":       check_memory_usage(),                # 메모리 사용량\n        \"consistency\":  check_cross_agent_consistency(agent_output)  # 에이전트 간 일관성\n    }\n    weights = [0.25, 0.20, 0.15, 0.25, 0.15]\n    return sum(s * w for s, w in zip(scores.values(), weights))\n```\n\n| 지표 | 가중치 | 설명 |\n|------|--------|------|\n| coherence | 25% | 응답의 논리적 일관성 |\n| completeness | 20% | 작업 요구사항 충족 여부 |\n| latency | 15% | 응답 지연 시간 임계값 준수 |\n| memory | 25% | VRAM/RAM 사용량 안전 범위 |\n| consistency | 15% | 다른 에이전트와의 출력 일관성 |\n\n건강 점수가 임계값 이하이면 복구 전략을 선택하고 실행합니다.\n\n---\n\n## 2. Resource‑Efficient Deployment (8 GB VRAM)\n\n### 2.1 동적 에이전트 풀링\n\n8 GB VRAM을 가진 단일 머신에서 4,882개의 에이전트를 실행하기 위해 **동적 에이전트 풀링**을 사용합니다. 한 번에 GPU에 상주하는 에이전트 수는 약 12개이며, 나머지는 CPU/디스크에 직렬화됩니다.\n\n```python\nfrom queue import PriorityQueue\n\nclass AgentPool:\n    def __init__(self, max_concurrent=12, vram_budget_mb=7168):\n        self.active   = PriorityQueue()   # priority = urgency\n        self.dormant  = {}                # serialized agents\n        self.vram_budget = vram_budget_mb\n\n    def activate(self, agent_id, priority):\n        # VRAM 예산의 85%를 초과하면 우선순위가 낮은 에이전트를 퇴거\n        while self.current_vram() > self.vram_budget * 0.85:\n            _, evicted = self.active.get()\n            self.dormant[evicted.id] = evicted.serialize()\n            evicted.release_gpu()\n\n        agent = self.dormant.pop(agent_id).deserialize()\n        self.active.put((priority, agent))\n        return agent\n```\n\n### 2.2 최적화 기법\n\n| 기법 | 효과 | 설명 |\n|------|------|------|\n| 4‑bit 양자화 | VRAM 75% 절감 | 모델 가중치를 4비트로 압축 |\n| KV‑캐시 공유 | 메모리 40% 절감 | 유사한 컨텍스트의 에이전트 간 캐시 재사용 |\n| 동적 풀링 | 동시 실행 제어 | 우선순위 기반 에이전트 활성화/비활성화 |\n| 디스크 직렬화 | 무제한 에이전트 수 | 비활성 에이전트를 디스크에 저장 |\n\n4‑bit 양자화와 KV‑캐시 공유를 결합하면 평균 활성화 지연 시간은 **약 850 ms** 수준입니다. 클라우드 없이, API 호출 없이, 감독 없이 단일 소비자 하드웨어에서 운영이 가능합니다.\n\n---\n\n## 3. Failure Detection & Automatic Recovery\n\n### 3.1 실시간 모니터링\n\n에이전트는 매 실행 사이클 후 **복합 건강 점수**를 계산하고, 점수가 임계값 이하이면 `RECOVER` 단계로 전이합니다. 모니터링은 에이전트 외부가 아닌 **에이전트 내부**에 내장되어 있어, 별도의 모니터링 인프라 없이도 자체적으로 상태를 감지합니다.\n\n### 3.2 계층적 복구 전략\n\n복구 전략은 오류의 심각도에 따라 세 단계로 나뉩니다.\n\n| 단계 | 복구 전략 | 대상 오류 | 예시 |\n|------|-----------|-----------|------|\n| Level 1 | 재시도 + 파라미터 재조정 | 경미한 오류 | 환각, 일시적 타임아웃 |\n| Level 2 | GPU 슬롯 이동 + 메모리 압축 | 자원 부족 | OOM, VRAM 초과 |\n| Level 3 | FAILED 전이 + 외부 개입 요청 | 심각한 오류 | 모델 손상, 하드웨어 장애 |\n\n### 3.3 복구 성과\n\n이러한 접근 방식은 단순 재시도 루프 대비 다음과 같은 개선을 달성합니다.\n\n- 오탐지 실패(false‑positive failure) **73 % 감소**\n- 전체 에이전트 중 FAILED 도달 비율 **2.3 %**\n- 평균 복구 시간(MTTR) **< 2 초**\n\n---\n\n## 4. 실험 결과\n\n아래 결과는 **독립 LLM 심판**이 구조화된 루브릭을 사용해 블라인드 평가한 것이며, 자체 보고가 아닙니다.\n\n| 지표 | 결과 | 비고 |\n|------|------|------|\n| 승률 | 96.5 % (201/208) | 토론 에이전트 블라인드 평가 |\n| 평균 심판 점수 | 4.68 / 5.0 | 독립 LLM 심판 |\n| 전체 품질 | 93.6 % | 복합 품질 지표 |\n| 접근성 | 5.0 / 5.0 | 사용 편의성 |\n| 안전 점수 | 4.6 / 5.0 | 안전성 평가 |\n\n---\n\n## 5. 기존 접근법과의 비교\n\n| 항목 | 기존 try‑catch 방식 | Self‑Healing 방식 |\n|------|---------------------|-------------------|\n| 오류 대응 | 수동 재시작 | 자동 감지·복구 |\n| 확장성 | GPU당 1‑2 에이전트 | GPU당 4,882+ 에이전트 |\n| 클라우드 의존 | API 호출 필요 | 로컬 실행 가능 |\n| 복구 시간 | 분 단위 (인간 개입) | 초 단위 (자동) |\n| 모니터링 | 외부 인프라 필요 | 에이전트 내장 |\n\n---\n\n## 6. 적용 시 고려사항\n\n1. **하드웨어 요구사항**: 최소 8 GB VRAM GPU (소비자급 가능)\n2. **양자화 트레이드오프**: 4‑bit 양자화는 모델 정확도를 소폭 희생하므로, 정밀도가 중요한 작업에서는 8‑bit 이상 권장\n3. **에이전트 간 통신**: 대규모 에이전트 풀에서는 메시지 큐 기반 비동기 통신이 효율적\n4. **직렬화 비용**: 디스크 I/O가 병목이 될 수 있으므로, NVMe SSD 사용 권장\n5. **건강 점수 튜닝**: 도메인에 따라 가중치 조정이 필요하며, 초기에는 보수적 임계값 설정을 추천\n\n---\n\n## 7. AI 에이전트 시뮬레이션 플랫폼 (2026)\n\nAI 에이전트가 프로덕션에 진입하면서, 배포 전 체계적인 시뮬레이션이 필수가 되었습니다. 표준 벤치마크는 고정 프롬프트에 대한 출력만 측정하지만, 에이전트는 동적 상호작용과 복잡한 실행 경로 전반에 걸쳐 테스트되어야 합니다.\n\n### 효과적인 시뮬레이션 플랫폼의 핵심 기능\n- **다중 턴 상호작용 테스트**: 장시간 대화에서 메모리, 지시사항, 상태 전이가 올바르게 작동하는지 검증\n- **도구 오케스트레이션 검증**: 올바른 도구 선택, 파라미터 사용, 실패 시 폴백 동작 확인\n- **경로 분석**: 에이전트가 답변에 도달하는 과정을 추적하여 최종 응답뿐 아니라 추론 과정도 평가\n\n### 주요 플랫폼 비교\n\n| 플랫폼 | 특화 영역 | 다중 에이전트 | 도구 테스트 | 가격 |\n|--------|-----------|:---:|:---:|------|\n| **AgentOps** | 에이전트 모니터링·디버깅 | ✅ | ✅ | Freemium |\n| **LangSmith** | LangChain 생태계 평가 | ✅ | ✅ | Freemium |\n| **Braintrust** | LLM 평가·실험 추적 | ✅ | ❌ | Freemium |\n| **Patronus AI** | 안전성·규정 준수 테스트 | ❌ | ✅ | Enterprise |\n| **Confident AI** | 자동화된 에이전트 벤치마크 | ✅ | ✅ | Freemium |\n\n### 선택 가이드\n1. **Self‑Healing 에이전트 테스트**: 복구 루프의 정확한 동작 검증이 필요하면 AgentOps의 trace 기능 활용\n2. **멀티 에이전트 오케스트레이션**: 4,882+ 에이전트 규모의 시뮬레이션은 LangSmith의 배치 평가 기능 권장\n3. **프로덕션 안전성 검증**: 프롬프트 인젝션 방어 테스트는 Patronus AI 특화\n\n*출처: euno.news – The Best Platforms for AI Agent Simulation in 2026 (2026‑02‑22)*\n\n---\n\n## 8. 참고 자료\n\n- 원본 기사: [euno.news – 8 GB VRAM으로 4,882개의 Self‑Healing AI Agents 구축](https://euno.news/posts/ko/i-built-4882-self-healing-ai-agents-on-8-gb-vram-h-f27aa8)\n- 관련 위키: [AI 에이전트 시스템 개요](../ai/)\n\n---\n\n*이 문서는 Issue #199를 기반으로 작성·업데이트되었습니다.*\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "멀티 에이전트",
        "Self‑Healing",
        "AI",
        "아키텍처",
        "자율 에이전트",
        "자원 효율"
      ],
      "order": 8,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Gemini 3.1 Pro",
      "slug": "ai/gemini-3-1-pro",
      "content": "\n# Gemini 3.1 Pro\n\n## 개요\nGemini 3.1 Pro는 Google이 2026년 2월 19일에 발표한 최신 대형 언어 모델(Large Language Model)입니다. 기존 Gemini 3 시리즈를 기반으로 **복잡한 추론**과 **멀티모달** 작업에서 크게 향상된 성능을 제공합니다. 모델은 **Gemini API**, **Vertex AI**, **Gemini 앱**, **NotebookLM** 등을 통해 접근할 수 있습니다.\n\n- **출시일**: 2026‑02‑19\n- **입력 컨텍스트**: 최대 1 M 토큰\n- **출력 컨텍스트**: 최대 64 K 토큰\n- **파라미터 수**: 공개되지 않음 (삭제)\n\n> 자세한 내용은 공식 블로그와 모델 카드를 참고하세요.\n> - 공식 블로그: [Gemini 3.1 Pro 발표](https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/)  \n> - 모델 카드: [Gemini 3.1 Pro Model Card](https://deepmind.google/models/model-cards/gemini-3-1-pro/)\n\n## 주요 벤치마크 (공식 모델 카드 기준)\n| 벤치마크 | 점수 / 성능 | 비고 |\n|---|---|---|\n| **ARC‑AGI‑2** | **77.1 %** | 새로운 논리 패턴 해결 능력\n| **GPQA Diamond** | **94.3 %** | 과학 지식 평가\n| **SWE‑Bench Verified** | **80.6 %** | 에이전트 기반 코딩 과제 (단일 시도)\n| **Humanity's Last Exam** (with tools) | **51.4 %** | 도구 사용 포함 평가\n| **MMMU‑Pro** | **80.5 %** | 멀티모달 이해 및 추론\n| **LiveCodeBench Pro** | **2887 Elo** | 경쟁 코딩 문제 (Codeforces, ICPC, IOI)\n| **Terminal‑Bench 2.0** | **68.5 %** | 에이전트 기반 터미널 코딩\n| **MRCR v2** (128 k context) | **84.9 %** | 장기 컨텍스트 성능\n\n> 위 수치는 모두 **Gemini 3.1 Pro 모델 카드**에 명시된 공식 결과이며, 다른 모델과의 직접 비교 표는 현재 확인된 데이터가 없으므로 포함하지 않았습니다.\n\n## 활용 예시\n- **복잡한 시스템 합성**: 대규모 API와 사용자 인터페이스를 연결하는 대시보드 자동 생성\n- **코드 기반 애니메이션**: 텍스트 프롬프트에서 SVG 애니메이션을 생성하여 파일 크기 최소화\n- **멀티모달 데이터 분석**: 텍스트·이미지·비디오·오디오를 동시에 처리하여 종합적인 인사이트 도출\n- **에이전트 워크플로우**: Gemini 3.1 Pro를 기반으로 한 자동화 에이전트가 복합 작업을 순차적으로 수행\n\n## 참고 자료\n- **공식 블로그**: Gemini 3.1 Pro 발표 – https://blog.google/innovation-and-ai/models-and-research/gemini-models/gemini-3-1-pro/\n- **모델 카드**: Gemini 3.1 Pro – https://deepmind.google/models/model-cards/gemini-3-1-pro/\n\n---\n*이 문서는 유지보수자를 위해 초안(draft) 상태로 저장되었습니다. 필요에 따라 추가 검토 및 업데이트가 이루어질 수 있습니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "Gemini",
        "AI",
        "Benchmark"
      ],
      "order": 9,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "프론트엔드 API 서비스 레이어 설명",
      "slug": "frontend/api-service-layer",
      "content": "\n## 1. 문서 개요\n**목적**  \n프론트엔드 애플리케이션이 백엔드와 통신할 때 사용하는 공통 API 클라이언트 로직(`src/services/api.ts`)을 이해하고, 유지·보수·확장에 필요한 정보를 제공한다.  \n\n**대상 독자**  \n- 프론트엔드 개발자 (신규 입사자 포함)  \n- QA 엔지니어 및 테스트 자동화 담당자  \n- 아키텍처 리뷰어 및 문서 담당자  \n\n**역할**  \n`services/api.ts`는 HTTP 요청/응답 처리, 에러 핸들링, 토큰 자동 갱신 등 **백엔드와의 통신 전반**을 캡슐화한다. 이를 통해 UI 레이어는 비즈니스 로직에 집중하고, 네트워크 관련 구현은 한 곳에 집중시킬 수 있다.  \n\n**커버리지 분석 결과 요약**  \n\n| 항목 | 내용 |\n|------|------|\n| **모듈** | `services/api.ts` |\n| **소스 경로** | `src/services/api.ts` |\n| **중요도** | **high** (백엔드와의 모든 통신을 담당) |\n| **문서 필요 사유** | 요청/응답 흐름, 에러 처리, 토큰 재발급 로직 등 핵심 로직이 포함돼 있어 신규 개발자와 운영팀 모두에게 필수적인 가이드가 필요함 |\n\n---\n\n## 2. 서비스 레이어 아키텍처 개요\n### 2.1 전체 프론트엔드 아키텍처에서 위치\n- UI 컴포넌트 → **서비스 레이어(`api.ts`)** → HTTP 클라이언트(Axios 혹은 fetch) → 백엔드 API  \n- 서비스 레이어는 UI와 네트워크 사이의 **추상화 계층**으로, 데이터 페칭·전송 로직을 중앙집중화한다. (Medium 기사 “프론트엔드 아키텍처: API 요청 관리” 참고)  \n\n### 2.2 `services/api.ts` 의 책임 범위\n- HTTP 메서드별 헬퍼 함수 제공 (GET, POST, PUT, DELETE 등)  \n- 공통 헤더(Authorization, Content-Type 등) 자동 삽입  \n- 응답 정규화 및 성공/실패 판별  \n- 전역 에러 로깅·모니터링 연동  \n- Access/Refresh 토큰 자동 갱신 로직 구현  \n\n### 2.3 외부 의존성\n| 의존성 | 용도 | 참고 |\n|--------|------|------|\n| **Axios** (또는 fetch) | HTTP 요청/응답 처리 | 일반적인 프론트엔드 API 클라이언트 구현에 사용됨 (Medium) |\n| **토큰 저장소** (예: `localStorage`, `sessionStorage`, 쿠키) | Access/Refresh 토큰 보관 | 보안 고려사항 섹션에서 상세히 다룸 |\n| **인터셉터** | 요청 전/후 공통 로직(헤더 삽입, 토큰 재발급) | Axios 인터셉터 활용이 일반적임 |\n| **타입 정의 파일** (`*.d.ts`) | API 응답 타입 및 파라미터 정의 | TypeScript 기반 프로젝트에서 타입 안전성 확보 |\n\n---\n\n## 3. 파일 및 디렉터리 구조\n```\nsrc/\n └─ services/\n     ├─ api.ts          ← 메인 API 클라이언트\n     ├─ interceptors.ts ← 요청·응답 인터셉터 정의 (예시)\n     └─ types.ts        ← API 요청·응답 인터페이스\n```\n\n- `api.ts`는 **public API**(예: `get`, `post`, `put`, `delete`)를 export하고, 내부적으로 인터셉터와 타입을 활용한다.  \n- `interceptors.ts`(존재한다면)에서는 토큰 자동 갱신 로직과 에러 전역 처리 로직을 구현한다.  \n- `types.ts`는 각 엔드포인트가 반환하는 데이터 구조를 정의해 TypeScript 컴파일 타임에 검증한다.  \n\n> **추가 조사 필요**: 현재 레포지토리에서 실제 `interceptors.ts`·`types.ts` 파일 존재 여부와 구체적인 export 형태를 확인해야 함.\n\n---\n\n## 4. 핵심 기능 상세\n### 4.1 요청(Request) 처리\n- **헬퍼 함수**: `get<T>(url, config)`, `post<T>(url, data, config)` 등 타입 파라미터 `T`를 통해 응답 타입을 명시한다.  \n- **파라미터 직렬화**: 객체를 쿼리스트링으로 변환해 GET 요청에 포함한다. (Axios 기본 동작)  \n- **공통 헤더 삽입**: `Authorization: Bearer <accessToken>` 및 `Content-Type: application/json` 등을 자동으로 추가한다.  \n\n### 4.2 응답(Response) 처리\n- **정규화**: 서버가 반환하는 `{ data, meta, pagination }` 형태를 일관된 구조로 변환한다.  \n- **성공/실패 판별**: HTTP 2xx는 성공, 그 외는 실패로 간주하고, `response.status`에 따라 분기한다.  \n- **페이징·메타데이터 추출**: `meta` 혹은 `pagination` 필드를 별도 객체로 분리해 UI 레이어에 전달한다.  \n\n### 4.3 에러 핸들링\n- **네트워크 오류·타임아웃**: Axios 인터셉터에서 `error.code`를 검사해 재시도 정책을 적용한다.  \n- **HTTP 상태 코드 별 처리**: 401(Unauthorized) → 토큰 재발급 흐름; 403(Forbidden) → 접근 제한 메시지; 5xx → 전역 알림 및 로깅.  \n- **사용자 친화적 메시지 매핑**: 서버 오류 코드를 프론트엔드 메시지(`'서버에 문제가 발생했습니다.'`)와 매핑한다.  \n- **전역 로깅·모니터링 연동**: Sentry·Datadog 등 외부 모니터링 툴에 에러 정보를 전송한다.  \n\n### 4.4 토큰 자동 갱신\n- **흐름**:  \n  1. 요청 인터셉터에서 `Authorization` 헤더에 현재 Access Token 삽입.  \n  2. 401 응답이 오면 응답 인터셉터가 Refresh Token을 사용해 새로운 Access Token을 발급받는다.  \n  3. 재발급 성공 시 원래 요청을 **재시도**하고, 실패 시 로그아웃 처리한다.  \n- **무한 루프 방지**: 재시도 횟수를 1회로 제한하고, 재시도 중에도 401이 발생하면 즉시 로그아웃한다.  \n\n> **추가 조사 필요**: 현재 구현에서 Refresh Token 저장 위치와 재발급 API 엔드포인트가 어떻게 정의돼 있는지 확인이 필요함.\n\n---\n\n## 5. 사용 예시\n- **기본 GET 호출**  \n  `const users = await get<User[]>('/api/users');`  \n\n- **POST with JSON Body**  \n  `await post('/api/posts', { title, content });`  \n\n- **파일 업로드 (멀티파트)**  \n  `await post('/api/upload', formData, { headers: { 'Content-Type': 'multipart/form-data' } });`  \n\n- **인증이 필요한 엔드포인트**  \n  `await get('/api/profile'); // 인터셉터가 자동으로 토큰 삽입`  \n\n> 실제 코드 예시는 프로젝트 내 `src/services/api.ts`를 참고하고, 필요 시 `interceptors.ts`에 정의된 로직을 검토한다.\n\n---\n\n## 6. 확장 및 커스터마이징\n- **인터셉터 추가/제거**: `apiInstance.interceptors.request.use(customInterceptor)` 형태로 새로운 로직을 삽입한다.  \n- **커스텀 헤더 삽입**: 호출 시 `config.headers`에 추가하면 인터셉터가 병합한다.  \n- **테스트 환경(모킹) 설정**: Jest·MSW(Mock Service Worker)를 사용해 `api.ts`의 Axios 인스턴스를 모킹한다.  \n\n---\n\n## 7. 테스트 전략\n| 테스트 종류 | 대상 | 주요 포인트 |\n|------------|------|-------------|\n| **단위 테스트** | 헬퍼 함수(`get`, `post` 등) | 파라미터 직렬화, 헤더 삽입 검증 (Jest + axios-mock-adapter) |\n| **통합 테스트** | 실제 API 엔드포인트와 연동 | 성공/실패 시 응답 구조, 토큰 재발급 흐름 검증 |\n| **CI/CD 자동화** | Pull Request 단계 | `npm test` 실행, 커버리지 80% 이상 목표 (nodebestpractices 참고) |\n\n---\n\n## 8. 보안 고려사항\n- **토큰 저장소 선택**:  \n  - `httpOnly` 쿠키 → XSS 방어에 유리하지만 CSRF 방어 필요.  \n  - `localStorage`/`sessionStorage` → XSS 위험 존재, 토큰 암호화 필요.  \n- **CSRF 방어**: `SameSite=Lax` 쿠키 설정 또는 CSRF 토큰 헤더 전송.  \n- **XSS 예방**: 모든 입력값을 이스케이프하고, Content Security Policy(CSP) 적용.  \n- **민감 데이터 마스킹**: 로그에 토큰·비밀번호 등은 `***` 로 마스킹하고, 로깅 레벨을 조절한다.  \n\n---\n\n## 9. 성능 최적화\n- **요청 중복 방지(디듀핑)**: 동일 URL·파라미터에 대한 병렬 요청을 하나로 합친 뒤 결과를 공유한다.  \n- **캐시 전략**:  \n  - 메모리 캐시(React Query, SWR) → 최신 데이터와 재요청 최소화.  \n  - IndexedDB 혹은 Service Worker 캐시 → 오프라인 지원.  \n- **타임아웃·재시도 정책**: Axios `timeout` 옵션과 지수 백오프 재시도 로직을 적용한다.  \n\n---\n\n## 10. 베스트 프랙티스\n- **API 명명 규칙**: 리소스는 명사 형태, 동사는 HTTP 메서드로 표현한다 (velog “22 Best Practices” 참고).  \n- **에러 코드·메시지 표준화**: 서버와 클라이언트가 공유하는 에러 코드 사전 정의.  \n- **문서·타입 정의 유지**: `src/services/types.ts`에 인터페이스를 선언하고, 변경 시 문서와 테스트를 동시에 업데이트한다.  \n\n---\n\n## 11. 마이거레이션 가이드\n1. **기존 fetch 기반 구현 파악** – 현재 `fetch` 호출이 있는 파일을 식별한다.  \n2. **API 레이어 설치** – `src/services/api.ts`와 의존 파일을 프로젝트에 추가한다.  \n3. **호출 교체** – `fetch(url, options)` → `get<T>(url)` 혹은 `post<T>(url, data)` 로 교체한다.  \n4. **헤더·토큰 로직 검증** – 새 레이어가 자동으로 Authorization 헤더를 삽입하는지 확인한다.  \n5. **테스트 실행** – 기존 단위 테스트와 새 레이어 테스트를 모두 통과하는지 검증한다.  \n\n---\n\n## 12. FAQ\n- **Q: 토큰 갱신이 실패하면 어떻게 해야 하나요?**  \n  A: 인터셉터에서 401 응답이 두 번 연속 발생하면 `logout()`을 호출해 세션을 종료하고 로그인 페이지로 리다이렉트한다.  \n\n- **Q: CORS 오류가 발생했을 때 점검 포인트는?**  \n  A: 서버의 `Access-Control-Allow-Origin` 헤더와 프론트엔드 요청에 포함된 `Origin`이 일치하는지, 프리플라이트 요청이 정상적으로 처리되는지 확인한다.  \n\n- **Q: 테스트 환경에서 실제 API 호출을 차단하려면?**  \n  A: Jest 설정 파일에 `axios` 모듈을 `jest.mock('axios')` 로 모킹하거나, MSW를 사용해 네트워크 요청을 가로채고 가짜 응답을 반환한다.  \n\n---\n\n## 13. 참고 자료\n- **프론트엔드 아키텍처: API 요청 관리** – Medium (https://medium.com/@junep/%ED%94%84%EB%A1%9C%ED%8A%B8%EC%97%94%EB%93%9C-%EC%95%84%ED%82%A4%ED%85%8C%EC%B2%98-api-%EC%9A%94%EC%B2%AD-%EA%B4%80%EB%A6%AC-113c31d7bcee)  \n- **Grab Front End Guide** – 네이버 블로그 (https://m.blog.naver.com/magnking/221149133410)  \n- **Node.js Best Practices (Korean)** – GitHub (https://github.com/goldbergyoni/nodebestpractices/blob/master/README.korean.md)  \n- **API Design Best Practices** – velog (https://velog.io/@juunini/%EB%B2%88%EC%97%AD-22-Best-Practices-to-Take-Your-API-Design-Skills-to-the-Next-Level)  \n\n> **추가 조사 필요**: 프로젝트 내 실제 `src/services/api.ts` 구현 상세와 커밋 히스토리, 인터셉터·타입 정의 파일 위치를 확인해 문서에 반영한다.",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "frontend",
        "api",
        "service-layer",
        "documentation",
        "coverage"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "Incremental Static Regeneration (ISR) 가이드",
      "slug": "frontend/isr-guide",
      "content": "\n## 1. 개요\n**Incremental Static Regeneration (ISR)** 은 Next.js 가 제공하는 정적 페이지 재생성 메커니즘으로,  \n- 최초 요청 시 미리 생성된 **정적 HTML** 을 CDN 캐시에서 바로 제공하고,  \n- 지정된 시간 간격이 지나면 백그라운드에서 최신 데이터를 기반으로 페이지를 **재생성** 합니다.  \n\n이 방식은 전통적인 **Static Site Generation (SSG)** 이 “빌드 시점에 한 번만” 정적 파일을 만들고, **Server‑Side Rendering (SSR)** 이 “요청마다 서버에서 렌더링” 하는 것과 달리, **정적·동적 렌더링의 중간** 형태를 제공합니다.  \n\n주로 **콘텐츠가 자주 업데이트되지만 SEO와 초저지연 응답이 중요한** 블로그, 마케팅 페이지, 전자상거래 카탈로그 등에 적용됩니다.  \n\n> “ISR 작동 방식 – 캐시에서 제공: 페이지에 대한 최초 요청은 사전 생성된 정적 버전을 캐시에서 제공하여 일관되게 빠른 응답을 보장합니다.” [euno.news](https://euno.news/posts/ko/reactjsnextjs-rendering-pattern-incremental-static-a406b6)\n\n## 2. ISR 작동 원리\n1. **초기 정적 페이지 생성 및 CDN 캐시 저장**  \n   - 빌드 단계에서 `getStaticProps`(또는 App Router) 를 실행해 HTML 과 JSON 데이터를 만든 뒤, CDN 에 저장합니다.  \n\n2. **시간 기반 백그라운드 재생성 (`revalidate`)**  \n   - 페이지 파일에 `export const revalidate = <seconds>` 를 선언하면, 해당 초가 경과한 뒤 **다음 사용자 요청** 시 기존 캐시된 페이지를 즉시 반환하고, 동시에 Next.js 가 백그라운드에서 새로운 페이지를 생성합니다.  \n   - 새 페이지가 완성되면 캐시가 교체되어 이후 방문자는 최신 콘텐츠를 받게 됩니다.  \n\n   > “백그라운드 재생성 (시간 기반): revalidate 시간을 초 단위로 지정합니다. 이 간격이 지나면 다음 사용자 요청은 여전히 오래된(캐시된) 페이지를 즉시 받습니다. 이 요청은 Next.js가 백그라운드에서 페이지의 새로운 버전을 재생성하도록 트리거합니다.” [euno.news](https://euno.news/posts/ko/reactjsnextjs-rendering-pattern-incremental-static-a406b6)\n\n3. **온‑디맨드 재검증 (수동 트리거)**  \n   - API 라우트 등을 통해 `unstable_revalidate`(또는 최신 버전에서는 `revalidate`) 를 호출하면, 지정된 경로의 페이지를 즉시 재생성하도록 강제할 수 있습니다.  \n\n4. **캐시 교체 시점 및 사용자 응답 흐름**  \n   - 기존 캐시 → 즉시 응답 → 백그라운드 재생성 → 새 캐시 교체 → 이후 요청에 새 페이지 제공  \n\n## 3. Next.js에서 ISR 구현하기\n### 페이지 파일에 `revalidate` 선언\n```tsx\n// app/page.tsx (또는 pages/your-page.tsx)\nexport const revalidate = 60; // 60초마다 페이지를 재생성\nexport default async function Page() {\n  const res = await fetch('https://example.com/items');\n  const items = await res.json();\n  // ... items 를 렌더링\n}\n```\n- `revalidate` 값은 **초 단위**이며, 위 예시에서는 1분마다 백그라운드 재생성이 트리거됩니다.  \n\n### 데이터 페칭과 ISR 연계\n- `fetch` 로 외부 API 를 호출할 때는 기본적으로 **캐시 정책**이 `force-cache` 로 동작합니다. 이는 ISR 과 충돌하지 않으며, 최신 데이터를 얻고 싶다면 `no-store` 옵션을 사용할 수 있습니다(필요 시 추가 조사 필요).  \n\n### 온‑디맨드 재검증 API 예시 (TypeScript)\n```tsx\n// pages/api/revalidate.ts\nimport type { NextApiRequest, NextApiResponse } from 'next';\n\nexport default async function handler(req: NextApiRequest, res: NextApiResponse) {\n  // 비밀 토큰 검증 등 보안 로직 필요 (추가 조사 필요)\n  await res.revalidate('/your-page');\n  return res.json({ revalidated: true });\n}\n```\n- `res.revalidate` (또는 `unstable_revalidate`) 를 호출하면 지정된 경로가 즉시 재생성됩니다.  \n\n## 4. 구성 옵션 및 세부 설정\n| 옵션 | 설명 | 현재 문서화 여부 |\n|------|------|----------------|\n| `revalidate` | 초 단위 재생성 간격 | ✅ 위 예시 참고 |\n| `fallback` | 동적 라우트와 결합 시 미리 생성되지 않은 페이지 처리 방식 | 추가 조사 필요 |\n| `force-static` / `dynamic` 플래그 | 최신 Next.js 에서 페이지 렌더링 모드 제어 | 추가 조사 필요 |\n| CDN 캐시 정책 (Vercel, Cloudflare 등) | ISR 페이지가 CDN 에 저장되는 방식 및 TTL 설정 | 추가 조사 필요 |\n\n> 위 옵션들에 대한 구체적인 설정 방법은 공식 Next.js 문서 또는 사용 중인 CDN 제공자의 가이드를 참고하십시오. (추가 조사 필요)\n\n## 5. 주요 장점\n- **성능 향상**: CDN 캐시에서 즉시 제공되므로 페이지 로드 시간이 매우 짧아집니다.  \n- **빌드 시간 감소**: 전체 사이트를 매번 재빌드할 필요 없이 변경된 페이지만 재생성합니다.  \n- **SEO 이점**: 검색 엔진이 정적 HTML 을 바로 크롤링하므로 인덱싱이 빠르고 정확합니다.  \n- **배포 없이 최신 콘텐츠 반영**: CMS 혹은 DB 업데이트가 발생해도 전체 배포 없이 페이지가 자동으로 최신화됩니다.  \n\n> “장점 – 성능 향상: 페이지가 CDN 캐시에서 즉시 제공됩니다. 빌드 시간 감소: 필요한 페이지만 재생성하므로 대규모 사이트에 효율적입니다. SEO 이점: 검색 엔진에 최적화된 신선한 정적 HTML 페이지를 제공합니다. 재배포 없이 최신 콘텐츠: CMS 또는 데이터베이스에서 업데이트된 콘텐츠가 전체 사이트 재빌드 없이 반영됩니다.” [euno.news](https://euno.news/posts/ko/reactjsnextjs-rendering-pattern-incremental-static-a406b6)\n\n## 6. 고려해야 할 제한 사항 및 함정\n- **Stale 콘텐츠 노출**: `revalidate` 간격이 길면 사용자는 오래된(캐시된) 페이지를 볼 수 있습니다.  \n- **데이터 일관성**: 동시에 여러 사용자가 페이지를 요청하면 백그라운드 재생성이 중복될 수 있으며, 데이터 레이스 컨디션을 방지하려면 추가 로직이 필요합니다 (추가 조사 필요).  \n- **지원 제한**: 일부 서버 전용 로직이나 복잡한 동적 라우트는 ISR 적용이 어려울 수 있습니다 (추가 조사 필요).  \n\n## 7. 베스트 프랙티스\n1. **적절한 `revalidate` 간격 설정**  \n   - 콘텐츠 업데이트 빈도와 사용자 기대 최신성을 고려해 초 단위 값을 결정합니다.  \n2. **CMS/Webhook 과 연동**  \n   - 콘텐츠가 변경될 때마다 온‑디맨드 재검증 API 를 호출하도록 Webhook 을 설정하면 “stale” 문제를 최소화할 수 있습니다.  \n3. **모니터링**  \n   - Next.js 가 제공하는 `on-demand-revalidate` 로그와 CDN 캐시 히트율을 모니터링해 재생성 빈도와 성능을 조정합니다.  \n4. **테스트 환경 검증**  \n   - 로컬 개발 서버(`next dev`)에서는 ISR 동작이 제한될 수 있으므로, 실제 배포 환경(Vercel 등)에서 동작을 확인합니다.  \n\n> 위 권장 사항은 일반적인 운영 경험에 기반한 것이며, 프로젝트별 세부 설정은 추가 조사가 필요합니다.\n\n## 8. 트러블슈팅 가이드\n| 문제 | 가능 원인 | 해결 방안 |\n|------|-----------|----------|\n| 페이지가 재생성되지 않음 | `revalidate` 값이 너무 크거나, `fetch` 캐시 정책이 `no-store` 로 설정돼 ISR 와 충돌 | `revalidate` 간격 확인, `fetch` 옵션 검토 |\n| 오래된 페이지가 계속 제공됨 | CDN 캐시 TTL 이 `revalidate` 보다 길게 설정 | CDN 캐시 정책을 `stale‑while‑revalidate` 로 조정 (추가 조사 필요) |\n| Vercel Edge 네트워크 오류 | 배포 설정 오류 또는 Edge 함수 제한 초과 | Vercel 로그 확인, 배포 설정 검토 |\n| CI/CD 파이프라인에서 ISR 관련 테스트 실패 | 빌드 단계에서 `getStaticProps` 가 정상 동작하지 않음 | 로컬에서 `next build && next export` 로 결과 확인 |\n\n## 9. 다른 렌더링 전략과 비교\n| 전략 | 빌드 시점 | 런타임 비용 | SEO | 최신성 |\n|------|-----------|------------|-----|--------|\n| SSR (Server‑Side Rendering) | 요청 시 | 높음 | 좋음 | 실시간 |\n| SSG (Static Site Generation) | 빌드 시 | 낮음 | 좋음 | 정적 |\n| ISR (Incremental Static Regeneration) | 빌드 + 재생성 | 중간 | 좋음 | 주기적·온‑디맨드 |\n\n- **선택 가이드라인**  \n  - **SSR**: 사용자마다 맞춤형 데이터가 필요하고, 실시간성이 가장 중요한 경우.  \n  - **SSG**: 콘텐츠가 거의 변하지 않으며, 빌드 시점에 모두 생성해도 무방한 경우.  \n  - **ISR**: 정적 페이지의 성능 이점은 유지하면서, 일정 주기 혹은 이벤트 기반으로 최신 콘텐츠를 제공하고자 할 때.  \n\n## 10. 기존 프로젝트에 ISR 도입하기\n1. **현황 파악**: `getStaticProps` 로 정적 페이지를 이미 사용 중인지 확인합니다.  \n2. **`revalidate` 추가**: 페이지 파일에 `export const revalidate = <seconds>` 를 선언합니다.  \n3. **배포 테스트**: Vercel 혹은 선택한 호스팅에 배포 후, 실제 요청 시 캐시와 재생성 흐름을 검증합니다.  \n4. **점진적 적용**: 트래픽이 많은 핵심 페이지부터 ISR 을 적용하고, 점차 범위를 확대합니다.  \n\n> 구체적인 마이그레이션 체크리스트와 단계별 가이드는 추가 조사가 필요합니다.\n\n## 11. FAQ\n**Q1. 재생성 중 오류가 발생하면 어떻게 되나요?**  \nA. 기존 캐시된 페이지가 그대로 제공되며, 오류 로그가 Next.js 로그에 기록됩니다. 오류가 지속되면 `revalidate` 간격을 조정하거나 데이터 소스를 점검해야 합니다. (추가 조사 필요)\n\n**Q2. 동시 사용자 요청 시 재생성은 한 번만 수행되나요?**  \nA. Next.js 는 동일 경로에 대해 동시에 여러 재생성 요청이 들어오면 하나만 실행하고, 나머지는 기존 캐시를 반환합니다. (추가 조사 필요)\n\n**Q3. Vercel 외 다른 호스팅에서도 ISR을 사용할 수 있나요?**  \nA. ISR 은 Next.js 자체 기능이므로, Edge 캐시를 지원하는 대부분의 호스팅(예: Cloudflare Pages, Netlify)에서도 동작합니다. 다만 CDN 설정에 따라 동작 방식이 달라질 수 있습니다. (추가 조사 필요)\n\n## 12. 참고 자료 및 링크\n- **Next.js 공식 문서 – Incremental Static Regeneration**: https://nextjs.org/docs/basic-features/data-fetching/incremental-static-regeneration  \n- **euno.news – ReactJS(NextJs) 렌더링 패턴 ~Incremental Static Regeneration (ISR)~**: https://euno.news/posts/ko/reactjsnextjs-rendering-pattern-incremental-static-a406b6  \n- **Dev.to** (ISR 작동 방식 원본): 해당 기사에서 ISR 의 기본 흐름과 장점을 확인할 수 있습니다.  \n\n*※ 본 문서는 현재 확보된 자료를 기반으로 작성되었으며, 일부 세부 설정 및 고급 옵션은 추가 조사가 필요합니다.*",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "draft",
      "isDraft": true,
      "isInvalid": false,
      "tags": [
        "Next.js",
        "ISR",
        "React",
        "정적 사이트",
        "성능 최적화"
      ],
      "order": 2,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "$100K AWS 라우팅 비용 함정: S3 + NAT 게이트웨이와 Terraform 해결법",
      "slug": "cloud/aws-nat-gateway-cost-trap",
      "content": "\n# $100K AWS 라우팅 비용 함정: S3 + NAT 게이트웨이\n\n> \"기본적으로 보안\" AWS 아키텍처가 의도치 않게 비용을 폭발시킬 수 있습니다. 클라우드 비용 급증의 주요 원인은 과다 프로비저닝된 EC2가 아니라 **의도하지 않은 데이터 전송 경로**입니다.\n\n---\n\n## 문제: NAT 게이트웨이의 숨은 비용\n\n### 일반적인 \"보안\" 아키텍처\n```\nPrivate Subnet (EC2)\n    ↓ S3 요청\nNAT Gateway\n    ↓ 퍼블릭 S3 엔드포인트로 전송\nInternet Gateway\n    ↓ AWS 백본을 벗어남\nS3 (퍼블릭 서비스)\n```\n\n### 왜 비용이 두 배가 되는가\n\n1. 컴퓨트 인스턴스는 퍼블릭 IP 없이 **프라이빗 서브넷**에 배치됩니다\n2. 아웃바운드 트래픽은 **관리형 NAT 게이트웨이**를 통해 라우팅됩니다\n3. S3는 퍼블릭 서비스 엔드포인트이므로, 데이터가 AWS 백본을 벗어나 **두 번** 측정됩니다\n\n하루에 10 TB를 다운로드하는 파이프라인이라면 실제로는 **20 TB의 아웃바운드**에 대해 청구됩니다.\n\n### 청구되는 비용 항목\n\n| 항목 | 요금 |\n|------|------|\n| NAT 게이트웨이 시간당 가동 비용 | ~$0.045/hr |\n| NAT 게이트웨이 처리 수수료 | $0.045/GB |\n| 표준 인터넷 아웃바운드 요금 | ~$0.09/GB (첫 10TB) |\n\n> **예시**: 월 300 TB S3 다운로드 시 NAT 처리 수수료만 **$13,500/월** ($162,000/년)\n\n---\n\n## 해결책: S3용 VPC 게이트웨이 엔드포인트\n\nVPC 게이트웨이 엔드포인트를 생성하면 S3 트래픽이 **AWS 백본 내부**에 머무르게 됩니다. NAT 게이트웨이를 우회하고, 내부 전송 비용이 **$0.00**으로 감소합니다.\n\n### 변경 후 아키텍처\n```\nPrivate Subnet (EC2)\n    ↓ S3 요청\nVPC Gateway Endpoint\n    ↓ AWS 내부 네트워크\nS3 (직접 접근)\n```\n\n### Terraform 구현\n\n```hcl\n# VPC 게이트웨이 엔드포인트 생성\nresource \"aws_vpc_endpoint\" \"s3\" {\n  vpc_id            = aws_vpc.main.id\n  service_name      = \"com.amazonaws.${var.region}.s3\"\n  vpc_endpoint_type = \"Gateway\"\n}\n\n# 프라이빗 서브넷 라우트 테이블에 연결\nresource \"aws_vpc_endpoint_route_table_association\" \"s3\" {\n  route_table_id  = aws_route_table.private.id\n  vpc_endpoint_id = aws_vpc_endpoint.s3.id\n}\n```\n\n### 적용 확인\n```bash\n# 엔드포인트 상태 확인\naws ec2 describe-vpc-endpoints \\\n  --filters \"Name=service-name,Values=com.amazonaws.ap-northeast-2.s3\" \\\n  --query \"VpcEndpoints[].State\"\n\n# S3 트래픽이 NAT를 우회하는지 확인\naws ec2 describe-route-tables \\\n  --route-table-ids rtb-xxxxx \\\n  --query \"RouteTables[].Routes[?DestinationPrefixListId]\"\n```\n\n---\n\n## 추가 비용 절감 포인트\n\n### 1. DynamoDB 게이트웨이 엔드포인트\nS3와 동일하게 DynamoDB도 게이트웨이 엔드포인트를 지원합니다.\n\n```hcl\nresource \"aws_vpc_endpoint\" \"dynamodb\" {\n  vpc_id            = aws_vpc.main.id\n  service_name      = \"com.amazonaws.${var.region}.dynamodb\"\n  vpc_endpoint_type = \"Gateway\"\n}\n```\n\n### 2. 인터페이스 엔드포인트 (PrivateLink)\nECR, CloudWatch, SSM 등 다른 AWS 서비스는 **인터페이스 엔드포인트**를 사용합니다. 시간당 비용($0.01/hr)이 있지만, NAT 처리 수수료보다 저렴할 수 있습니다.\n\n### 3. NAT 게이트웨이 모니터링\n```bash\n# NAT 게이트웨이를 통한 바이트 수 확인 (CloudWatch)\naws cloudwatch get-metric-statistics \\\n  --namespace AWS/NATGateway \\\n  --metric-name BytesOutToDestination \\\n  --dimensions Name=NatGatewayId,Value=nat-xxxxx \\\n  --start-time 2026-02-01T00:00:00Z \\\n  --end-time 2026-02-22T00:00:00Z \\\n  --period 86400 \\\n  --statistics Sum\n```\n\n---\n\n## 핵심 원칙\n\n> **데이터 중력**이 기본 비용을 결정하고, **라우팅**이 그 비용에 곱해지는 배수를 결정합니다.\n\n1. **VPC 엔드포인트를 기본으로** – S3, DynamoDB는 게이트웨이 엔드포인트를 항상 생성\n2. **NAT 트래픽을 모니터링** – CloudWatch 메트릭으로 예상치 못한 데이터 전송 감지\n3. **Terraform 모듈화** – VPC 모듈에 엔드포인트를 기본 포함시켜 누락 방지\n\n---\n\n## 참고 자료\n\n- [원본 기사: $100k AWS 라우팅 함정 (euno.news)](https://euno.news/posts/ko/the-100k-aws-routing-trap-s3-nat-gateways-and-how-307ce6)\n- [AWS VPC 엔드포인트 공식 문서](https://docs.aws.amazon.com/vpc/latest/privatelink/vpc-endpoints-s3.html)\n- [Terraform aws_vpc_endpoint 리소스](https://registry.terraform.io/providers/hashicorp/aws/latest/docs/resources/vpc_endpoint)\n\n---\n\n*이 문서는 Issue #212를 기반으로 작성되었습니다.*\n",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "GitHub Action",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "AWS",
        "NAT Gateway",
        "S3",
        "Terraform",
        "비용 최적화",
        "VPC"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "주간 위키 보고서 - 2026년 9주차",
      "slug": "meta/weekly-2026-09",
      "content": "\n## 요약\n- 전체 문서 36개 중 신규 15개, 수정 4개, 현재 발행된 문서 31개(삭제 3개, 초안 2개)  \n- AI가 73건의 작업을 수행했으며, 유지보수(`maintain`) 29건이 가장 많음  \n- 열린 이슈 18건(최근 활동 15건)과 커밋 82건이 기록됨  \n\n## 문서 현황\n| 항목 | 수량 |\n|------|------|\n| 전체 문서 | 36 |\n| 발행(published) | 31 |\n| 삭제(deleted) | 3 |\n| 초안(draft) | 2 |\n| 신규 문서(newCount) | 15 |\n| 수정된 문서(modifiedCount) | 4 |\n| 이번 주 발행(publishedCount) | 0 |\n\n## AI 활동 요약\n- **총 작업**: 73건  \n- **작업 유형별**  \n  - maintain: 29건  \n  - generate: 15건  \n  - recover: 9건  \n  - quality_score: 11건  \n  - cross_reference: 5건  \n  - modify: 4건  \n\n### 주요 AI 활동\n- **Wiki Tree Maintenance**  \n  - `_wiki-tree` 문서에 구조 분석 후 자동 적용 38~43건, 보류 0~3건, Issue 1건 생성 (여러 차례 실행)  \n- **뉴스 인텔리전스**  \n  - 매일 200건 스캔, 신규 55~72건, 관련 13~24건, Issue 생성 0~5건 (스케줄링)  \n- **교차 참조 업데이트**  \n  - `_cross-reference` 문서에 21~25개 문서의 교차 참조를 자동 업데이트  \n- **문서 복구(recover)**  \n  - Issue #212, #199, #209, #198에 대해 피드백 기반 신규 문서 생성  \n- **문서 생성(generate)**  \n  - Issue #212 → “$100k AWS 라우팅 함정: S3 + NAT 게이트웨이 비용 최적화 가이드” (총 32 074 ms, 6개 소스)  \n  - Issue #209 → “GPU 가속 Rust 기반 얼굴 크롭 도구 설계 및 구현 가이드” (총 36 741 ms, 8개 소스)  \n  - Issue #207 → “클라우드 기반 영구 터미널 설계 및 구현 가이드” (총 44 738 ms, 9개 소스)  \n\n## 열린 이슈\n- **전체 오픈 이슈**: 18건  \n- **최근 활동(지난 주)**: 15건  \n\n## 주간 변경사항\n| SHA | 커밋 메시지 |\n|-----|--------------|\n| 729ba5e | 🌳 Wiki Tree Maintenance: 36문서가 9개 상위 디렉터리로 분류, 중복·메타 데이터 정비 필요 |\n| 21561b6 | 🌳 Wiki Tree Maintenance: 38문서가 10개 카테고리로 분류, 구조 비효율 및 파일명 정규화 제안 |\n| 77a095c | 🔗 교차 참조 업데이트: 25개 문서 |\n| f9181e2 | docs: Issue #216 - draft 문서 published 전환 |\n| abc1b0c | docs: Issue #210 - 피드백 반영 |\n\n(전체 82건의 커밋이 기록되었으며, 위 항목은 주요 변경을 대표합니다.)\n\n## 향후 과제\n- **초안(draft) 문서** 2건을 검토 후 발행(published) 혹은 삭제 처리  \n- **삭제된 문서** 3건에 대한 복구 필요성 검토  \n- **Wiki Tree** 구조와 메타데이터 정비를 지속하여 중복·불필요 카테고리 최소화  \n- **교차 참조** 자동 업데이트 빈도와 정확도 모니터링, 누락된 문서가 없는지 확인  \n- **AI 유지보수 작업**에서 보류된 항목(총 3~5건) 해결 및 생성된 Issue 추적  \n- **이슈 관리**: 현재 18건 중 미해결 이슈에 대한 우선순위 재조정 및 해결 속도 향상  \n\n---",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "보고서",
        "주간",
        "통계"
      ],
      "order": 1,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    },
    {
      "title": "주간 위키 보고서 - 2026년 08주차",
      "slug": "meta/weekly-2026-08",
      "content": "\n## 요약\n- 전체 문서 수는 **18개**이며, 이번 주에 **14개**가 신규 생성되었습니다.  \n- 현재 초안(draft) 상태가 **10개**, 발행(published) 상태가 **7개**, 삭제된 문서가 **1개**입니다.  \n- AI가 수행한 작업은 **50건**으로, `maintain` 13건, `generate` 14건, `cross_reference` 9건 등이 주요 활동이었습니다.  \n- 열린 이슈는 **6개**이며, 최근 7일간 **12건**의 이슈 활동이 있었습니다.\n\n## 문서 현황\n| 구분 | 개수 |\n|------|------|\n| 전체 문서 | 18 |\n| 초안(draft) | 10 |\n| 발행(published) | 7 |\n| 삭제된 문서 | 1 |\n| 신규 생성 | 14 |\n| 수정된 문서 | 2 |\n| 이번 주 발행된 문서 | 3 |\n\n## AI 활동 요약\n- **총 작업 수**: 50\n- **작업 유형별**  \n  - `maintain` (유지보수): 13  \n  - `generate` (문서 생성): 14  \n  - `cross_reference` (교차 참조 업데이트): 9  \n  - `recover` (복구/피드백 반영): 6  \n  - `publish` (발행): 3  \n  - `coverage_analysis` (커버리지 분석): 1  \n  - `tag_normalize` (태그 정규화): 2  \n  - `modify` (수정): 2  \n\n### 주요 AI 로그\n- **Wiki Tree Maintenance** – 자동 구조 분석 후 22개 적용(0 보류) (2026‑02‑16)  \n- **학습 루프** – 패턴 2개 감지, 에이전트 2개 개선 (2026‑02‑15)  \n- **문서 커버리지 분석** – 커버리지 점수 12점, 미문서화 모듈 10개 발견 (2026‑02‑15)  \n- **URL 변경 감지** – 30개 체크, 1개 변경, 4개 깨짐, 3건 Issue 생성 (2026‑02‑13)  \n- **트렌드 모니터링** – 23건 수집, 3건 감지, 3건 Issue 생성 (2026‑02‑13)  \n- **문서 생성 예시**  \n  - `glm5` (Issue #160) – 연구·아웃라인·작성·리뷰 4단계 총 39,971 ms, 토큰 약 1,525 개 (2026‑02‑12)  \n  - `바이브 코딩이란?` (Issue #158) – 총 41,234 ms, 토큰 약 1,875 개 (2026‑02‑11)  \n  - `Opencode에 대해` (Issue #156) – 총 32,781 ms, 토큰 약 1,403 개 (2026‑02‑11)  \n\n## 열린 이슈\n- **전체 오픈 이슈**: 6  \n- **최근 7일간 이슈 활동**: 12건 (코멘트, 라벨링, 클로즈 등)\n\n## 주간 변경사항\n| SHA | 커밋 메시지 |\n|-----|-------------|\n| 5132464 | 🌳 Wiki Tree Maintenance: 전체 위키는 4개의 주요 카테고리(kubernetes, projects, bun, ai)로 구성. 중복 Opencode 문서 존재, 메타데이터 추가 제안 |\n| bbce2ca | 🌳 Wiki Tree Maintenance: 루트 레벨에 glm5, opencode 두 문서와 중복 Opencode 가이드 존재. 파일명 slug 정규화 및 순서 지정 권고 |\n| f2989d2 | docs: Issue #160 - [요청] 어제 발표한 glm5 에 대해 조사해줘 |\n| af0cfb6 | docs: Issue #156 - 문서 발행 |\n| a897516 | 🌳 Wiki Tree Maintenance: 4개 카테고리 구성, 루트 비정형 파일·삭제된 Opencode 문서 존재, URL 깨짐 위험 |\n| ca25fed | docs: Issue #158 - [요청] 바이브코딩에 대해 |\n| 0190970 | 🔗 교차 참조 업데이트: 16개 문서 |\n| 08e2761 | Rename .md to opencode.md |\n| e873878 | 🌳 Wiki Tree Maintenance: 22개 문서가 6개 디렉터리에 흩어짐, 루트 파일·중복 Opencode 문제 지적 |\n| 605d980 | docs: Issue #156 - 피드백 반영 |\n\n## 향후 과제\n1. **초안(draft) 문서 정리** – 현재 10개의 초안 중 7개 이상을 검토·발행하거나 삭제하여 발행 비율을 높일 필요가 있습니다.  \n2. **중복 및 URL 깨짐 문서 해결** – `opencode` 관련 중복 파일과 루트 레벨 비정형 파일을 정규화하고, 깨진 URL 4건을 복구합니다.  \n3. **문서 커버리지 개선** – 커버리지 분석 결과 발견된 10개의 미문서화 모듈에 대한 문서 작성 작업을 계획합니다.  \n4. **교차 참조 최신화** – 이번 주에 5번에 걸쳐 62개의 교차 참조가 업데이트되었으나, 지속적인 자동 업데이트 스케줄을 검토해 누락을 최소화합니다.  \n5. **열린 이슈 처리** – 현재 6개의 오픈 이슈를 우선순위에 따라 해결하고, 최근 활동이 많은 이슈(12건)와 연계된 문서·태스크를 정리합니다.  \n6. **태그 정규화** – `tag_normalize` 작업이 2건 수행되었으니, 전체 문서에 일관된 태그 체계를 적용해 검색성을 향상시킵니다.  ",
      "lastModified": "2026-02-24T00:35:21Z",
      "author": "SEPilot AI",
      "status": "published",
      "isDraft": false,
      "isInvalid": false,
      "tags": [
        "보고서",
        "주간",
        "통계"
      ],
      "order": 2,
      "history": [
        {
          "sha": "60b9a30",
          "message": "🌳 Wiki Tree Maintenance: 전체 46개의 위키 문서가 13개의 카테고리로 흩어져 있습니다. Dependabot 라벨 가이드가 여러 위치에 중복되어 있고, ISR 가이드와 같은 오래된 파일이 삭제 상태이며, AI 카테고리에 초안(draft) 문서가 다수 존재합니다. 대부분 파일명은 slug 형태이지만, 중복·삭제된 문서는 정리하고, 카테고리 메타데이터와 문서 순서를 명시하면 탐색성이 크게 향상됩니다.",
          "author": "GitHub Action",
          "authorEmail": "action@github.com",
          "date": "2026-02-24T00:35:21Z",
          "isAutoCommit": true,
          "additions": 0,
          "deletions": 0
        }
      ]
    }
  ],
  "tree": [
    {
      "name": "프로젝트",
      "path": "projects",
      "isCategory": true,
      "order": 1,
      "children": [
        {
          "title": "OpenClaw 완벽 가이드",
          "slug": "projects/openclaw-complete-guide",
          "menu": "OpenClaw",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Claude Code 릴리즈 히스토리 상세 가이드",
          "slug": "projects/claude-code-release-history",
          "menu": "Claude Code",
          "order": 2,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Opencode에 대해",
          "slug": "projects/opencode",
          "order": 3,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "SEPilot Desktop 소개",
          "slug": "projects/sepilot-desktop-intro",
          "order": 4,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Sepilot Wiki가 어떤 언어/프레임워크로 구현되어 있나요?",
          "slug": "projects/sepilot-technology-stack",
          "menu": "SEPilot Wiki에 대해",
          "order": 5,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Antigravity 릴리즈 노트 정리",
          "slug": "projects/antigravity-release-notes",
          "menu": "Antigravity",
          "order": 6,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Rust 기반 GPU 가속 얼굴 크롭 도구 구현 가이드",
          "slug": "projects/rust-gpu-face-crop-tool",
          "order": 7,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Moltbook 소개",
          "slug": "projects/moltbook-intro",
          "order": 8,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "AI·LLM",
      "path": "ai",
      "isCategory": true,
      "order": 2,
      "children": [
        {
          "title": "클라우드 터미널 구축: 지속적인 AI 에이전트 세션 유지하기",
          "slug": "ai/cloud-terminal-persistent-ai-agent-sessions",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "MCP (Model Context Protocol) 완벽 가이드",
          "slug": "ai/mcp-model-context-protocol",
          "menu": "MCP 가이드",
          "order": 2,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Qwen 3.5",
          "slug": "ai/qwen3-5",
          "order": 3,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Continuous AI – 인간이 AI 오류를 검증하는 방법",
          "slug": "ai/continuous-ai",
          "order": 4,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "glm 5",
          "slug": "ai/glm-5",
          "order": 5,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Automate Repository Tasks with GitHub Agentic Workflows",
          "slug": "ai/github-agentic-workflows",
          "order": 6,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "바이브 코딩이란?",
          "slug": "ai/vibe-coding",
          "order": 7,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "멀티 에이전트 시스템 – Self‑Healing AI Agents",
          "slug": "ai/multi-agent-system",
          "order": 8,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Gemini 3.1 Pro",
          "slug": "ai/gemini-3-1-pro",
          "order": 9,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "AI 코드 리뷰 에이전트 구축 가이드",
          "slug": "ai/code-review-agent-guide",
          "order": 10,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "LLM 진화 연대별 타임라인 및 171개 모델 개관",
          "slug": "ai/243",
          "order": 11,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "AI Agent 배포 실패 방지와 테스트 전략 가이드",
          "slug": "ai/240",
          "order": 12,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Ollama와 Claude Code 연결 방법",
          "slug": "ai/ollama-claude-code",
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "Kubernetes",
      "path": "kubernetes",
      "isCategory": true,
      "order": 3,
      "children": [
        {
          "title": "Introducing Node Readiness Controller",
          "slug": "kubernetes/node-readiness-controller",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Ingress NGINX 은퇴 선언 및 마이그레이션 가이드",
          "slug": "kubernetes/ingress-nginx-deprecation-guide",
          "menu": "Ingress NGINX 마이그레이션",
          "order": 2,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "cgroup v1 CPU Shares → v2 CPU Weight 변환 공식 업데이트 가이드",
          "slug": "kubernetes/cgroup-migration",
          "order": 4,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Kubernetes 버전별 릴리즈 노트",
          "slug": "kubernetes/release-notes",
          "menu": "K8s 릴리즈 노트",
          "order": 5,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Kubernetes/Api Governance",
          "slug": "kubernetes/api-governance",
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "Bun",
      "path": "bun",
      "isCategory": true,
      "order": 4,
      "children": [
        {
          "title": "bun 이란?",
          "slug": "bun/overview",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "bun과 pnpm, npm의 차이",
          "slug": "bun/comparison-pnpm-npm",
          "order": 2,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "GitHub Actions로 bun을 쓰는 방법",
          "slug": "bun/github-actions-setup",
          "order": 3,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "Docker",
      "path": "docker",
      "isCategory": true,
      "order": 5,
      "children": [
        {
          "title": "Docker/Hardened Images",
          "slug": "docker/hardened-images",
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "클라우드 인프라",
      "path": "cloud",
      "isCategory": true,
      "order": 6,
      "children": [
        {
          "title": "$100K AWS 라우팅 비용 함정: S3 + NAT 게이트웨이와 Terraform 해결법",
          "slug": "cloud/aws-nat-gateway-cost-trap",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "프론트엔드",
      "path": "frontend",
      "isCategory": true,
      "order": 7,
      "children": [
        {
          "title": "프론트엔드 API 서비스 레이어 설명",
          "slug": "frontend/api-service-layer",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "Incremental Static Regeneration (ISR) 가이드",
          "slug": "frontend/isr-guide",
          "order": 2,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "백엔드",
      "path": "backend",
      "isCategory": true,
      "order": 8,
      "children": [
        {
          "title": "Wiki 페이지 API 라우트 상세 가이드",
          "slug": "backend/wiki-api-route-guide",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "관측성",
      "path": "observability",
      "isCategory": true,
      "order": 9,
      "children": [
        {
          "title": "OpenTelemetry 개요 및 실전 가이드",
          "slug": "observability/open-telemetry-guide",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "GitHub",
      "path": "github",
      "isCategory": true,
      "order": 10,
      "children": [
        {
          "title": "Dependabot 라벨 설정 가이드",
          "slug": "github/dependabot-labels",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    },
    {
      "name": "메타·보고서",
      "path": "meta",
      "isCategory": true,
      "order": 11,
      "children": [
        {
          "title": "주간 위키 보고서 - 2026년 9주차",
          "slug": "meta/weekly-2026-09",
          "order": 1,
          "lastModified": "2026-02-24T00:35:21Z"
        },
        {
          "title": "주간 위키 보고서 - 2026년 08주차",
          "slug": "meta/weekly-2026-08",
          "order": 2,
          "lastModified": "2026-02-24T00:35:21Z"
        }
      ]
    }
  ]
}