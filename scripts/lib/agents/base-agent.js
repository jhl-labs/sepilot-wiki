/**
 * ì—ì´ì „íŠ¸ ê¸°ë³¸ í´ë˜ìŠ¤
 *
 * ëª¨ë“  ì „ë¬¸ ì—ì´ì „íŠ¸(Researcher, Writer, Reviewer, Editor)ì˜ ë¶€ëª¨ í´ë˜ìŠ¤
 * ê³µí†µ LLM í˜¸ì¶œ, ë„êµ¬ ê¶Œí•œ í™•ì¸, ì‹¤í–‰ ì¶”ì  ê¸°ëŠ¥ ì œê³µ
 */

import { callOpenAI } from '../utils.js';

export class BaseAgent {
  /**
   * @param {Object} definition - ì—ì´ì „íŠ¸ ì •ì˜
   * @param {string} definition.role - ì—ì´ì „íŠ¸ ì—­í•  ID
   * @param {string} definition.name - ì—ì´ì „íŠ¸ ì´ë¦„ (í‘œì‹œìš©)
   * @param {string} definition.systemPrompt - ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
   * @param {string[]} definition.tools - ì‚¬ìš© ê°€ëŠ¥í•œ ë„êµ¬ ëª©ë¡
   * @param {'markdown'|'json'|'text'} definition.outputFormat - ì¶œë ¥ í˜•ì‹
   * @param {number} definition.temperature - LLM ì˜¨ë„
   * @param {number} definition.maxTokens - ìµœëŒ€ í† í° ìˆ˜
   */
  constructor(definition) {
    this.role = definition.role;
    this.name = definition.name;
    this.systemPrompt = definition.systemPrompt;
    this.tools = definition.tools || [];
    this.outputFormat = definition.outputFormat || 'text';
    this.temperature = definition.temperature ?? 0.1;
    this.maxTokens = definition.maxTokens ?? 4000;
  }

  /**
   * íƒœìŠ¤í¬ ì‹¤í–‰ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ ì˜¤ë²„ë¼ì´ë“œ)
   * @param {Object} task - íƒœìŠ¤í¬ ê°ì²´
   * @param {Object} context - ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
   * @returns {Promise<Object>} ì‹¤í–‰ ê²°ê³¼
   */
  async execute(task, context) {
    const start = Date.now();
    console.log(`ğŸ¤– [${this.name}] íƒœìŠ¤í¬ ì‹¤í–‰: ${task.type}`);

    try {
      const result = await this.run(task, context);
      const durationMs = Date.now() - start;

      console.log(`   âœ… [${this.name}] ì™„ë£Œ (${(durationMs / 1000).toFixed(1)}ì´ˆ)`);

      return {
        success: true,
        output: result,
        agent: this.role,
        durationMs,
      };
    } catch (error) {
      const durationMs = Date.now() - start;
      console.error(`   âŒ [${this.name}] ì‹¤íŒ¨: ${error.message}`);

      return {
        success: false,
        error: error.message,
        agent: this.role,
        durationMs,
      };
    }
  }

  /**
   * ì‹¤ì œ ì‘ì—… ìˆ˜í–‰ (ì„œë¸Œí´ë˜ìŠ¤ì—ì„œ êµ¬í˜„)
   * @param {Object} task - íƒœìŠ¤í¬ ê°ì²´
   * @param {Object} context - ì‹¤í–‰ ì»¨í…ìŠ¤íŠ¸
   * @returns {Promise<*>} ì‘ì—… ê²°ê³¼
   */
  async run(task, context) {
    throw new Error(`${this.name}: run() ë©”ì„œë“œê°€ êµ¬í˜„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.`);
  }

  /**
   * ì—ì´ì „íŠ¸ ì„¤ì •ì´ ì ìš©ëœ LLM í˜¸ì¶œ
   * @param {string} userPrompt - ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸
   * @param {Object} [opts] - ì¶”ê°€ ì˜µì…˜ (temperature, maxTokens ì˜¤ë²„ë¼ì´ë“œ ê°€ëŠ¥)
   * @returns {Promise<string>} LLM ì‘ë‹µ
   */
  async callLLM(userPrompt, opts = {}) {
    const messages = [
      { role: 'system', content: this.systemPrompt },
      { role: 'user', content: userPrompt },
    ];

    const options = {
      temperature: opts.temperature ?? this.temperature,
      maxTokens: opts.maxTokens ?? this.maxTokens,
    };

    // JSON ì¶œë ¥ í˜•ì‹ì´ë©´ response_format ì„¤ì •
    if (this.outputFormat === 'json') {
      options.responseFormat = 'json_object';
    }

    return callOpenAI(messages, options);
  }

  /**
   * ë„êµ¬ ì‚¬ìš© ê¶Œí•œ í™•ì¸
   * @param {string} tool - ë„êµ¬ ì´ë¦„
   * @returns {boolean}
   */
  canUseTool(tool) {
    return this.tools.includes(tool);
  }

  /**
   * ì—ì´ì „íŠ¸ ì •ë³´ ë°˜í™˜
   * @returns {Object}
   */
  getInfo() {
    return {
      role: this.role,
      name: this.name,
      tools: this.tools,
      outputFormat: this.outputFormat,
      temperature: this.temperature,
      maxTokens: this.maxTokens,
    };
  }
}
