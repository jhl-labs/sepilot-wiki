#!/usr/bin/env node

/**
 * í†µí•© ë¹Œë“œ íŒŒì´í”„ë¼ì¸
 *
 * build-wiki-data, build-search-index, build-sitemapì„ í•˜ë‚˜ì˜ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‹¤í–‰
 * ë””ìŠ¤í¬ I/O ì¤‘ë³µ ì œê±°: íŒŒì‹±ëœ pages ë°°ì—´ì„ ë©”ëª¨ë¦¬ ë‚´ì—ì„œ ê³µìœ 
 * ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê¸°ë°˜ ë³€ê²½ ê°ì§€ + health-status ê°±ì‹ 
 */

import { buildWikiData, buildGuideData } from './build-wiki-data.js';
import { buildSearchIndex } from './build-search-index.js';
import { readFile, writeFile, mkdir } from 'fs/promises';
import { join } from 'path';
import { existsSync } from 'fs';

const PUBLIC_DIR = join(process.cwd(), 'public');
const DATA_DIR = join(PUBLIC_DIR, 'data');

/**
 * í†µí•© ë¹Œë“œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
 *
 * 1. ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë³€ê²½ ê°ì§€ (ì„ íƒì )
 * 2. Wiki ë°ì´í„° ë¹Œë“œ (JSON íŒŒì¼ ìƒì„±)
 * 3. Guide ë°ì´í„° ë¹Œë“œ
 * 4. ê²€ìƒ‰ ì¸ë±ìŠ¤ ë¹Œë“œ (ë©”ëª¨ë¦¬ì—ì„œ pages ë°ì´í„° ê³µìœ )
 * 5. Sitemap ë¹Œë“œ (ì¡´ì¬í•˜ëŠ” ê²½ìš°)
 * 6. Health Status ê°±ì‹ 
 */
async function runBuildPipeline() {
  const pipelineStart = Date.now();
  console.log('ğŸ”§ í†µí•© ë¹Œë“œ íŒŒì´í”„ë¼ì¸ ì‹œì‘...\n');

  // Step 1: Wiki ë°ì´í„° ë¹Œë“œ
  console.log('â”â”â” Step 1/5: Wiki ë°ì´í„° ë¹Œë“œ â”â”â”');
  await buildWikiData();

  // Step 2: Guide ë°ì´í„° ë¹Œë“œ
  console.log('\nâ”â”â” Step 2/5: Guide ë°ì´í„° ë¹Œë“œ â”â”â”');
  await buildGuideData();

  // Step 3: ê²€ìƒ‰ ì¸ë±ìŠ¤ ë¹Œë“œ (ë¹Œë“œëœ JSONì—ì„œ ë¡œë“œí•˜ì—¬ ê³µìœ )
  console.log('\nâ”â”â” Step 3/5: ê²€ìƒ‰ ì¸ë±ìŠ¤ ë¹Œë“œ â”â”â”');
  let wikiPages = [];
  let guidePages = [];

  const wikiDataFile = join(PUBLIC_DIR, 'wiki-data.json');
  if (existsSync(wikiDataFile)) {
    const wikiData = JSON.parse(await readFile(wikiDataFile, 'utf-8'));
    wikiPages = wikiData.pages || [];
  }

  const guideDataFile = join(PUBLIC_DIR, 'guide-data.json');
  if (existsSync(guideDataFile)) {
    const guideData = JSON.parse(await readFile(guideDataFile, 'utf-8'));
    guidePages = (guideData.pages || []).map((page) => ({
      ...page,
      slug: `guide/${page.slug}`,
    }));
  }

  await buildSearchIndex({ wikiPages, guidePages });

  // Step 4: Sitemap ë¹Œë“œ (íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°)
  console.log('\nâ”â”â” Step 4/5: Sitemap ë¹Œë“œ â”â”â”');
  try {
    const { buildSitemap } = await import('./build-sitemap.js');
    await buildSitemap(wikiPages);
  } catch {
    console.log('â„¹ï¸ Sitemap ë¹Œë“œ ê±´ë„ˆëœ€ (ëª¨ë“ˆ ì—†ìŒ)');
  }

  // Step 5: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ + Health Status ê°±ì‹ 
  console.log('\nâ”â”â” Step 5/5: ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë° Health Status ê°±ì‹  â”â”â”');
  try {
    const { computeCurrentHashes, saveManifest } = await import('./build-manifest.js');
    const currentHashes = await computeCurrentHashes();
    await saveManifest({
      files: currentHashes,
      lastFullBuild: new Date().toISOString(),
    });
    console.log(`   ğŸ“‹ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê°±ì‹ : ${Object.keys(currentHashes).length}ê°œ íŒŒì¼`);
  } catch {
    console.log('â„¹ï¸ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ê°±ì‹  ê±´ë„ˆëœ€');
  }

  // Health Status ê°±ì‹ 
  try {
    await updateHealthStatus(wikiPages.length);
    console.log('   ğŸ¥ Health Status ê°±ì‹  ì™„ë£Œ');
  } catch {
    console.log('â„¹ï¸ Health Status ê°±ì‹  ê±´ë„ˆëœ€');
  }

  const totalMs = Date.now() - pipelineStart;

  // ë¹Œë“œ ë©”íŠ¸ë¦­ ê¸°ë¡
  try {
    const { collectBuildMetrics } = await import('../collectors/collect-build-metrics.js');
    await collectBuildMetrics({
      buildDurationMs: totalMs,
      pageCount: wikiPages.length,
    });
  } catch {
    console.log('â„¹ï¸ ë¹Œë“œ ë©”íŠ¸ë¦­ ê¸°ë¡ ê±´ë„ˆëœ€');
  }

  console.log(`\nğŸ‰ í†µí•© ë¹Œë“œ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ (${(totalMs / 1000).toFixed(1)}ì´ˆ)`);
  console.log(`   Wiki: ${wikiPages.length}ê°œ ë¬¸ì„œ`);
  console.log(`   Guide: ${guidePages.length}ê°œ ë¬¸ì„œ`);
}

/**
 * Health Status ê°±ì‹ 
 * @param {number} pageCount - ë¹Œë“œëœ í˜ì´ì§€ ìˆ˜
 */
async function updateHealthStatus(pageCount) {
  await mkdir(DATA_DIR, { recursive: true });
  const healthFile = join(DATA_DIR, 'health-status.json');

  // error-log.jsonì—ì„œ ìµœê·¼ 24ì‹œê°„ ì—ëŸ¬ ìˆ˜ ì§‘ê³„
  let recentErrors = 0;
  const errorLogFile = join(DATA_DIR, 'error-log.json');
  if (existsSync(errorLogFile)) {
    try {
      const errorLog = JSON.parse(await readFile(errorLogFile, 'utf-8'));
      const oneDayAgo = new Date(Date.now() - 24 * 60 * 60 * 1000).toISOString();
      recentErrors = (errorLog.entries || []).filter(
        (e) => e.timestamp > oneDayAgo
      ).length;
    } catch {
      // ë¬´ì‹œ
    }
  }

  // agent-metrics.jsonì—ì„œ í‰ê·  ì ìˆ˜ ê³„ì‚°
  let avgScore = null;
  const metricsFile = join(DATA_DIR, 'agent-metrics.json');
  if (existsSync(metricsFile)) {
    try {
      const metrics = JSON.parse(await readFile(metricsFile, 'utf-8'));
      const reviewerStats = metrics.summary?.reviewer;
      if (reviewerStats?.avgReviewScore != null) {
        avgScore = reviewerStats.avgReviewScore;
      }
    } catch {
      // ë¬´ì‹œ
    }
  }

  // overall ìƒíƒœ ê²°ì •
  let overall = 'healthy';
  if (recentErrors >= 10) overall = 'unhealthy';
  else if (recentErrors >= 3) overall = 'degraded';

  const healthStatus = {
    overall,
    checks: {
      'build-pipeline': {
        lastSuccess: new Date().toISOString(),
        status: 'ok',
      },
      'agent-pipeline': {
        lastSuccess: new Date().toISOString(),
        avgScore,
        status: avgScore != null && avgScore < 60 ? 'warning' : 'ok',
      },
    },
    pageCount,
    recentErrors,
    updatedAt: new Date().toISOString(),
  };

  await writeFile(healthFile, JSON.stringify(healthStatus, null, 2));
}

runBuildPipeline().catch((err) => {
  console.error('âŒ í†µí•© ë¹Œë“œ íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨:', err);
  process.exit(1);
});
