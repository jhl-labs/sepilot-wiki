---
title: Open WebUI와 Docker Model Runner를 활용한 셀프‑호스티드 LLM 가이드
author: SEPilot AI
status: draft
tags: [Docker, OpenWebUI, LLM, Sandbox, Self‑Hosted]
---

## 1. 개요
이 문서는 **Open WebUI**와 **Docker Model Runner**를 결합해 로컬에서 대형 언어 모델(LLM)을 안전하게 운영하고자 하는 개발자·운영자를 대상으로 합니다.  
- **목적**: Docker 기반 마이크로VM 샌드박스를 이용해 Claude Code, Gemini, Codex, Kiro 등 최신 코딩 에이전트를 감독 없이(unsupervised) 실행하면서도 격리와 보안을 유지하는 방법을 제공한다.  
- **대상 독자**: Docker 사용 경험이 있는 엔지니어, AI·LLM 실험을 로컬 환경에서 진행하려는 연구자, 보안·규정 준수가 필요한 기업 사용자.  

셀프‑호스티드 LLM 운영은  
- 클라우드 비용 절감,  
- 데이터 유출 위험 최소화,  
- 커스텀 프롬프트·플러그인 적용 자유  
와 같은 기대 효과를 제공합니다 [출처: euno.news](https://euno.news/posts/ko/open-webui-docker-model-runner-self-hosted-models-a92a5a).

## 2. 사전 요구사항
| 항목 | 권장/필수 | 비고 |
|------|-----------|------|
| 운영체제 | Linux (Ubuntu 20.04 이상 권장) | Docker Engine은 Linux 커널 기능을 활용합니다. |
| Docker Engine | **Docker Engine 24.x 이상** (Docker Desktop 포함) | 최신 Hardened Images와 microVM 기능은 최신 엔진에서 지원됩니다 [Docker Blog, 2025‑12‑17]. |
| CPU | x86_64 또는 ARM64, **멀티코어 4코어 이상** 권장 | 모델 로드·추론 시 멀티스레드 활용. |
| GPU | NVIDIA CUDA 11.x 이상 (옵션) | GPU 가속이 필요할 경우 `nvidia-docker2` 설치 필요. |
| 메모리 | 최소 **8 GB**, 권장 **16 GB 이상** | 모델 크기에 따라 차등. |
| 저장소 | SSD ≥ 50 GB, 모델 캐시용 별도 볼륨 권장 | 모델 파일은 수십 GB에 달할 수 있음. |
| 네트워크 | 포트 **8080**(Open WebUI) 및 **5000**(Model Runner API) 개방 | 방화벽 규칙에 예외 추가 필요. |
| 계정 | Docker Hub 계정 (이미지 pull용) | 무료 Hardened Images는 Docker Hub에서 제공됩니다 [Docker Blog, 2025‑12‑17]. |
| 기타 도구 | `git` (레포지터리 클론), `curl` (헬스체크) |  |

> **※ 추가 조사 필요**: 정확한 Docker Engine 최소 버전, GPU 드라이버 호환 매트릭스, 권장 OS 배포판 등은 공식 Docker 문서와 모델 러너 릴리즈 노트를 확인해야 합니다.

## 3. Docker Model Runner 소개
### 3.1 전체 아키텍처
```
+-------------------+      +-------------------+      +-------------------+
|   Open WebUI      | <--->| Docker Model Runner| <--->|  MicroVM Sandbox  |
+-------------------+      +-------------------+      +-------------------+
        ^                         ^                         ^
        |                         |                         |
   사용자 UI                API (REST)               격리된 모델 프로세스
```
- **Open WebUI**: 웹 기반 프론트엔드, 사용자 인증·프롬프트 관리.  
- **Docker Model Runner**: 모델 파일을 로드하고 HTTP / gRPC API를 제공하는 경량 컨테이너.  
- **MicroVM Sandbox**: Docker가 제공하는 **microVM 기반 격리**(Firecracker 등) 위에 모델 프로세스를 실행, “Unsupervised하지만 Safe” 환경을 구현 [Docker Blog, 2026‑01‑30].

### 3.2 주요 컴포넌트
| 컴포넌트 | 역할 |
|----------|------|
| `model-runner` | 모델 로드, 추론 엔드포인트 제공 |
| `microVM` | 하드웨어 가상화 없이 경량 VM 형태로 격리 |
| `sandbox‑controller` | 컨테이너·microVM lifecycle 관리, 정책 적용 |

### 3.3 이미지 구조와 레이어
Docker Hardened Images는 **베이스 이미지 + 보안 패치 레이어** 형태로 제공됩니다. 이미지 레이어는 다음과 같이 구성됩니다.
1. `docker.io/library/ubuntu:22.04` (베이스)  
2. `docker.io/hardened/model-runner:latest` (Hardened Image) – 최신 보안 설정 포함 [Docker Blog, 2025‑12‑17].

### 3.4 실행 흐름
1. **컨테이너 생성** – `docker run` 명령으로 Hardened Image 실행.  
2. **MicroVM 초기화** – `sandbox‑controller`가 microVM을 스폰하고 네임스페이스를 할당.  
3. **모델 로드** – 지정된 모델 레지스트리(HF, Ollama 등)에서 파일을 다운로드하고 캐시.  
4. **API 제공** – `localhost:5000`(또는 지정 포트)에서 REST / gRPC 엔드포인트 오픈.  
5. **Open WebUI 연동** – UI에서 모델 선택·프롬프트 전송 → Model Runner API 호출.

## 4. Open WebUI와의 통합
### 4.1 Open WebUI 설치
```bash
docker pull ghcr.io/open-webui/open-webui:latest
docker run -d -p 8080:8080 ghcr.io/open-webui/open-webui:latest
```
> 공식 문서: <https://docs.openwebui.com/>

### 4.2 Docker Model Runner 플러그인 연결
Open WebUI는 `MODEL_RUNNER_URL` 환경변수를 통해 외부 모델 서버를 지정합니다.
```bash
export MODEL_RUNNER_URL=http://host.docker.internal:5000
```
설정 파일(`config.yaml`)에 아래와 같이 매핑:
```yaml
model:
  runner_url: http://host.docker.internal:5000
  default_model: claude-code
```

### 4.3 인증·인가 연동
- **API‑Key**: Model Runner는 `X-API-KEY` 헤더를 검증합니다. Open WebUI 관리 페이지에서 키를 생성하고 환경변수 `MODEL_RUNNER_API_KEY`에 전달합니다.  
- **OAuth**: 필요 시 Open WebUI OAuth 플러그인을 활성화하고, Model Runner에 토큰 검증 미들웨어를 추가할 수 있습니다 (추가 조사 필요).

## 5. 보안 샌드박스 구현
### 5.1 마이크로VM 기반 격리
Docker는 **Firecracker**와 같은 microVM을 활용해 컨테이너 내부에 별도 커널을 실행합니다. 이는 전통적인 컨테이너보다 **더 낮은 공격 표면**을 제공합니다 [Docker Blog, 2026‑01‑30].

### 5.2 Docker Hardened Images
- **무료 제공**: Docker Hardened Images는 라이선스 없이 사용·공유·빌드가 가능 [Docker Blog, 2025‑12‑17].  
- **보안 강화**: 기본 이미지에 `seccomp`, `AppArmor` 프로파일이 사전 적용되어 있습니다.

### 5.3 권한 최소화
| 메커니즘 | 적용 방법 |
|----------|-----------|
| User Namespace | `--userns-remap=default` 옵션 사용 |
| Seccomp | Hardened Image에 기본 제공된 `seccomp.json` 적용 |
| AppArmor | `docker run --security-opt apparmor=profile_name` |

### 5.4 네트워크 격리 및 데이터 영구성
- **네트워크**: `--network=none`으로 외부와 격리하고, UI와 API 통신만 `--publish`로 허용.  
- **볼륨**: 모델 캐시는 읽기 전용 볼륨에 마운트하고, 로그·설정은 별도 영구 볼륨에 저장합니다.

## 6. 모델 배포 및 관리
### 6.1 지원 모델 포맷·레지스트리
- **Hugging Face Hub** (`hf://model-id`)  
- **Ollama** (`ollama://model-name`)  
- **로컬 파일** (`file:///path/to/model`)  

### 6.2 모델 다운로드·캐시 전략
Model Runner는 최초 요청 시 레지스트리에서 모델을 다운로드하고, `/var/lib/model-runner/cache`에 저장합니다. 캐시 정책은 `CACHE_MAX_SIZE`(GB)와 `CACHE_TTL`(days) 환경변수로 조정 가능.

### 6.3 버전 관리·롤백
- **버전 태그**: `model-runner:1.2.0` 등으로 이미지 버전 관리.  
- **롤백**: 이전 이미지로 `docker compose down && docker compose up -d` 실행.  

### 6.4 자동 업데이트(CI/CD)
GitHub Actions 예시 (YAML 형식, 코드 블록 없이):
```yaml
name: Deploy Model Runner
on:
  push:
    tags:
      - 'v*'
jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Build Docker image
        run: docker build -t ghcr.io/yourorg/model-runner:${{ github.ref_name }} .
      - name: Push to GHCR
        run: docker push ghcr.io/yourorg/model-runner:${{ github.ref_name }}
      - name: Deploy
        run: ssh user@host 'docker pull ghcr.io/yourorg/model-runner:${{ github.ref_name }} && docker compose up -d'
```
> 공식 CI/CD 문서: <https://docs.github.com/en/actions>

## 7. 실전 예시
### 7.1 Claude Code 샌드박스
1. **이미지 Pull**  
```bash
docker pull ghcr.io/docker/hardened/model-runner:claude-code
```
2. **컨테이너 실행**  
```bash
docker run -d --name claude-code \
  -p 5000:5000 \
  --security-opt seccomp=default.json \
  ghcr.io/docker/hardened/model-runner:claude-code
```
3. **Open WebUI 연동** – `MODEL_RUNNER_URL`을 `http://localhost:5000`으로 지정.

### 7.2 Gemini, Codex, Kiro
위와 동일한 절차로 각각의 태그(`gemini`, `codex`, `kiro`)를 사용해 이미지 Pull·실행하면 됩니다. 각 모델은 **microVM 격리**와 **Hardened Image** 보안 정책을 자동 적용합니다 [Docker Blog, 2026‑01‑30].

### 7.3 OpenClaw 로컬 실행
Oleg Selajev가 제시한 예시(2026‑02‑23)와 동일하게:
```bash
docker run -d --name openclaw \
  -p 5001:5000 \
  -e MODEL=openclaw \
  ghcr.io/docker/hardened/model-runner:openclaw
```
- API 키 없이 로컬에서 실행 가능, 클라우드 비용 발생 없음 [Docker Blog, 2026‑02‑23].

### 7.4 성능 튜닝 포인트
- **CPU 제한**: `--cpus="4"`  
- **메모리 제한**: `--memory="8g"`  
- **GPU 할당**: `--gpus=all` (NVIDIA Docker)  

## 8. 성능 및 비용 최적화
| 최적화 항목 | 방법 |
|-------------|------|
| 리소스 제한 | `docker run --cpus`, `--memory` 옵션 사용 |
| 자동 재시작 | `--restart=unless-stopped` |
| 로컬 실행 | 클라우드 API 호출을 배제해 비용 절감 |
| 모니터링 | Prometheus `node_exporter`와 Grafana 대시보드 연동 (Docker Hub `prom/prometheus` 이미지) |
| 스케일링 | 필요 시 `docker compose scale model-runner=3` 로 다중 인스턴스 배포 |

## 9. 트러블슈팅 및 FAQ
### 9.1 일반 오류
- **이미지 Pull 실패**: Docker Hub 인증 토큰 확인, 네트워크 방화벽 포트 443 개방.  
- **포트 충돌**: `docker ps`로 현재 바인딩된 포트 확인 후 `-p` 옵션 변경.  
- **GPU 인식 안 됨**: `nvidia-smi` 실행 확인, `nvidia-docker2` 설치 여부 점검.

### 9.2 로그 분석
컨테이너 로그는 `docker logs <container>` 로 확인. Model Runner는 `/var/log/model-runner.log`에 상세 스택 트레이스를 남깁니다.

### 9.3 FAQ
**Q**: Open WebUI와 Model Runner를 같은 Docker Compose 파일에 넣을 수 있나요?  
**A**: 가능. `depends_on`을 이용해 UI가 Model Runner가 준비될 때까지 대기하도록 설정합니다.

**Q**: 모델 업데이트 시 다운타임을 최소화하려면?  
**A**: Blue‑Green 배포 전략을 사용해 새 컨테이너를 먼저 띄운 뒤, 트래픽을 스위치합니다.

## 10. 향후 로드맵 및 참고 자료
- **Docker Model Runner**: 향후 **GPU 자동 할당**, **멀티‑테넌시** 지원 예정 (Docker Blog, 2026‑02‑23).  
- **Open WebUI**: 플러그인 마켓플레이스 확대와 **OAuth2** 표준 연동 로드맵 발표 (예정).  

### 공식 문서·블로그·커뮤니티
- Docker Blog – Sandbox & Hardened Images: <https://www.docker.com/blog/>  
- Open WebUI GitHub: <https://github.com/open-webui/open-webui>  
- Docker Docs – Engine & Security: <https://docs.docker.com/engine/>  

### 추가 학습 자료
- “Secure AI Inference with MicroVMs” – Docker Community Webinar (2026)  
- “Self‑Hosted LLM Best Practices” – euno.news 시리즈 (2026‑01‑30)  

> **※ 본 가이드는 현재 공개된 Docker Blog와 euno.news 자료를 기반으로 작성되었습니다. 구체적인 버전 호환성, GPU 드라이버 매트릭스 등은 추후 공식 릴리즈 노트를 참고해 업데이트가 필요합니다.**